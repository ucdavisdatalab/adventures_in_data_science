[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adventures in Data Science",
    "section": "",
    "text": "Overview\nThis is the course reader for IST008, Adventures in Data Science: Social Science Edition. The course is designed to provide students with a basic understanding of computing and network architecture, basic programming skills, and an introduction to common methods in Data Science and Digital Humanities. This course reader provides background information that will help you to better understand the concepts that we will discuss in class and to better participate in the hands-on portion of the course.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "chapters/required-software.html",
    "href": "chapters/required-software.html",
    "title": "Required Software",
    "section": "",
    "text": "Git\nGit is version control system. It helps keep track of changes and updates to your files. You can use it locally on your machine and also on servers.\nYou can download Git for free here.",
    "crumbs": [
      "Required Software"
    ]
  },
  {
    "objectID": "chapters/required-software.html#git",
    "href": "chapters/required-software.html#git",
    "title": "Required Software",
    "section": "",
    "text": "Important\n\n\n\nOn Windows, an extra configuration step is necessary to make sure Git Bash is installed with Git.\nOn macOS, no extra configuration steps are necessary. We recommend installing Git via Xcode.\nFor more detailed instructions on how to download Git for your specific operating system, see the Installing Git section of DataLab’s Introduction to Version Control workshop.",
    "crumbs": [
      "Required Software"
    ]
  },
  {
    "objectID": "chapters/required-software.html#r-r-studio",
    "href": "chapters/required-software.html#r-r-studio",
    "title": "Required Software",
    "section": "R & R Studio",
    "text": "R & R Studio\nR is a programming language for working with data, performing statistical analyses, and generating data visualizations.\nYou can download R for free here.\nRStudio is an integrated development environment (IDE) that provides a user-friendly interface for working with R. RStudio will not work if you do not also have R installed.\nYou can download the RStudio Desktop Open-Source Edition for free here.",
    "crumbs": [
      "Required Software"
    ]
  },
  {
    "objectID": "chapters/01_command-line.html",
    "href": "chapters/01_command-line.html",
    "title": "1  Command Line",
    "section": "",
    "text": "This lesson provides an introduction to the command line, equipping you with the tools to open and work within your systems’ files without a graphical user interface.\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nAfter this lesson, you should be able to:\n\nUnderstand the components of your computer’s command line prompt\nRun commands in the command line\nIdentify common commands and flags to navigate your system\nOpen and interact with the Vim text editor\nUse common Vim commands\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe primary material for this lesson is Chapters 4-8 of DataLab’s Introduction to the Unix Command Line workshop.\nAny supplementary material will be posted in this chapter.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Command Line</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html",
    "href": "chapters/02_version-control.html",
    "title": "2  Version Control",
    "section": "",
    "text": "2.1 Introduction\nVersion control describes the process of storing and organizing multiple versions (or copies) of files on your computer. Approaches to version control range from simple to complex and they can involve the use of both manual and automatic workflows. Ultimately, the overall goal of version control is to store and manage multiple versions of the same file(s).\nChances are good that you are already doing some kind of version control yourself. Most people have a folder/directory somewhere on their computer that looks something like this:\nOr perhaps, this:\nThis is a rudimentary form of version control where it’s completely up to you to name, save, and keep track of multiple versions of a file. This filesystem approach works minimally well, in that it does provide you with a history of file versions theoretically organized by their time sequence. But this system provides no information about how the file has changed from version to version, why you might have saved a particular version, or specifically how the various versions are related. This approach is also subject to human error. It’s easy to make a mistake when naming a file version, or to go back and edit a file without saving a new copy.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#introduction",
    "href": "chapters/02_version-control.html#introduction",
    "title": "2  Version Control",
    "section": "",
    "text": "2.1.1 Version Control Systems\nA version control system (VCS) is software designed to automate version control. Version control systems originated in the software development community, where it’s common for many people to work on the same file, sometimes synchronously, amplifying the need to track and understand revisions. But nearly all types of computer files, not just code, can be tracked using modern version control systems.\n\n\n\n\n\n\nHistorical Note\n\n\n\nIBM’s OS/360 IEBUPDTE software update tool is widely regarded as the earliest and most widely adopted precursor to modern, version control systems. Its release in 1972 of the Source Code Control System (SCCS) package marked the first, fully fledged system designed specifically for software version control.\n\n\nIt’s common for projects to have multiple associated files, so most version control systems keep track of changes to a repository: a collection of files. Generally, a repository (or repo) is just a directory where you’ve set up a version control system to keep track of changes to the contents. A repository can contain any number of files and subdirectories.\nIt’s also common for people to collaborate on projects, so most version control systems provide a way to create multiple copies of a repository and share changes between them. Version control systems can be divided into two categories based on how they do this:\n\nCentralized version control systems store the repository and its history on a single computer. This computer is usually a server, a computer connected to the Internet or some other network. Users can check out a copy of the repository from the server, make changes, and then check in their changes with the server. The server is the sole authority on the repository’s history. You can think of this as a “hub and spoke” model, where the server is the hub and users are the spokes. This is the oldest kind of version control system.\nDistributed version control systems treat each copy of the repository as an authority on the repository’s history, and provide ways to sync changes and resolve conflicts between copies. As two different users make changes to their copies of the repository, the copies will diverge if both users edit the same file. The divergence will remain in place until the two copies are synced, at which time the VCS merges the two different versions of the file into a single version that reflects the changes made by both users. You can think of this as a “network” model (like a social network).\n\n\n\n\n\n\n\n\n\nCentralized (hub and spoke) model\n\n\n\n\n\n\n\nDistributed (network) model\n\n\n\n\n\n\nFigure 2.1\n\n\n\nCentralized VCS provide a very ordered and controlled universe. They ensure users have access to the most recent version of every file in the repository, which reduces the potential for conflicting changes to files.\n\n\n\n\n\n\nHistorical Note\n\n\n\nEarly centralized version control systems typically required users to check out individual files or directories rather than entire repositories, and only allowed one user to check out a given file at time. This prevented conflicting edits, but made it difficult to work concurrently.\n\n\nOn the other hand, distributed VCS offer greater flexibility. They allow users to work alone or in small groups, work offline, or work on experimental changes over an extended period without losing the benefits of version control. These characteristics facilitate collaborative work. Moreover, a distributed VCS can be used in a centralized way, where one copy of the repository is treated as the final authority on the repository’s history. This gives users the best of both worlds, by allowing some to sync directly with each other while others sync with this authoritative copy.\nToday, a distributed VCS, Git, is the most popular VCS. Some polls estimate that it’s used by more than 90% of all developers. A few other version control systems in use today include Mercurial, Subversion, Perforce, and Plastic SCM. Many document editors, such as Google Docs and Microsoft Word, also have built-in version control systems. Each of these systems offers a twist on version control, differing sometimes in the area of user functionality, sometimes in how they handle things on the back-end, and sometimes both. In this reader, we’ll focus on Git.\n\n\n2.1.2 First-time Git Configuration\nWhen you save changes to a repository, Git will automatically annotate the changes with your name and email. In collaborative projects, these annotations are important for determining who made which changes. Thus the first time you use Git, you need to set your name and email.\n\n\n\n\n\n\nTip\n\n\n\nAll Git commands begin with git and the name of a subcommand.\nYou can view the documentation for any subcommand by adding --help to the end. For instance, to get help with the git config subcommand used in the next example, run git config --help.\n\n\nTo set your name, open a terminal and type:\ngit config --global user.name \"YOUR_NAME\"\nReplace YOUR_NAME with your name or preferred alias. Then press Enter. To set your email, enter:\ngit config --global user.email \"YOUR_EMAIL\"\nReplace YOUR_EMAIL with your preferred public email address. Git is open-source, community-developed software, so it won’t share your email address with spammers, but your email address will be visible on any changes you make to public repositories.\n\n\n\n\n\n\nTip\n\n\n\nMany developers configure Git to use their real name. This can be beneficial for ensuring you receive credit for any open-source or academic computing work you do while building your career.\nIf you’re not comfortable attaching your real name to work you do with Git, a reasonable alternative is to use an alias you control, such as your GitHub username. Section 2.5 explains more about GitHub.\nLikewise, if you don’t want to attach your primary email address to work you do with Git, set up a new email address and use that. Avoid making up a fake email address, as this will make it impossible for people to contact you and might even allow someone else to take credit for your work.\n\n\nYou can run either of these commands again later to change the name and email address with which Git annotates your work.\nFinally, we suggest that you change the default branch name from master to main. You’ll learn more about what branches are later, but we advise making this change now. For too long the computing industry has relied on offensive terms like “master” and “slave” to describe technology, and changing such terms is part of a wider push to move away from the framework they imply. This is a small change, but we at the DataLab believe that, in all instances, language matters.\nTo make this change, run:\ngit config --global init.defaultBranch main",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#sec-creating-a-repository",
    "href": "chapters/02_version-control.html#sec-creating-a-repository",
    "title": "2  Version Control",
    "section": "2.2 Creating a Repository",
    "text": "2.2 Creating a Repository\nNow that we’ve established what version control systems are, and you’ve configured Git, it’s time to create a repository.\nOpen a terminal and navigate to your home directory:\ncd\nTo initialize a repository called my_first_repository, enter:\ngit init my_first_repository\nGit will reply with a message like:\nInitialized empty Git repository in /home/USERNAME/my_first_repository/.git/\nWhen you run the git init command, Git first checks whether the specified directory (my_first_repository/) exists, and creates it if it doesn’t. Then Git makes the directory a repository by creating a hidden .git/ subdirectory. This subdirectory is where Git will store the history of the repository.\n\n\n\n\n\n\nWarning\n\n\n\nThe .git/ subdirectory is hidden for a reason: generally, you should let Git manage its contents. Avoid creating or modifying files and directories inside .git/, as this might break your repository. If you delete .git/, your repository will no longer be a repository—it will just be an ordinary directory.\n\n\n\n\n\n\n\n\nTip\n\n\n\nHow many repositories to create is up to you, and depends on how you like to work, but we recommend that you create a separate repository for each distinct project.\n\n\nNow let’s check that Git actually recognizes my_first_repository/ as a repository. First, navigate to the directory:\ncd my_first_repository/\nYou can use git status to check the status of a repository. Try running it for the new repository:\ngit status\nSince the directory is a repository, Git will respond with output like:\nOn branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\nWe’ll save branches for a different lesson. Skipping to the second part of the message, Git says that there are no “commits” yet. A commit is a saved snapshot (or version) of the repository. You’ll learn how to make a commit soon, but right now, it makes sense that there are no commits yet, since you just created the repository. Finally, in the third part of the message, Git says that there is nothing to commit. This also makes sense, since we haven’t created any files in the repository yet.\n\n\n\n\n\n\nNote\n\n\n\nWhen Git doesn’t recognize a directory as a repository, the output from git status instead looks like:\nfatal: not a git repository",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#sec-adding-committing-changes",
    "href": "chapters/02_version-control.html#sec-adding-committing-changes",
    "title": "2  Version Control",
    "section": "2.3 Adding & Committing Changes",
    "text": "2.3 Adding & Committing Changes\nLet’s create a new file in the repository called hello.txt. Open a text editor (like nano or vim), enter the following text, and save it as hello.txt:\nHello world!\nNow check the status of the repository again:\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        hello.txt\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nGit notices the new file, hello.txt, and says it’s untracked, which means Git doesn’t have any history for the file. You just created the file and haven’t committed it yet, so it makes sense that there’s no history.\nLet’s commit hello.txt now. The first step is to add the file to Git’s staging area (or index). The staging area is a virtual space for preparing commits, where you can select which files or changes to include in the commit. It might help to imagine the staging area as a box 📦 that you’re packing up to store or to send to a friend. The git add command adds a file or set of changes to the box.\n\n\n\n\n\n\nTip\n\n\n\nPutting distinct work in distinct commits makes it easier to inspect (and occasionally undo) the work. Use git add (and its inverse, git restore --staged or git reset --) to curate the contents of your commits.\n\n\nGo ahead and add hello.txt to the staging area:\ngit add hello.txt\nNow check the status of the repository again:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n        new file:   hello.txt\nNow Git reports that hello.txt is in the staging area and ready to be committed.\nYou can make a commit with the git commit command. Enter the command:\ngit commit\nIn response, Git will open a text editor (typically vim) with the following text:\n\n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n#\n# On branch main\n#\n# Initial commit\n#\n# Changes to be committed:\n#   new file:   hello.txt\n#\nGit will then wait for you to write a commit message, a description of what the commit changes, at the beginning of the text. The first line of the commit message must be a summary of the commit in 72 characters or less. You can also optionally follow this with a blank second line and then a longer description of the commit beginning on the third line.\n\n\n\n\n\n\nNote\n\n\n\nConventionally, the first line of a commit message should be 50 characters or less, a complete sentence, and written in the imperative mood. For example:\nFix typos in the main text.\nFollowing conventions makes it easier for others to understand your work, but there are occasionally situations where doing something else is justified. The best approach is to talk to your collaborators about specific conventions they want to follow, and check in with them about exceptions to the conventions.\n\n\nEdit the first line of the text to look like this:\nAdd first file.\n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n#\n# On branch main\n#\n# Initial commit\n#\n# Changes to be committed:\n#   new file:   hello.txt\n#\nFinally, you can let Git know that you’re done writing the commit message by saving the text and exiting the text editor.\n\n\n\n\n\n\nUsing Vim\n\n\n\n\n\nIn Vim, press i to enter insert mode and type the commit message.\nWhen you’re finished, press Esc to return to normal mode, type :wq (the command to write and quit), and press Enter.\nIf you want to cancel the commit instead, press Esc to return to normal mode, type :q! (the command to quit without saving), and press Enter.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you exit the text editor without saving, Git will cancel the commit.\n\n\nGit will print some output to confirm that the commit was created:\n[main (root-commit) 0f5c79d] Add first file.\n 1 file changed, 1 insertion(+)\n create mode 100644 hello.txt\nImportant details in the output include:\n\nA hash that uniquely identifies the commit (0f5c79d above, but yours will be different)\nThe commit message\nThe number of files changed\nA list of which files were changed (hello.txt in this case)\n\nRun git status to see how the output has changed now that you’ve made a commit:\ngit status\nOn branch main\nnothing to commit, working tree clean\nGit reports that there’s nothing to commit, and that the “working tree” is clean. The working tree consists of the files and directories you actually have in your repository. The working tree is clean if it’s identical to the most recent commit, meaning you haven’t changed anything since that commit.\nTo get more practice making commits, suppose we want to move the file hello.txt to README.md, since README.md is conventionally the first file people read when they start working with an unfamiliar repository. Use the mv shell command to move the file:\nmv hello.txt README.md\nNow check the status of the repository:\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add/rm &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        deleted:    hello.txt\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        README.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nGit notices that hello.txt is gone, and also that there’s a new file README.md. Since README.md is untracked, Git doesn’t recognize that it’s the same file as the old hello.txt. Go ahead and add the changes to README.md to the staging area:\ngit add README.md\nAdd the changes to hello.txt as well:\ngit add hello.txt\nIt might seem counterintuitive to add hello.txt, since it no longer exists. What you should keep in mind is that git add adds changes to the staging area, not files, and moving (or removing) a file is a change to that file.\n\n\n\n\n\n\nImportant\n\n\n\nRemoving/deleting a file is a change to that file, just like creating, editing, or moving the file.\nIf you want to delete a file called FILE from a repository, first delete the file, then run git add FILE to add the change to the staging area, and finally run git commit to make a commit.\nNote that deleted files remain in the repository’s history, so it’s possible to restore them later.\n\n\nNow check the status:\ngit status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        renamed:    hello.txt -&gt; README.md\nAfter adding the changes to both files, Git correctly recognizes that the file was moved/renamed. Go ahead and commit the change with the commit message Move hello.txt to README.md.:\ngit commit\n[main 4f57023] Move hello.txt to README.md.\n 1 file changed, 0 insertions(+), 0 deletions(-)\n rename hello.txt =&gt; README.md (100%)\nIf you check the status now, you’ll see that the working tree is once again clean.\n\n\n\n\n\n\nImportant\n\n\n\nRemember, saving your work in Git is a two step process:\n\ngit add (for each file with changes you want to save)\ngit commit\n\nIt’s also usually a good idea to run git status (and git diff, which we’ll see later) before git commit to check that you’ve added the changes you meant to add to the staging area.\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also make commits without opening a text editor. Use this command:\ngit commit -m \"COMMIT_MESSAGE\"\nReplace COMMIT_MESSAGE with your commit message. You can’t provide a detailed description when you commit this way, so it’s only appropriate for small, simple commits.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#exploring-restoring-history",
    "href": "chapters/02_version-control.html#exploring-restoring-history",
    "title": "2  Version Control",
    "section": "2.4 Exploring & Restoring History",
    "text": "2.4 Exploring & Restoring History\nNow that you’ve made some commits, let’s take a look at the repository’s history. To view the history of commits to a repository, enter the command:\ngit log\ncommit 4f5702364c155faa260080671b63177550347ea0 (HEAD -&gt; main)\nAuthor: YOUR_NAME &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 14:32:21 2025 -0800\n\n    Move hello.txt to README.md.\n\ncommit 0f5c79d0494763a31ade6a2514dd389f3f1eb1b4\nAuthor: YOUR_EMAIL &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 13:59:08 2025 -0800\n\n    Add first file.\n\nFor each commit, the log lists the hash, name and email of the author, the timestamp, and commit message.\n\n\n\n\n\n\nNote\n\n\n\nWhen a repository has a long history, git log will display the commits in a scrolling window. You can use the up and down arrow keys to scroll, and type q (for quit) to return to the terminal.\n\n\nLet’s make one more commit: we’ll add a title to the README.md file. Open the file with a text editor and edit it so that the contents are:\n# My README\n\nHello world!\nWhen you’re finished, save the file. As usual, Git notices that something in the repository has changed:\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   README.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nYou can view the difference, or diff between the working tree and the most recent commit with git diff:\ngit diff\ndiff --git a/README.md b/README.md\nindex cd08755..4e3eb18 100644\n--- a/README.md\n+++ b/README.md\n@@ -1 +1,3 @@\n+# My README\n+\n Hello world!\n\nThe git diff command prints a diff for each file that’s been changed. In each diff, lines added since the last commit are prefixed with +, while lines removed since the last commit are prefixed with -. For context, each diff usually also includes a few lines that didn’t change (no prefix). It’s a good idea to check git diff before adding files to the staging area, so that you know what you’re adding.\n\n\n\n\n\n\nTip\n\n\n\nIf you’ve changed a lot of files, the output from git diff can be overwhelming. You can use the command git diff PATH to view only the changes to the file or directory at PATH.\nYou can also use git diff --staged to see the difference between files in the staging area and the last commit.\nThere are many other ways to use git diff; check the documentation (git diff --help) to learn more.\n\n\nAdd and commit the changes. After you finish, you should have a third commit in the repository history (git log) that looks something like this:\ncommit e15d8c1355f16c26fe00354855c24bff3626fc1b (HEAD -&gt; main)\nAuthor: YOUR_NAME &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 15:35:02 2025 -0800\n\n    Add title.\n\nNow suppose you decide you don’t like the new title in README.md. If you want to change the title to something new, the best approach is to edit the file and make a new commit. On the other hand, if you want to restore an earlier version of the file, manual editing is tedious and error-prone.\nInstead, you can use the git restore --source command to restore a file to how it was in a particular commit.\nTo demonstrate this, let’s restore README.md to how it was in the commit before we added a title. First check git log to get the commit’s hash:\ncommit e15d8c1355f16c26fe00354855c24bff3626fc1b (HEAD -&gt; main)\nAuthor: YOUR_NAME &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 15:35:02 2025 -0800\n\n    Add title.\n\ncommit 4f5702364c155faa260080671b63177550347ea0\nAuthor: YOUR_NAME &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 14:32:21 2025 -0800\n\n    Move hello.txt to README.md.\n\ncommit 0f5c79d0494763a31ade6a2514dd389f3f1eb1b4\nAuthor: YOUR_NAME &lt;YOUR_EMAIL&gt;\nDate:   Wed Jan 8 13:59:08 2025 -0800\n\n    Add first file.\n\nIn this example, the hash begins 4f5702, but it will be different for your commit.\n\n\n\n\n\n\nTip\n\n\n\nAs you can see from git log, the full hash for each commit is quite long. For most Git commands that require a hash, you can just use the first 5-6 digits. Git will let you know if it needs more digits to disambiguate which commit you mean.\n\n\nTo restore README.md to how it was in commit 4f5702, run:\ngit restore --source 4f5702 README.md\nMake sure to replace 4f5702 with the actual hash for your commit.\nAfter running the command, take a look at README.md with your text editor. You should see that it no longer has the title. And if you look at the status of the repository, you’ll see that Git noticed the change:\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   README.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nAs with any other change, you can add and commit this change if you want to save it in the repository’s history.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful with git restore: when you restore a file, any uncommitted changes you’ve made to the file will be erased, and there’s no undo.\nIf you just want to see what a file looked like in a previous commit, use git show HASH:FILE instead, where HASH is the commit’s hash and FILE is the path to the file.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are many other ways to use git restore. For instance, you can use git restore --staged FILE to remove a file from the staging area. To learn more, check the documentation (git restore --help).\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to revert/undo an entire commit, use git revert rather than git restore. Specifically, run:\ngit revert HASH\nReplace HASH with the hash of the commit you want to revert.\nGit reverts a commit by creating a new commit, called a revert commit, with changes exactly the opposite of the original: lines that were added get removed and lines that were removed get added. Because of this, Git will prompt you for a commit message when you run git revert; it’s fine to use the default message.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#sec-github",
    "href": "chapters/02_version-control.html#sec-github",
    "title": "2  Version Control",
    "section": "2.5 GitHub",
    "text": "2.5 GitHub\nUp to this point, you’ve only used Git to work with a single repository local to your computer. As a distributed VCS (Section 2.1.1), one of Git’s major features is that you can share commits between repositories (or copies of a repository).\nFrom the perspective of your repository, other repositories are remote. Remote repositories, or remotes, are typically stored on some other computer connected to yours by a network (such as the Internet).\nGitHub is a hosting service for Git repositories, much like Google Drive and Dropbox are hosting services for files. You don’t have to use GitHub or competing services (such as GitLab and BitBucket) in order to use Git, but doing so provides a convenient way to share, collaborate on, and back up repositories.\nWe’ll use a remote repository hosted on GitHub to demonstrate how to share commits, but all of the Git commands described will work with any remote repository.\n\n\n\n\n\n\nImportant\n\n\n\nRemember that Git and GitHub are different things! Git is a version control system, while GitHub is a hosting service built around Git.\nGitHub also offers an application called GitHub Desktop, which allows users to manage their local repositories with a point-and-click graphical user interface (GUI).\nUltimately, it’s a matter of preference whether you use the GUI or stick with the command line for your own projects, but it’s a good idea to first become proficient at interacting with Git via the command line. The primary reason for this is that not every computer you use will have GitHub Desktop installed—or even have graphics! Many computing servers offer command line-only access, and if you ever want to use Git repositories on these machines, you’ll need to do so without GitHub Desktop.\n\n\n\n2.5.1 Making an Account\nTo use GitHub, you need to make a (free) account. Go to GitHub and click “Sign Up” in the top-right corner of the page. This should take you to a form, which asks you to enter a username, email address, and password. After you’ve entered in this information (and completed a quick CAPTCHA), GitHub will make you an account. Then, the site will prompt you to complete an optional survey. Fill it out, or scroll to the bottom to skip it.\nEither way, you’ll need to then verify your email address. Go to your inbox and look for an email from GitHub. Click the “Verify email address” button. Doing so will take you to your profile, where, if you’d like, you can add a few details about yourself.\n\nYou now have a GitHub account! 🎉\n\n\n2.5.2 Connecting to GitHub with SSH\nTo connect to GitHub from the command line, you must have a GitHub account and a way to authenticate, or establish your identity (prove that you are who you say you are). GitHub requires authentication as a security measure, so that individuals and teams can control who has access to their repositories.\nYou can establish your identity with an SSH key, a kind of cryptographic key. An SSH key consists of two separate key files:\n\nA public key file which can be used to encrypt data. The public key is meant to be freely shared, so that people (or servers) can encrypt data they want to securely send to you.\nA private key file which can be used to decrypt data that was encrypted with the associated public key. The private key is meant for you alone, so that only you can decrypt and use data that people send to you. Never share your private key with anyone else.\n\nSSH keys are much more secure than passwords, which is one reason why GitHub uses them for authentication.\n\n\n\n\n\n\nNote\n\n\n\nSSH stands for secure shell protocol, a protocol for communication between two computers. The “secure” in secure shell means that all messages sent between the computers are encrypted. This makes it practically impossible for a third party to see what’s being sent.\nGit uses SSH to connect GitHub. Git can also use SSH to connect to other servers hosting repositories.\n\n\nGitHub provides detailed documentation about how to create an SSH key and add the public key to your GitHub account. Work through the following sections of the documentation to set up SSH key authentication with GitHub:\n\nChecking for existing SSH keys\nGenerating a new SSH key and adding it to the ssh-agent\nAdding a new SSH key to your GitHub account\nTesting your SSH connection\n\n\n\n\n\n\n\nImportant\n\n\n\nDon’t skip this part—it’s necessary if you want to follow along with the subsequent examples.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#sec-sharing-a-repository",
    "href": "chapters/02_version-control.html#sec-sharing-a-repository",
    "title": "2  Version Control",
    "section": "2.6 Sharing a Repository",
    "text": "2.6 Sharing a Repository\nWith a GitHub account and SSH key set up, you’re ready to upload your first shared repository to GitHub.\nTo get started, open a terminal and navigate to your home directory:\ncd\nInitialize a new Git repository called USERNAME_first_shared_repo (replace USERNAME with your GitHub username):\ngit init USERNAME_first_shared_repo\nIn the repository, use a text editor to create a README.md file with contents Hello world!. It should look something like this:\n\nCommit README.md and write a descriptive commit message like `Add a README.”\nSo far so good! These steps should be familiar from Section 2.2 and Section 2.3. But now it’s time to do something new: we need to set up a repository on GitHub where we can push, or send, commits from the local repository.\nOpen a web browser and go to GitHub. Make sure you’re logged in, then click the “+” button in the upper-right corner and select the “New repository” option. You’ll be taken to a page like this:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nThe page asks for several details about the new repository:\n\nA name for the repository\nA short (1-2 sentence) description of what’s in the repository\nWhether the repository should be public (viewable by anyone) or private (viewable only by you and those you grant access)\nWhether the repository should be initalized with:\n\nA README file, to describe your project to others.\nA .gitignore file, to tell Git to ignore specific files or directories.\nA license, to governs the use or redistribution of your files\n\n\nFor this example, give the repository the same name as the one you just created on your computer (USERNAME_first_shared_repo, replacing USERNAME with your GitHub username). Leave the description blank and make sure the repository is public. Because you already initialized the repository locally, leave all of the initialization options unchecked. It should look something like this:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nOnce you’ve filled in the details, click the green “Create repository” button at the bottom of the page.\nGitHub will take you to a new page with “Quick setup” and instructions to “create a new repository on the command line” or “push an existing repository from the command line.” The page should look something like this:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nUnder “Quick setup,” click on the “SSH” button, so that the instructions show how to connect to GitHub with SSH. Since we already created a repository locally, we need to use the “push an existing repository from the command line” instructions.\nOpen a terminal, navigate to the repository you created earlier, and then run the commands listed on the page. In the screenshot above, these are:\ngit remote add origin git@github.com:nick-ulle/nick-ulle_first_shared_repo.git\ngit branch -M main\ngit push -u origin main\nThe first command, git remote add, will look slightly different for you, since your GitHub username is probably not nick-ulle. This command tells Git where to find the repository on GitHub, and to call it origin.\nThe second command, git branch, ensures that the default branch is called main.\nFinally, the third command, git push, pushes the contents of the local repository to the repository on GitHub (origin). You should see some output like:\nEnumerating objects: 3, done.\nCounting objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 1.39 KiB | 1.39 MiB/s, done.\nTotal 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nTo github.com:nick-ulle/nick-ulle_first_shared_repo.git\n * [new branch]      main -&gt; main\nbranch 'main' set up to track 'origin/main'.\nFrom now on, when you want to push commits from this repository to GitHub, you can simply run git push (without any arguments).\nNow go back to your web browser and refresh the repository’s page on GitHub. You should now see the message in your README.md file:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nGitHub automatically checks for a README file in your repository and if it finds one, displays it on the repository’s main page. If the README file is written in Markdown, GitHub will even render the formatting.\n\n\n\n\n\n\nSee also\n\n\n\nMore information about writing effective README files is available through the DataLab’s README, Write Me! workshop.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#collaborating",
    "href": "chapters/02_version-control.html#collaborating",
    "title": "2  Version Control",
    "section": "2.7 Collaborating",
    "text": "2.7 Collaborating\n\n\n\n\n\n\nImportant\n\n\n\nFor this this part, you’ll need to work with a partner. Take a moment to find a partner and exchange GitHub usernames. Pay careful attention to the spelling and capitalization.\n\n\nYou now know how to push commits from a local repository to a remote. The counterpart to this is pulling, or downloading, commits from a remote to a local repository. In order to learn how to collaborate on repositories and how to pull commits, let’s share the repository from Section 2.6 with a partner. Then they can push a change up to GitHub, and you can pull the change down to your local repository.\nTo get started, open a web browser to your repository’s main page on GitHub. Click on the “Settings” button. You’ll be taken to a page that looks like this:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nOn the left side, click on “Collaborators”. GitHub might ask you to enter your password or complete two-factor authentication. Once you’ve done that, you’ll end up at a page like this:\n\n\n\n\n\n\n\n(click image to enlarge)\n\n\nClick on the green “Add people” button near the bottom of the page, then enter your partner’s GitHub username in the popup that appears. Then tell your partner to check their email (the one they used to register with GitHub) for an invitation to collaborate on your repository.\nAfter you and your partner have each accepted the invitation to the other’s repository, open the main page of your partner’s repository in your web browser. In order to make and commit changes, you first need to clone—download a copy of—their repository to your computer. Click on the green “Code” button on their repository’s main page, select the “Local” tab, and select “SSH”. Then copy the listed URL to your clipboard. It will look something like this:\ngit@github.com:tshoemaker/tshoemaker_first_shared_repo.git\nThe URL will have your partner’s GitHub username rather than tshoemaker.\nNext, open a terminal and navigate to your home directory:\ncd\nThen use the git clone command to clone a copy of your partner’s repository. You’ll need to paste the URL you copied to the end of the command:\ngit clone git@github.com:tshoemaker/tshoemaker_first_shared_repo.git\nCloning into 'tshoemaker_first_shared_repo'...\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\nReceiving objects: 100% (3/3), done.\nGit will display some details about what it cloned from the remote repository.\nYou should now see a copy of your partner’s repository in your home directory. In the repository, open README.md with a text editor, add a short message for your partner, and save the changes. Then add, commit, and push your changes.\nPause here to check in with your partner. Confirm that they can see the commit you made on their repository’s GitHub page, and check that you can see the commit they made on your repository’s GitHub page. If anything doesn’t seem right, try working through the steps again.\nFinally, it’s time to pull the commit your partner made to your repository on GitHub down to your local repository. Open a terminal again and navigate to your repository. Then run git pull:\ngit pull\nGit should print output that looks something like this:\nremote: Enumerating objects: 5, done.\nremote: Counting objects: 100% (5/5), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nUnpacking objects: 100% (3/3), 918 bytes | 918.00 KiB/s, done.\nFrom github.com:nick-ulle/nick-ulle_first_shared_repo\n   c4bae61..260a2b4  main       -&gt; origin/main\nUpdating c4bae61..260a2b4\nFast-forward\n README.md | 1 +\n 1 file changed, 1 insertion(+)\nAfter pulling the commit, inspect the README.md file with a text editor to confirm that it now contains the message from your partner. If it does, congratulations! You’ve successfully used Git and GitHub to collaborate with someone.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/02_version-control.html#recap",
    "href": "chapters/02_version-control.html#recap",
    "title": "2  Version Control",
    "section": "2.8 Recap",
    "text": "2.8 Recap\n\nAs shown in the figure above, a typical Git workflow is:\n\nMake some changes to the local repository.\nStage your changes with git add.\nCommit your changes with git commit.\nPush the changes up to the remote with git push.\nRepeat steps 1-4 until the project is finished.\n\nThere are lots of steps in this process, so there are lots of places where it can go wrong. Pay attention to error messages and search online if you get stuck. Lots of people use Git, and your question has probably been asked and answered :)\n\n\n\n\n\n\nSee also\n\n\n\nThe Git Book is the definitive Git resource and an excellent reference to keep at hand as you begin to work with Git after finishing this reader.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Version Control</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html",
    "href": "chapters/03_r-intro.html",
    "title": "3  Introduction to R",
    "section": "",
    "text": "3.1 Getting Started",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#getting-started",
    "href": "chapters/03_r-intro.html#getting-started",
    "title": "3  Introduction to R",
    "section": "",
    "text": "3.1.1 What are R and RStudio?\n\nR is both a free and open source programming language designed for statistical computing and graphics, and the software for interpreting the code written in the R language.\nRStudio is an integrated development environment (IDE) within which you can write and execute code, and interact with the R software. It’s an interface for working with the R software that allows you to see your code, plots, variables, etc. all on one screen. This functionality can help you work with R, connect it with other tools, and manage your workspace and projects. You don’t need RStudio to use R, but many people find that using RStudio makes writing, editing, searching and running their code easier. You cannot run RStudio without having R installed. While RStudio is a commercial product, the free version is sufficient for most researchers.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou can download R for free here.\nYou can download RStudio Desktop Open-Source Edition for free here.\n\n\n\n\n3.1.2 Why Learn R?\nThere are many advantages to working with R:\n\nScientific integrity. Working with a scripting language like R facilitates reproducible research. Having the commands for an analysis captured in code promotes transparency and reproducibility. Someone using your code and data should be able to exactly reproduce your analyses. An increasing number of research journals not only encourage, but are beginning to require, submission of code along with a manuscript.\nMany data types and sizes. R was designed for statistical computing and thus incorporates many data structures and types to facilitate analyses. It can also connect to local and cloud databases.\nGraphics. R has built-in plotting functionalities that allow you to adjust any aspect of your graph to effectively tell the story of your data.\nOpen and cross-platform. Because R is free, open-source software that works across many different operating systems, anyone can inspect the source code, and report and fix bugs. It is supported by a large community of users and developers.\nInterdisciplinary and extensible. Because anyone can write and share R packages, it provides a framework for integrating approaches across domains, encouraging innovation.\n\n\n\n3.1.3 Navigating the Interface\nThe first time you open RStudio, you’ll see a window divided into several panes, like this:\n\nThe exact presentation of the panes might be slightly different depending on your operating system, versions of R and RStudio, and any set preferences. Generally, the panes include:\n\nSource is your script. You can write your code here and save this as a .R file and re-run to reproduce your results.\nConsole is where you run the code. You can type directly here, but anything entered here won’t be saved when you exit RStudio.\nEnvironment/history lists all the objects you have created (including your data) and the commands you have run.\nFiles/plots/packages/help/viewer pane is useful for locating files on your machine to read into R, inspecting any graphics you create, seeing a list of available packages, and getting help.\n\nTo interact with R, compose your code in the source pane and use the execute (or run) command to send them to the console.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the keyboard shortcut Ctrl + Enter (on macOS: Cmd + Enter) to run a line of code.\nFor more keyboard shortcuts, see the official RStudio Cheatsheet.\n\n\nIn your ~/ist008/ directory, create a lecture03/ directory for today’s lecture. Then create a new R script and save it in the lecture03/ directory.\n\n\n\n\n\n\nTip\n\n\n\nIt’s a good habit to make a new directory for every project or lecture.\nFor projects, some useful subdirectories to create are:\n\ndata/ to store data sets\ndocs/ to store documents\noutputs/ to store outputs such as plots and cleaned data sets\nR/ to store R code",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#mathematical-operations",
    "href": "chapters/03_r-intro.html#mathematical-operations",
    "title": "3  Introduction to R",
    "section": "3.2 Mathematical Operations",
    "text": "3.2 Mathematical Operations\nR runs as a read-evaluate-print loop, or REPL. This means:\n\nR waits until you type an expression (a single piece of code) and press Enter, then reads and parses what you typed, checking whether it is a syntactically valid expression.\nR evaluates the expression, computing the result.\nR prints the result in the R console.\nFinally, R loops back to step 1 to wait for your next expression.\n\nYou can use R like a calculator to see how it processes expressions:\n\n7 + 2\n\nR always puts the result on a separate line (or lines) from your code.\n\n\n\n\n\n\nNote\n\n\n\nIn this case, the result begins with the tag [1], which is a hint from R that the result is a vector and that this line starts with the element at position 1. We’ll learn more about vectors later in this lesson, and eventually learn about other data types that are displayed differently.\n\n\nIf you enter an incomplete expression, R will get stuck at the evaluate step and change the prompt to +, then wait for you to type the rest of the expression and press the Enter key. If this happens, you can finish entering the expression on the new line, or you can cancel it by pressing the Esc key (or Ctrl + c if you’re using R without RStudio). R can only tell an expression is incomplete if it’s missing something that it is expecting, like the second operand here:\n\n7 -\n\nError in parse(text = input): &lt;text&gt;:2:0: unexpected end of input\n1: 7 -\n   ^\n\n\nLet’s do more math! Other arithmetic operators are:\n\n- for subtraction\n* for multiplication\n/ for division\n%% for remainder division (modulo)\n^ or ** for exponentiation\n\n\n7 - 2\n244/12\n2 * 12\n\nArithmetic in R follows an order of operations (aka PEMDAS): parenthesis, exponents, multiplication and division, addition and subtraction. You can combine these and use parentheses to make more complicated expressions, just as you would when writing a mathematical expression.\nFor example, to estimate the area of a circle with radius 3, you can write:\n\n3.14 * 3^2\n\n[1] 28.26\n\n\nTo see the complete order of operations, use the help command:\n\n?Syntax\n\nYou can also perform other operations in R:\n\n3 &gt; 1\n3 &lt; 1\n\n\n\n\n\n\n\nTip\n\n\n\nYou can write R expressions with any number of spaces (including none) around the operators and R will still compute the result. Nevertheless, putting spaces in your code makes it easier for you and others to read, so it’s good to make it a habit. Put spaces around most operators, after commas, and after keywords.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#variables",
    "href": "chapters/03_r-intro.html#variables",
    "title": "3  Introduction to R",
    "section": "3.3 Variables",
    "text": "3.3 Variables\nSince R is designed for mathematics and statistics, you might expect that it provides a better approximation for \\(\\pi\\) than 3.14. R and most other programming languages allow you to create and store values called variables. Variables allow you to reuse the result of a computation, write general expressions (such as a*x + b), and break up your code into smaller steps so it’s easier to test and understand.\nR has a built in variable called ‘pi’ for the value of \\(\\pi\\). You can display a variable’s value by entering its name in the console:\n\npi\n\nYou can also use variables in mathematical expressions. Here’s a more precise calculation of the area of a circle with radius 3:\n\npi *3^2\n\nYou can define your own variables with the assignment operator ‘=’ or ‘&lt;-’. Variable names can contain letters, numbers, dots ., and underscores _, but they cannot begin with a number. Spaces and other symbols are not allowed in variable names. In general, variable names should be descriptive but concise, and should not use the same name as common (base R) functions like mean, T, median, sum, etc..\nLet’s make some more variables:\n\nx &lt;- 10\ny &lt;- 24\nfantastic.variable2 = x\nx &lt;- y / 2\n\nIn R, variables are copy-on-write. When we change a variable (“write”), R automatically copies the original value so dependent variables are unchanged until they are re-run.\n\nx &lt;- 13\ny &lt;- x\nx &lt;- 16\ny\n\nWhy do you think copy-on-write is helpful? Where do you think it could trip you up?",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#sec-calling-functions",
    "href": "chapters/03_r-intro.html#sec-calling-functions",
    "title": "3  Introduction to R",
    "section": "3.4 Calling Functions",
    "text": "3.4 Calling Functions\nR has many functions (reusable commands) built-in that allow you to compute mathematical operations, statistics, and perform other computing tasks on your variables. You can think of a function as a machine that takes some inputs and uses them to produce some output. Code that uses a function is said to call that function. When you call a function, the values that you assign as input are called arguments. The output is called the return value.\nWe call a function by writing its name followed by a parentheses containing the arguments.\n\nlog(10)\nsqrt(9)\n\nMany functions have multiple parameters and can accept multiple arguments. For example, the sum function accepts any number of arguments and adds them all together. When you call a function with multiple arguments, separate the arguments with commas.\n\nsum(5, 4, 1)\n\nWhen you call a function, R assigns each argument to a parameter. Parameters are special variables that represent the inputs to a function and only exist while that function runs. For example, the log function, which computes a logarithm, has parameters x and base for the operand and base of the logarithm, respectively.\nBy default, R assigns arguments to parameters based on their order. The first argument is assigned to the function’s first parameter, the second to the second, and so on. If you know the order that a function expects to receive the parameters then you can list them separated by commas. Here the argument 64 is assigned to the parameter x, and the argument 2 is assigned to the parameter base.\n\nlog(64, 2)\n\nYou can also assign arguments to parameters by name with = (but not with &lt;-), overriding their positions.\n\nlog(64, base = 2)\nlog(base = 2, x= 64)\n\n\n\n\n\n\n\nTip\n\n\n\nBoth of these expressions are equivalent, so which one should you use? When you write code, choose whatever seems the clearest to you. Leaving parameter names out of calls saves typing, but including some or all of them can make the code easier to understand.\n\n\nNot sure what parameters a specific function needs? Read on for how to get…",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#help",
    "href": "chapters/03_r-intro.html#help",
    "title": "3  Introduction to R",
    "section": "3.5 HELP!",
    "text": "3.5 HELP!\nThis is just the beginning, and there are lots of resources to help you learn more. R has built-in help files that can be accessed with the ? and help commands. You can also search within the help documentation using the ?? command. There’s also a vibrant online help community. Here are some examples of how you can use all this help to help yourself:\n? The help pages for all of R’s built-in functions usually have the same name as the function itself. Function help pages usually include a brief description, a list of parameters, a description of the return value, and some examples. To open the help page for the log function:\n\n?log\n\nThere are also help pages for other topics, such as built-in mathematical constants (such as ?pi), data sets (such as ?cars), and operators. To look up the help page for an operator, put the operator’s name in single or double quotes. For example, this code opens the help page for the arithmetic operators:\n\n?\"+\"\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s always okay to put single or double quotes around the name of the page when you use ?, but they’re only required if it contains arithmetic commands or non-alphabetic characters. So ?sqrt, ?'sqrt', and ?\"sqrt\" all open the documentation for sqrt, the square root function. Why does this work? R treats anything inside single or double quotes as literal text rather than as an expression to evaluate.\nIn programming jargon, a piece of literal text is called a string. You can use whichever kind of quotes you prefer, but the quote at the beginning of the string must match the quote at the end. We’ll learn more about strings in later lessons when we cover working with unstructured data.\n\n\n?? Sometimes you might not know the name of the help page you want to look up. You can do a general search of R’s help pages with ?? followed by a string of search terms. For example, to get a list of all help pages related to linear models:\n\n??\"linear model\"\n\nThis search function doesn’t always work well, and it’s often more efficient to use an online search engine. When you search for help with R online, include “R” as a search term. Alternatively, you can use RSeek, which restricts the search to a selection of R-related websites.\nIn later lessons we’ll learn about packages, which are sharable bundles of code. You’ll often need to look up the documentation to get help figuring out how to work with a new package. You can view a package’s help documentation using packageDescription(\"Name\").\n\n3.5.1 When Something Goes Wrong (and it will)\nSooner or later you’ll run some code and get an error message or result you didn’t expect. Don’t panic! Even experienced programmers make mistakes regularly, so learning how to diagnose and fix problems is vital. We call this troubleshooting or debugging.\nStay calm and try going through these steps:\n\nIf R returned a warning or error message, read it! If you’re not sure what the message means, try searching for it online.\nCheck your code for typ0s. Did you capitalize something that should be lower case? Are you missing or have an extra comma, quote, parenthesis?\nTest your code one line at a time, starting from the beginning. After each line that assigns a variable, check that the value of the variable is what you expect. Try to determine the exact line where the problem originates (which may differ from the line that emits an error!). Sometimes the “shut it down and restart” trick really works—you might have created a variable and forgot about it, and you need a fresh start for the code to work as intended.\n\nIf all else fails, just Google it. Stack Overflow is a popular question and answer website and you can often find solutions to your problems there, or pick up tips to help you tackle your problem in a new way. On CRAN, check out the Intro to R Manual and R FAQ. Many regions also have grassroots R-Users Groups that you can join and ask for help. Just remember to pay it forward and use your new found R prowess to help others in the community on their learning journeys!\n\n\n\n\n\n\nTip\n\n\n\nWhen asking for help, clearly state the problem and provide a reproducible example. Take a look at StackOverflow’s How do I ask a good question? guide and R’s Posting guide before you write your first question. These guides will help you write questions that are more likely to get a useful reply.\nIt’s also a good idea to save your sessionInfo() so you can show others how your machine and session was configured. Doing this before coming to office hours for a programming class is also highly recommended!",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#sec-vectors",
    "href": "chapters/03_r-intro.html#sec-vectors",
    "title": "3  Introduction to R",
    "section": "3.6 Vectors",
    "text": "3.6 Vectors\nA vector is an ordered collection of values. The values in a vector are called elements. Vectors can have any number of elements, including 0 or 1 element. For example, a single value, like 3, is a vector with 1 element. So every value that you’ve worked with in R so far was a vector.\nThe elements of a vector must all be the same type of data (we say the elements are homogeneous). A vector can contain integers, decimal numbers, strings (text), or several other types of data, but not a mix these all at once.\nYou can combine or concatenate vectors to create a longer vector with the c function:\n\n# numbers\ntime.min &lt;- c(5, 4, 4, 12, 10, 2, 3, 4, 4, 5, 19)\n\n# strings\npets &lt;- c(\"woof\", \"woof\", \"cat\", \"woof\", \"woof\", \"cat\", \"woof\", \"woof\", \"woof\",\n  \"woof\", \"woof\")\nplace &lt;- c(\"Temple\", \"Yakitori\", \"Panera\", \"Yakitori\", \"Guads\", \"Home\",\n  \"Tea List\", \"Raising Canes\", \"Pachamama\", \"Lazi Cow\", \"Wok of Flame\")\n\nYou can check the length of a vector (and other objects) with the length function:\n\nlength(3)\n\n[1] 1\n\nlength(\"hello\")\n\n[1] 1\n\nlength(time.min)\n\n[1] 11\n\nlength(pets)\n\n[1] 11\n\n\n\n3.6.1 Indexing Vectors\nVectors are ordered, which just means the elements have specific positions. For example, in the place vector, the value of the 1st element is \"Temple\", the 2nd is \"Yakitori\", the 5th is \"Guads\", and so on.\nYou can access individual elements of a vector with the indexing operator [ (also called the square bracket operator). The way to write it, or syntax is:\nVECTOR[INDEXES]\nHere INDEXES is a vector of positions of elements you want to get or set.\nFor example, let’s get the 2nd element of the place vector:\n\nplace[2]\n\n[1] \"Yakitori\"\n\n\nNow let’s get the 3rd and 1st element:\n\nplace[c(3, 1)]\n\n[1] \"Panera\" \"Temple\"\n\n\nIndexing is among the most frequently used operations in R, so take some time to try it out with few different vectors and indexes. We’ll revisit indexing in a later lesson to learn a lot more about it.\n\n\n3.6.2 Vectorization\nLet’s look at what happens if we call a mathematical function, like sqrt, on a vector:\n\nx &lt;- c(2, 16, 4, 7)\nsqrt(x)\n\n[1] 1.414214 4.000000 2.000000 2.645751\n\n\nThis gives us the same result as if we had called the function separately on each element. That is, the result is the same as:\n\nc(sqrt(2), sqrt(16), sqrt(4), sqrt(7))\n\n[1] 1.414214 4.000000 2.000000 2.645751\n\n\nOf course, the first version is much easier to type.\nFunctions that take a vector argument and get applied element-by-element are called vectorized functions. Most functions in R are vectorized, especially math functions. Some examples include sin, cos, tan, log, exp, and sqrt.\nA function can be vectorized across multiple arguments. This is easiest to understand in terms of the arithmetic operators. Let’s see what happens if we add two vectors together:\n\nx = c(1, 2, 3, 4)\ny = c(-1, 7, 10, -10)\nx + y\n\n[1]  0  9 13 -6\n\n\nThe elements are paired up and added according to their positions. The other arithmetic operators are also vectorized:\n\nx - y\n\n[1]  2 -5 -7 14\n\nx * y\n\n[1]  -1  14  30 -40\n\nx / y\n\n[1] -1.0000000  0.2857143  0.3000000 -0.4000000\n\n\nNote that if you are trying to run vectorized operations on vectors of different lengths, the values of the shorter vector will be recycled. For example, if we create a vector z with only three values, and try to add it to x, which has four values, we get the following result.\n\nz = c(-1, 7, 10)\nx + z\n\nWarning in x + z: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  0  9 13  3\n\n\nFirst, we get a warning, which lets us know that these vectors are not the same length. But we still get a result, which manages to make a calculation for the fourth value. To get this fourth value, R recycles the shorter vector z by going back to its first element, -1, and using that to add to the fourth element in x (4). Thus our result is x[4] + z[1] = 4 (or -1 + 3 = 4). This is something to be cautious of, because if values are recycled inadvertently, we’ll have errors in our results.\nFunctions that are not vectorized tend to be ones that combine or aggregate values in some way. For instance, the sum, length, and class functions are not vectorized.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#sec-data-frames",
    "href": "chapters/03_r-intro.html#sec-data-frames",
    "title": "3  Introduction to R",
    "section": "3.7 Data Frames",
    "text": "3.7 Data Frames\nWe frequently work with 2-dimensional tables of data (also called tabular data). Typically each row corresponds to a single subject and is called an observation. Each column corresponds to a measurement of the subject.\nIn data science, the columns of a table are called features or covariates. Sometimes people also refer to them as “variables”, but that can be confusing as “variable” means something else in R, so here we’ll try to avoid that term.\nR’s structure for tabular data is the data frame. The columns are vectors, so the elements within a column must all be the same type of data. In a data frame, every column must have the same number of elements (so the table is rectangular). There are no restrictions on the data types in each row.\nYou can use the data.frame function to create a data frame from column vectors:\n\n# current data (vectors)\ntime.min\nplace\npets\n\n# create new data (vectors)\ndistance.mi &lt;- c(0.9, 0.6, 0.8, 0.6, 2, 100, 0.6, 0.7, 0.8, 1, 3.7)\n\nmajor &lt;- c(\"chicanix studies\", \"human development\", \"economics\", \"undeclared\",\n  \"psychology\", \"MMM\", \"psychology\", \"undeclared\", \"human development\",\n  \"undeclared\", \"GG\")\n\n# combine vectors into dataframe\nmy.data &lt;- data.frame(place, distance.mi, time.min, major, pets)\n\n\n3.7.1 Selecting Columns\nYou can select an individual column from a data frame by name with $, the dollar sign operator. The syntax is:\n\nVARIABLE$COLUMN_NAME\n\nFor instance, to select the place column:\n\nmy.data$place\n\n [1] \"Temple\"        \"Yakitori\"      \"Panera\"        \"Yakitori\"     \n [5] \"Guads\"         \"Home\"          \"Tea List\"      \"Raising Canes\"\n [9] \"Pachamama\"     \"Lazi Cow\"      \"Wok of Flame\" \n\n\nThe selected column is just a vector, so you can assign it to a variable and use it in functions. For example, to compute the sum of the distance.mi column:\n\nsum(my.data$distance.mi)\n\n[1] 111.7\n\n\n\n\n\n\n\n\nNote\n\n\n\nPreview of future lesson content: what if you want to extract a row from your data frame?\nFor example, to pull out all responses from only the 11th row, you would subset it:\n\nmy.data[11, ]\n\n\n\n\n\n3.7.2 Inspecting Data\nYou can print a small dataset, but it can be slow and hard to read especially if there are a lot of columns. R has many built in functions to inspect objects:\n\n\n\nExpression\nDescription\n\n\n\n\nhead\nGet only the beginning of the data set.\n\n\ntail\nGet only the end of the data set.\n\n\nnrow\nGet the number of rows.\n\n\nncol\nGet the number of columns.\n\n\nls\nGet the names of the columns in alphabetical order.\n\n\nnames\nGet the names of the columns in their actual order.\n\n\nrownames\nGet the names of the rows.\n\n\n\nA highly informative function for inspecting the structure of a data frame or other object is str:\n\nstr(my.data)\n\nThe table function is another useful function for inspecting data. The table function computes the frequency of each unique value in a vector. For instance, you can use table to compute how many entries in the pets column are woof:\n\ntable(my.data$pets)\n\n\n cat woof \n   2    9 \n\n\n\n\n\n\n\n\nSee also\n\n\n\nCheck out DataLab’s Keeping Your Data Tidy workshop, which covers best practices for structuring, naming, and organizing your data frames (and spreadsheets).",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/03_r-intro.html#sec-data-types-classes",
    "href": "chapters/03_r-intro.html#sec-data-types-classes",
    "title": "3  Introduction to R",
    "section": "3.8 Data Types & Classes",
    "text": "3.8 Data Types & Classes\nData can be categorized into different types based on sets of shared characteristics. For instance, statisticians tend to think about whether data are numeric or categorical:\n\nnumeric\n\ncontinuous (real or complex numbers)\ndiscrete (integers)\n\ncategorical\n\nnominal (categories with no ordering)\nordinal (categories with some ordering)\n\n\nOf course, other types of data, like graphs (networks) and natural language (books, speech, and so on), are also possible. Categorizing data this way is useful for reasoning about which methods to apply to which data.\nIn R, data objects are categorized in two different ways:\n\nThe class of an R object describes what the object does, or the role that it plays. Sometimes objects can do more than one thing, so objects can have more than one class. The class function returns the classes of its argument.\nThe type of an R object describes what the object is. Technically, the type corresponds to how the object is stored in your computer’s memory. Each object has exactly one type. The typeof function returns the type of its argument.\n\nOf the two, classes tend to be more important than types. If you aren’t sure what an object is, checking its classes should be the first thing you do.\nThe built-in classes you’ll use all the time correspond to vectors and lists (which we’ll learn more about in Section 3.8.1):\n\n\n\n\n\n\n\n\nClass\nExample\nDescription\n\n\n\n\nlogical\nTRUE, FALSE\nLogical (or Boolean) values\n\n\ninteger\n-1L, 1L, 2L\nInteger numbers\n\n\nnumeric\n-2.1, 7, 34.2\nReal numbers\n\n\ncomplex\n3-2i, -8+0i\nComplex numbers\n\n\ncharacter\n\"hi\", \"YAY\"\nText strings\n\n\nlist\nlist(TRUE, 1, \"hi\")\nOrdered collection of heterogeneous elements\n\n\n\nThe class of a vector is the same as the class of its elements:\n\nclass(\"hi\")\n\n[1] \"character\"\n\nclass(c(\"hello\", \"hi\"))\n\n[1] \"character\"\n\n\nIn addition, for ordinary vectors, the class and the type are the same:\n\nx &lt;- c(TRUE, FALSE)\nclass(x)\n\n[1] \"logical\"\n\ntypeof(x)\n\n[1] \"logical\"\n\n\nThe exception to this rule is numeric vectors, which have type double for historical reasons:\n\nclass(pi)\n\n[1] \"numeric\"\n\ntypeof(pi)\n\n[1] \"double\"\n\ntypeof(3)\n\n[1] \"double\"\n\n\nThe word “double” here stands for double-precision floating point number, a standard way to represent real numbers on computers.\nBy default, R assumes any numbers you enter in code are numeric, even if they’re integer-valued.\nThe class integer also represents integer numbers, but it’s not used as often as numeric. A few functions, such as the sequence operator : and the length function, return integers. The difference between numeric and integer is generally not important.\n\nclass(3)\n\n[1] \"numeric\"\n\nclass(length(pets))\n\n[1] \"integer\"\n\nclass(1:3)\n\n[1] \"integer\"\n\n\nBesides the classes for vectors and lists, there are several built-in classes that represent more sophisticated data structures:\n\n\n\n\n\n\n\nClass\nDescription\n\n\n\n\nfunction\nFunctions\n\n\nfactor\nCategorical values\n\n\nmatrix\nTwo-dimensional ordered collection of homogeneous elements\n\n\narray\nMulti-dimensional ordered collection of homogeneous elements\n\n\ndata.frame\nData frames\n\n\n\nFor these, the class is usually different from the type. We’ll learn more about most of these later on.\n\n3.8.1 Lists\nA list is an ordered data structure where the elements can have different types (they are heterogeneous). This differs from a vector, where the elements all have to have the same type, as we saw in Section 3.6. The tradeoff is that most vectorized functions do not work with lists.\nYou can make an ordinary list with the list function:\n\nx &lt;- list(1, c(\"hi\", \"bye\"))\nclass(x)\n\n[1] \"list\"\n\ntypeof(x)\n\n[1] \"list\"\n\n\nFor ordinary lists, the type and the class are both list. In a later lesson, we’ll learn how to get and set list elements, and more about when and why to use lists.\nYou’ve already seen one list, the my.data data frame:\n\nclass(my.data)\n\n[1] \"data.frame\"\n\ntypeof(my.data)\n\n[1] \"list\"\n\n\nUnder the hood, data frames are lists, and each column is a list element. Because the class is data.frame rather than list, R treats data frames differently from ordinary lists. For example, R prints data frames differently from ordinary lists.\n\n\n3.8.2 Implicit Coercion\nR’s types fall into a natural hierarchy of expressiveness:\n\nEach type on the right is more expressive than the ones to its left.\nFor example, with the convention that FALSE is 0 and TRUE is 1, we can represent any logical value as an integer. In turn, we can represent any integer as a double, and any double as a complex number. By writing the number out, we can also represent any complex number as a string.\nThe point is that no information is lost as we follow the arrows from left to right along the types in the hierarchy. In fact, R will automatically and silently convert from types on the left to types on the right as needed. This is called implicit coercion.\nAs an example, consider what happens if we add a logical value to a number:\n\nTRUE + 2\n\n[1] 3\n\n\nR automatically converts the TRUE to the numeric value 1, and then carries out the arithmetic as usual.\nWe’ve already seen implicit coercion at work once before, when we learned the c function. Since the elements of a vector all have to have the same type, if you pass several different types to c, then R tries to use implicit coercion to make them the same:\n\nx &lt;- c(TRUE, \"hi\", 1, 1+3i)\nclass(x)\n\n[1] \"character\"\n\nx\n\n[1] \"TRUE\" \"hi\"   \"1\"    \"1+3i\"\n\n\nImplicit coercion is strictly one-way; it never occurs in the other direction. If you want to coerce a type on the right to one on the left, you can do it explicitly with one of the as.TYPE functions. For instance, the as.numeric (or as.double) function coerces to numeric:\n\nas.numeric(\"3.1\")\n\n[1] 3.1\n\n\nThere are a few types that fall outside of the hierarchy entirely, like functions. Implicit coercion doesn’t apply to these. If you try to use these types where it doesn’t make sense to, R generally returns an error:\n\nsin + 3\n\nError in sin + 3: non-numeric argument to binary operator\n\n\nIf you try to use these types as elements of a vector, you get back a list instead:\n\nx &lt;- c(1, 2, sum)\nclass(x)\n\n[1] \"list\"\n\n\nUnderstanding how implicit coercion works will help you avoid bugs, and can also be a time-saver.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapters/04_programming-foundations.html",
    "href": "chapters/04_programming-foundations.html",
    "title": "4  Core Programming Concepts",
    "section": "",
    "text": "4.1 Introduction\nControl flow structures are computer programming commands that change the order in which code runs (the flow of control in the program). Specifically, control flow structures can check conditions, such as the value of a variable, to decide what code to run next. They can also run a section of code more than once.\nThe sections that follow provide examples of how to use the most common R control structures.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Programming Concepts</span>"
    ]
  },
  {
    "objectID": "chapters/04_programming-foundations.html#sec-control-flow-structures",
    "href": "chapters/04_programming-foundations.html#sec-control-flow-structures",
    "title": "4  Core Programming Concepts",
    "section": "",
    "text": "See also\n\n\n\nFor complete documentation on control flow structures in R, see the Control Flow chapter in Advanced R. You can also get more details from the R control flow help page:\n?Control",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Programming Concepts</span>"
    ]
  },
  {
    "objectID": "chapters/04_programming-foundations.html#conditional-expressions",
    "href": "chapters/04_programming-foundations.html#conditional-expressions",
    "title": "4  Core Programming Concepts",
    "section": "4.2 Conditional Expressions",
    "text": "4.2 Conditional Expressions\nSometimes you might need R to make decisions about what to do next as your code runs. For example, suppose you want to load a collection of data files, some of which are CSV files and some of which are TSV files. You can tell which is which by each file name’s suffix (.csv versus .tsv), but need to call read.csv for the CSV files and read.table for the TSV files. One way to do this is with an if-expression, which tells R to run a block of code only if a particular condition is satisfied.\nAn if-expression begins with the keyword if, then has a condition in parentheses ( ), and finally has a block of code to run if the condition is satisified in curly braces { }:\nif (condition) {\n    # Code to run if the condition is TRUE.\n}\nThe condition must be some R code that returns a single logical (TRUE or FALSE) value.\n\n\n\n\n\n\nTip\n\n\n\nIndent code between curly braces by 2 or 4 spaces. R doesn’t require you to indent your code, but doing so will make your code easier to read.\n\n\nContinuing the example, you can use the endsWith function to check whether a string ends with a specific pattern, so you can check for CSV files with this if-expression:\n\npath &lt;- \"test.csv\"\n\nif (endsWith(path, \".csv\")) {\n    message(\"This is a CSV file.\")\n    # data &lt;- read.csv(path)\n    # ...\n}\n\nThis is a CSV file.\n\n\nWhen this code runs, R checks the condition endsWith(path, \".csv\"). If it’s TRUE, then R runs the code between the curly braces. If it’s FALSE, then R skips over all of the code between the curly braces. So if you run the code with path &lt;- \"test.csv\", R will print a message, but if you run the code with path &lt;- \"test.tsv\", R won’t print anything.\nYou can use the optional else keyword with an if-expression to tell R to run a different block of code only if the condition is not satisfied. This turns the if-expression into an if-else-expression. An if-else-expression typically looks like this:\nif (condition) {\n    # Code to run if condition is TRUE.\n} else {\n    # Code to run if condition is FALSE.\n}\nReturning to the example, let’s change the if-expression so that R prints an error message and stops running (with the stop function) if the file is not a CSV file:\n\npath &lt;- \"test.csv\"\n\nif (endsWith(path, \".csv\")) {\n    message(\"This is a CSV file.\")\n    # data &lt;- read.csv(path)\n    # ...\n} else {\n    stop(\"Unrecognized file format.\")\n}\n\nThis is a CSV file.\n\n\nTry this code out with a few different values for path.\nThe else and if keywords can be combined, so you can write if-else expressions that check several different mutually exclusive conditions:\nif (condition1) {\n    # Code to run if condition1 is TRUE.\n} else if (condition2) {\n    # Code to run if condition2 is TRUE (and condition1 is FALSE).\n} else {\n    # Code to run if both condition1 and condition2 are FALSE.\n}\nComing back to the example one last time, now we can add a case that handles TSV files:\n\npath &lt;- \"test.csv\"\n\nif (endsWith(path, \".csv\")) {\n    message(\"This is a CSV file.\")\n    # data = read.csv(path)\n    # ...\n} else if (endsWith(path, \".tsv\")) {\n    message(\"This is a TSV file.\")\n    # data &lt;- read.table(path)\n    # ...\n} else {\n  stop(\"Unrecognized file format.\")\n}\n\nThis is a CSV file.\n\n\nAs usual, try this code out with a few different values for path. Testing your code as you write it is a great way to prevent bugs.\n\n\n\n\n\n\nNote\n\n\n\nThe R function ifelse is similar to an if-else-expression, but operates element-by-element on vectors. The condition should be a logical vector with multiple elements. For example:\n\nx &lt;- c(0, 1, -1, 2)\nifelse(x &lt;= 0, \"non-positive\", \"positive\")\n\n[1] \"non-positive\" \"positive\"     \"non-positive\" \"positive\"    \n\n\nIf you only need to test a single condition, it is clearer and more efficient to use an if-else-expression than to use ifelse.\n\n\nIf-expressions are a fairly universal control flow structure across programming languages, setting aside minor differences in syntax.\n\n4.2.1 Comparisons\nThe condition in an if-expression will often be a comparison between two variables or a variable and a value. For instance, you might want to check whether a variable is equal to a specific value.\nIn R, you can make comparisons with the following operators:\n\n&lt; for “less than”\n&gt; for “greater than”\n&lt;= for “less than or equal to”\n&gt;= for “greater than or equal to”\n== for “equal to”\n!= for “not equal to”\n\nThe “equal to” operator uses two equal signs so that R can distinguish it from =, the assignment operator.\nLet’s look at a few examples:\n\n1.5 &lt; 3\n\n[1] TRUE\n\n\"a\" &gt; \"b\"\n\n[1] FALSE\n\npi == 3.14\n\n[1] FALSE\n\n\"hi\" == 'hi'\n\n[1] TRUE\n\n\nWhen you make a comparison, R returns a logical value (TRUE or FALSE), to indicate the result. Logical values are not the same as strings, so they are not quoted.\nLogical values are values, so you can use them in other computations. For example:\n\nTRUE\n\n[1] TRUE\n\nTRUE == FALSE\n\n[1] FALSE\n\n\nSection 4.2.2 describes more ways to use and combine logical values.\n\n\n\n\n\n\nWarning\n\n\n\nBeware that the equality operators don’t always return FALSE when you compare two different types of data:\n\n\"1\" == 1\n\n[1] TRUE\n\n\"TRUE\" &lt;= TRUE\n\n[1] TRUE\n\n\"FALSE\" &lt;= TRUE\n\n[1] TRUE\n\n\nThis is due to R’s implicit coercion, which was explained in Section 3.8.2.\n\n\n\n\n4.2.2 Logic\nAll of the conditions we’ve seen so far have been written in terms of a single test. If you want to use more sophisticated conditions, R provides operators to negate and combine logical vectors. These operators are useful for working with logical vectors even outside the context of indexing.\n\nNegation\nThe NOT operator ! converts TRUE to FALSE and FALSE to TRUE:\n\nx = c(TRUE, FALSE, TRUE, TRUE)\nx\n\n[1]  TRUE FALSE  TRUE  TRUE\n\n!x\n\n[1] FALSE  TRUE FALSE FALSE\n\n\nYou can use ! with a condition:\n\ny = c(\"hi\", \"hello\")\n!(y == \"hi\")\n\n[1] FALSE  TRUE\n\n\nThe NOT operator is vectorized.\n\n\nCombinations\nR also has operators for combining logical values.\nThe AND operator & returns TRUE only when both arguments are TRUE. Here are some examples:\n\nFALSE & FALSE\n\n[1] FALSE\n\nTRUE & FALSE\n\n[1] FALSE\n\nFALSE & TRUE\n\n[1] FALSE\n\nTRUE & TRUE\n\n[1] TRUE\n\nc(TRUE, FALSE, TRUE) & c(TRUE, TRUE, FALSE)\n\n[1]  TRUE FALSE FALSE\n\n\nThe OR operator | returns TRUE when at least one argument is TRUE. Let’s see some examples:\n\nFALSE | FALSE\n\n[1] FALSE\n\nTRUE | FALSE\n\n[1] TRUE\n\nFALSE | TRUE\n\n[1] TRUE\n\nTRUE | TRUE\n\n[1] TRUE\n\nc(TRUE, FALSE) | c(TRUE, TRUE)\n\n[1] TRUE TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nEveryday English is less precise than logic. You might say:\n\nI want all subjects with age over 50 and all subjects that like cats.\n\nBut in logic this means:\n(subject age over 50) OR (subject likes cats)\nSo think carefully about whether you need both conditions to be true (AND) or at least one (OR).\n\n\nThe AND, and OR operators are vectorized.\n\n\n\n\n\n\nNote\n\n\n\nRarely, you might want exactly one condition to be true. The XOR (eXclusive OR) function xor returns TRUE when exactly one argument is TRUE. For example:\n\nxor(FALSE, FALSE)\n\n[1] FALSE\n\nxor(TRUE, FALSE)\n\n[1] TRUE\n\nxor(TRUE, TRUE)\n\n[1] FALSE\n\n\n\n\n\n\nShort-circuiting\nThe second argument is irrelevant in some conditions:\n\nFALSE & is always FALSE\nTRUE | is always TRUE\n\nNow imagine you have FALSE & long_computation(). You can save time by skipping long_computation(). A short-circuit operator does exactly that.\nR has two short-circuit operators:\n\n&& is a short-circuited &\n|| is a short-circuited |\n\nThese operators only evaluate the second argument if it is necessary to determine the result. Here are some of these:\n\nTRUE && FALSE\n\n[1] FALSE\n\nTRUE && TRUE\n\n[1] TRUE\n\nTRUE || TRUE\n\n[1] TRUE\n\n\nThe short-circuit operators are not vectorized—they only accept length-1 arguments:\n\nc(TRUE, FALSE) && c(TRUE, TRUE)\n\nError in c(TRUE, FALSE) && c(TRUE, TRUE): 'length = 2' in coercion to 'logical(1)'\n\n\nBecause of this, you can’t use short-circuit operators for indexing. Their main use is in writing conditions for if-expressions, which we’ll learn about later on.\n\n\n\n\n\n\nNote\n\n\n\nPrior to R 4.3.0, short-circuit operators didn’t raise an error for inputs with length greater than 1 (and thus were a common source of bugs).",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Programming Concepts</span>"
    ]
  },
  {
    "objectID": "chapters/04_programming-foundations.html#iteration",
    "href": "chapters/04_programming-foundations.html#iteration",
    "title": "4  Core Programming Concepts",
    "section": "4.3 Iteration",
    "text": "4.3 Iteration\nR is powerful tool for automating tasks that have repetitive steps. For example, you can:\n\nApply a transformation to an entire column of data.\nCompute distances between all pairs from a set of points.\nRead a large collection of files from disk in order to combine and analyze the data they contain.\nSimulate how a system evolves over time from a specific set of starting parameters.\nScrape data from many pages of a website.\n\nYou can implement concise, efficient solutions for these kinds of tasks in R by using iteration, which means repeating a computation many times. R provides four different strategies for writing iterative code:\n\nVectorization, where a function is implicitly called on each element of a vector. See Section 3.6.2 for more details.\nApply functions, where a function is explicitly called on each element of a vector or array. These will be covered in Section 7.3.\nLoops, where an expression is evaluated repeatedly until some condition is met.\nRecursion, where a function calls itself.\n\nVectorization is the most efficient and most concise iteration strategy, but also the least flexible, because it only works with vectorized functions and vectors. Apply functions are more flexible—they work with any function and any data structure with elements—but less efficient and less concise. Loops and recursion provide the most flexibility but are the least concise. In recent versions of R, apply functions and loops are similar in terms of efficiency. Recursion tends to be the least efficient iteration strategy in R.\nThe rest of this section explains how to write loops and how to choose which iteration strategy to use. We assume you’re already comfortable with vectorization and have at least some familiarity with apply functions.\n\n4.3.1 For-loops\nA for-loop evaluates an expression once for each element of a vector or list. The for keyword creates a for-loop. The syntax is:\nfor (I in DATA) {\n  # Your code goes here\n}\nThe variable I is called an induction variable. At the beginning of each iteration, I is assigned the next element of DATA. The loop iterates once for each element, unless a keyword instructs R to exit the loop early (more about this in Section 4.3.4. As with if-statements and functions, the curly braces { } are only required if the body contains multiple lines of code. Here’s a simple for-loop:\n\nfor (i in 1:10)\n  message(\"Hi from iteration  \", i)\n\nHi from iteration  1\n\n\nHi from iteration  2\n\n\nHi from iteration  3\n\n\nHi from iteration  4\n\n\nHi from iteration  5\n\n\nHi from iteration  6\n\n\nHi from iteration  7\n\n\nHi from iteration  8\n\n\nHi from iteration  9\n\n\nHi from iteration  10\n\n\nWhen some or all of the iterations in a task depend on results from prior iterations, loops tend to be the most appropriate iteration strategy. For instance, loops are a good way to implement time-based simulations or compute values in recursively defined sequences.\nAs a concrete example, suppose you want to compute the result of starting from the value 1 and composing the sine function 100 times:\n\nresult = 1\nfor (i in 1:100) {\n  result = sin(result)\n}\n\nresult\n\n[1] 0.1688525\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnlike other iteration strategies, loops don’t return a result automatically. It’s up to you to use variables to store any results you want to use later. If you want to save a result from every iteration, you can use a vector or a list indexed on the iteration number:\n\nn = 1 + 100\nresult = numeric(n)\nresult[1] = 1\nfor (i in 2:n) {\n  result[i] = sin(result[i - 1])\n}\n\nplot(result)\n\n\n\n\n\n\n\n\nSection 4.3.3 explains this in more detail.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf the iterations in a task are not dependent, it’s preferable to use vectorization or apply functions instead of a loop. Vectorization is more efficient, and apply functions are usually more concise.\nIn some cases, you can use vectorization to handle a task even if the iterations are dependent. For example, you can use vectorized exponentiation and the sum function to compute the sum of the cubes of many numbers:\n\nnumbers = c(10, 3, 100, -5, 2, 10)\nsum(numbers^3)\n\n[1] 1001910\n\n\n\n\n\n\n4.3.2 While-loops\nA while-loop runs a block of code repeatedly as long as some condition is TRUE. The while keyword creates a while-loop. The syntax is:\n\nwhile (CONDITION) {\n  # Your code goes here\n}\n\nThe CONDITION should be a scalar logical value or an expression that returns one. At the beginning of each iteration, R checks the CONDITION and exits the loop if it’s FALSE. As always, the curly braces { } are only required if the body contains multiple lines of code. Here’s a simple while-loop:\n\ni = 0\nwhile (i &lt; 10) {\n  i = i + 1\n  message(\"Hello from iteration \", i)\n}\n\nHello from iteration 1\n\n\nHello from iteration 2\n\n\nHello from iteration 3\n\n\nHello from iteration 4\n\n\nHello from iteration 5\n\n\nHello from iteration 6\n\n\nHello from iteration 7\n\n\nHello from iteration 8\n\n\nHello from iteration 9\n\n\nHello from iteration 10\n\n\nNotice that this example does the same thing as the simple for-loop in Section 4.3.1, but requires 5 lines of code instead of 2. While-loops are a generalization of for-loops, and only do the bare minimum necessary to iterate. They tend to be most useful when you don’t know how many iterations will be necessary to complete a task.\nAs an example, suppose you want to add up the integers in order until the total is greater than 50:\n\ntotal = 0\ni = 1\nwhile (total &lt; 50) {\n  total = total + i\n  message(\"i is \", i, \" total is \", total)\n  i = i + 1\n}\n\ni is 1 total is 1\n\n\ni is 2 total is 3\n\n\ni is 3 total is 6\n\n\ni is 4 total is 10\n\n\ni is 5 total is 15\n\n\ni is 6 total is 21\n\n\ni is 7 total is 28\n\n\ni is 8 total is 36\n\n\ni is 9 total is 45\n\n\ni is 10 total is 55\n\ntotal\n\n[1] 55\n\ni\n\n[1] 11\n\n\n\n\n4.3.3 Saving Multiple Results\nLoops often produce a different result for each iteration. If you want to save more than one result, there are a few things you must do.\nFirst, set up an index vector. The index vector should usually correspond to the positions of the elements in the data you want to process. The seq_along function returns an index vector when passed a vector or list. For instance:\n\nnumbers = c(-1, 21, 3, -8, 5)\nindex = seq_along(numbers)\n\nThe loop will iterate over the index rather than the input, so the induction variable will track the current iteration number. On the first iteration, the induction variable will be 1, on the second it will be 2, and so on. Then you can use the induction variable and indexing to get the input for each iteration.\nSecond, set up an empty output vector or list. This should usually also correspond to the input, or one element longer (the extra element comes from the initial value). R has several functions for creating vectors:\n\nlogical, integer, numeric, complex, and character create an empty vector with a specific type and length\nvector creates an empty vector with a specific type and length\nrep creates a vector by repeating elements of some other vector\n\nEmpty vectors are filled with FALSE, 0, or \"\", depending on the type of the vector. Here are some examples:\n\nlogical(3)\n\n[1] FALSE FALSE FALSE\n\nnumeric(4)\n\n[1] 0 0 0 0\n\nrep(c(1, 2), 2)\n\n[1] 1 2 1 2\n\n\nLet’s create an empty numeric vector congruent to the numbers vector:\n\nn = length(numbers)\nresult = numeric(n)\n\nAs with the input, you can use the induction variable and indexing to set the output for each iteration.\nCreating a vector or list in advance to store something, as we’ve just done, is called preallocation. Preallocation is extremely important for efficiency in loops. Avoid the temptation to use c or append to build up the output bit by bit in each iteration.\nFinally, write the loop, making sure to get the input and set the output. As an example, this loop adds each element of numbers to a running total and squares the new running total:\n\nfor (i in index) {\n  prev = if (i &gt; 1) result[i - 1] else 0\n  result[i] = (numbers[i] + prev)^2\n}\nresult\n\n[1] 1.000000e+00 4.840000e+02 2.371690e+05 5.624534e+10 3.163538e+21\n\n\n\n\n4.3.4 Break & Next\nThe break keyword causes a loop to immediately exit. It only makes sense to use break inside of an if-statement.\nFor example, suppose you want to print each string in a vector, but stop at the first missing value. You can do this with a for-loop and the break keyword:\n\nmy_messages = c(\"Hi\", \"Hello\", NA, \"Goodbye\")\n\nfor (msg in my_messages) {\n  if (is.na(msg))\n    break\n\n  message(msg)\n}\n\nHi\n\n\nHello\n\n\nThe next keyword causes a loop to immediately go to the next iteration. As with break, it only makes sense to use next inside of an if-statement.\nLet’s modify the previous example so that missing values are skipped, but don’t cause printing to stop. Here’s the code:\n\nfor (msg in my_messages) {\n  if (is.na(msg))\n    next\n\n  message(msg)\n}\n\nHi\n\n\nHello\n\n\nGoodbye\n\n\nThese keywords work with both for-loops and while-loops.\n\n\n4.3.5 Planning for Iteration\nAt first it may seem difficult to decide if and what kind of iteration to use. Start by thinking about whether you need to do something over and over. If you don’t, then you probably don’t need to use iteration. If you do, then try iteration strategies in this order:\n\nVectorization\nApply functions\n\nTry an apply function if iterations are independent.\n\nLoops\n\nTry a for-loop if some iterations depend on others.\nTry a while-loop if the number of iterations is unknown.\n\nRecursion (which isn’t covered here)\n\nConvenient for naturally recursive tasks (like Fibonacci), but often there are faster solutions.\n\n\nStart by writing the code for just one iteration. Make sure that code works; it’s easy to test code for one iteration.\nWhen you have one iteration working, then try using the code with an iteration strategy (you will have to make some small changes). If it doesn’t work, try to figure out which iteration is causing the problem. One way to do this is to use message to print out information. Then try to write the code for the broken iteration, get that iteration working, and repeat this whole process.\n\n\n4.3.6 Case Study: The Collatz Conjecture\nThe Collatz Conjecture is a conjecture in math that was introduced in 1937 by Lothar Collatz and remains unproven today, despite being relatively easy to explain. Here’s a statement of the conjecture:\n\nStart from any positive integer. If the integer is even, divide by 2. If the integer is odd, multiply by 3 and add 1.\nIf the result is not 1, repeat using the result as the new starting value.\nThe result will always reach 1 eventually, regardless of the starting value.\n\nThe sequences of numbers this process generates are called Collatz sequences. For instance, the Collatz sequence starting from 2 is 2, 1. The Collatz sequence starting from 12 is 12, 6, 3, 10, 5, 16, 8, 4, 2, 1.\nYou can use iteration to compute the Collatz sequence for a given starting value. Since each number in the sequence depends on the previous one, and since the length of the sequence varies, a while-loop is the most appropriate iteration strategy:\n\nn = 5\ni = 0\nwhile (n != 1) {\n  i = i + 1\n  if (n %% 2 == 0) {\n    n = n / 2\n  } else {\n    n = 3 * n + 1\n  }\n  message(n, \" \", appendLF = FALSE)\n}\n\n16 8 4 2 1\n\n\nAs of 2020, scientists have used computers to check the Collatz sequences for every number up to approximately \\(2^{64}\\).\n\n\n\n\n\n\nSee also\n\n\n\nFor more details about the Collatz Conjecture, check out this video.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Programming Concepts</span>"
    ]
  },
  {
    "objectID": "chapters/04_programming-foundations.html#functions",
    "href": "chapters/04_programming-foundations.html#functions",
    "title": "4  Core Programming Concepts",
    "section": "4.4 Functions",
    "text": "4.4 Functions\nWhy build code several or a hundred times when you can build it once and then call and run it as many times as you want? The answer is, don’t! A function allows you to perform an action multiple times in R by calling it and applying it in similar contexts.\nFor instance, if you build a function that checks the class of all vectors in a data frame, you can name this function and then apply it to do the same operation with any other data frame. Or, if you build a function that graphs the correlation between two numeric vectors and exports this graph to a .png file, you can call this same function and apply it to two other vectors, again and again as needed. Functions can greatly increase the efficiency of your programming, and allow you to create flexible and customized solutions. This section explains how you can write your own functions.\n\nTo start, let’s briefly review what functions are, and some of the jargon associated with them. It’s useful to think of functions as factories: raw materials (inputs) go in, products (outputs) come out. We can also represent this visually:\n\nProgrammers use several specific terms to describe the parts and usage of functions:\n\nParameters are placeholder variables for inputs.\n\nArguments are the actual values assigned to the parameters in a call.\n\nThe return value is the output.\nThe body is the code inside.\nCalling a function means using a function to compute something.\n\nAlmost every command in R is a function, even the arithmetic operators and the parentheses!\nThe function keyword creates a new function. Here’s the syntax:\nfunction(parameter1, parameter2, ...) {\n  # Your code goes here\n\n  # The result goes here\n}\nA function can have any number of parameters, and will automatically return the value of the last line of its body.\nA function is a value, and like any other value, if you want to reuse it, you need to assign it to variable. Choosing descriptive variable names is a good habit. For functions, that means choosing a name that describes what the function does. It often makes sense to use verbs in function names.\n\n\n\n\n\n\nImportant\n\n\n\nDefining a function (with the function keyword) and calling a function are different ideas. When you define a function, R does not run the code in the body of the function. Instead, R waits to do this until you actually call the function.\n\n\nLet’s write a function that gets the largest values in a vector. The inputs or arguments to the function will be the vector in question and also the number of values to get. Let’s call these vec and n, respectively. The result will be a vector of the n largest elements. Here’s one way to write the function:\n\nget_largest = function(vec, n) {\n  sorted = sort(vec, decreasing = TRUE)\n  head(sorted, n)\n}\n\nThe name of the function, get_largest, describes what the function does and includes a verb. If this function will be used frequently, a shorter name, such as largest, might be preferable (compare to the head function).\nAny time you write a function, the first thing you should do afterwards is test that it actually works. Let’s try the get_largest function on a few test cases:\n\nx = c(1, 10, 20, -3)\nget_largest(x, 2)\n\n[1] 20 10\n\nget_largest(x, 3)\n\n[1] 20 10  1\n\ny = c(-1, -2, -3)\nget_largest(y, 2)\n\n[1] -1 -2\n\nz = c(\"d\", \"a\", \"t\", \"a\", \"l\", \"a\", \"b\")\nget_largest(z, 3)\n\n[1] \"t\" \"l\" \"d\"\n\n\nNotice that the parameters vec and n inside the function do not exist as variables outside of the function:\n\nvec\n\nError: object 'vec' not found\n\n\nIn general, R keeps parameters and variables you define inside of a function separate from variables you define outside of a function. You can read more about the specific rules for how R searches for variables in DataLab’s Intermediate R reader.\nAs a function for quickly summarizing data, get_largest would be more convenient if the parameter n for the number of values to return was optional (again, compare to the head function). You can make the parameter n optional by setting a default argument: an argument assigned to the parameter if no argument is assigned in the call to the function. You can use = to assign default arguments to parameters when you define a function with the function keyword. Here’s a new definition of the function with the default n = 5:\n\nget_largest = function(vec, n = 5) {\n  sorted = sort(vec, decreasing = TRUE)\n  head(sorted, n)\n}\n\nAfter making this change, it’s a good idea to test the function again:\n\nget_largest(x)\n\n[1] 20 10  1 -3\n\nget_largest(y)\n\n[1] -1 -2 -3\n\nget_largest(z)\n\n[1] \"t\" \"l\" \"d\" \"b\" \"a\"\n\n\n\n4.4.1 Returning Values\nWe’ve already seen that a function will automatically return the value of its last line.\nThe return keyword causes a function to return a result immediately, without running any subsequent code in its body. It only makes sense to use return from inside of an if-expression. If your function doesn’t have any if-expressions, you don’t need to use return.\nFor example, suppose you want the get_largest function to immediately return NULL if the argument for vec is a list. Here’s the code, along with some test cases:\n\nget_largest = function(vec, n = 5) {\n  if (is.list(vec))\n    return(NULL)\n\n  sorted = sort(vec, decreasing = TRUE)\n  head(sorted, n)\n}\n\nget_largest(x)\n\n[1] 20 10  1 -3\n\nget_largest(z)\n\n[1] \"t\" \"l\" \"d\" \"b\" \"a\"\n\nget_largest(list(1, 2))\n\nNULL\n\n\nAlternatively, you could make the function raise an error by calling the stop function. Whether it makes more sense to return NULL or print an error depends on how you plan to use the get_largest function.\nNotice that the last line of the get_largest function still doesn’t use the return keyword. It’s idiomatic to only use return when strictly necessary.\nA function returns one R object, but sometimes computations have multiple results. In that case, return the results in a vector, list, or other data structure.\nFor example, let’s make a function that computes the mean and median for a vector. We’ll return the results in a named list, although we could also use a named vector:\n\ncompute_mean_med = function(x) {\n  m1 = mean(x)\n  m2 = median(x)\n  list(mean = m1, median = m2)\n}\ncompute_mean_med(c(1, 2, 3, 1))\n\n$mean\n[1] 1.75\n\n$median\n[1] 1.5\n\n\nThe names make the result easier to understand for the caller of the function, although they certainly aren’t required here.\n\n\n\n\n\n\nTip\n\n\n\nYou can view the body of a function by typing its name without trailing parentheses (in contrast to how you call functions). The body of a function is usually surrounded by curly braces { }, although they’re optional if the body only contains one line of code. Indenting code inside of curly braces by 2-4 spaces also helps make it visually distinct from other code.\nFor example, let’s look at the body of the append function, which appends a value to the end of a list or vector:\n\nappend\n\nfunction (x, values, after = length(x)) \n{\n    lengx &lt;- length(x)\n    if (!after) \n        c(values, x)\n    else if (after &gt;= lengx) \n        c(x, values)\n    else c(x[1L:after], values, x[(after + 1L):lengx])\n}\n&lt;bytecode: 0x622211a72430&gt;\n&lt;environment: namespace:base&gt;\n\n\nDon’t worry if you can’t understand everything the append function’s code does yet. It will make more sense later on, after you’ve written a few functions of your own.\nMany of R’s built-in functions are not entirely written in R code. You can spot these by calls to the special .Primitive or .Internal functions in their code.\nFor instance, the sum function is not written in R code:\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\n\n\n\n\n\n4.4.2 Planning Your Functions\nBefore you write a function, it’s useful to go through several steps:\n\nWrite down what you want to do, in detail. It can also help to draw a picture of what needs to happen.\nCheck whether there’s already a built-in function. Search online and in the R documentation.\nWrite the code to handle a simple case first. For data science problems, use a small dataset at this step.\n\nLet’s apply this in one final example: a function that detects leap years. A year is a leap year if either of these conditions is true:\n\nIt is divisible by 4 and not 100\nIt is divisible by 400\n\nThat means the years 2004 and 2000 are leap years, but the year 2200 is not. Here’s the code and a few test cases:\n\n# If year is divisible by 4 and not 100 -&gt; leap\n# If year is divisible by 400 -&gt; leap\nyear = 2004\nis_leap = function(year) {\n  if (year %% 4 == 0 & year %% 100 != 0) {\n    leap = TRUE\n  } else if (year %% 400 == 0) {\n    leap = TRUE\n  } else {\n    leap = FALSE\n  }\n  leap\n}\nis_leap(400)\n\n[1] TRUE\n\nis_leap(1997)\n\n[1] FALSE\n\n\nFunctions are the building blocks for solving larger problems. Take a divide-and-conquer approach, breaking large problems into smaller steps. Use a short function for each step. This approach makes it easier to:\n\nTest that each step works correctly.\nModify, reuse, or repurpose a step.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Core Programming Concepts</span>"
    ]
  },
  {
    "objectID": "chapters/05_files-packages-indexing.html",
    "href": "chapters/05_files-packages-indexing.html",
    "title": "5  Files, Packages, and Data",
    "section": "",
    "text": "5.1 Working with Files",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Files, Packages, and Data</span>"
    ]
  },
  {
    "objectID": "chapters/05_files-packages-indexing.html#working-with-files",
    "href": "chapters/05_files-packages-indexing.html#working-with-files",
    "title": "5  Files, Packages, and Data",
    "section": "",
    "text": "5.1.1 Setup\n\n\n\n\n\n\nImportant\n\n\n\nTo follow along, download this zip file!\n\n\nNavigate to where you want to save your work:\ncd ~/Documents/\nNext, make a directory:\nmkdir files_in_r\ncd files_in_r\nCopy the downloaded zip file into that directory:\ncp ~/Downloads/best_in_show.zip .\nUnzip the file:\nunzip best_in_show.zip\nNavigate to the newly created directory\ncd best_in_show\n\n\n5.1.2 Exploring Files\nWhen working with files, its important to gather lots of information, and constantly test assumptions that you may have.\nThis process is a key part of programming and of working in the command line.\nLet’s start by seeing what we have, which we do with the ls command:\nls\nRemember that ls can be modified with flags, for example, to see all the files including hidden ones, use the -a flag:\nls -a\nYou can see more information about the files with the -l flag:\nls -l\nModifiers can be combined for ls:\nls -la\nYou can use du -h to see the disk usage (file size) of a given file:\ndu -h dogs.csv\n-h refers to human readable as by default du displays the size in block units. Being aware of the size of a file early on can help debug issues with running out of disk space, as well as issues down the line in the analysis process. For example, reading in too many too large files into R can create issues for you by overloading your system’s RAM (your computer’s working memory).\nYou can view the disk usage for all the files in the directory with the wildcard symbol *:\ndu -h *\n\n5.1.2.1 File Extensions\nMost of the time, you can guess the format of a file by looking at its extension, the characters (usually three) after the last dot . in the file name. For example, the extension .jpg or .jpeg indicates a JPEG image file. Some operating systems hide extensions by default, but you can find instructions to change this setting online by searching for “show file extensions” and your operating system’s name. The extension is just part of the file’s name, so it should be taken as a hint about the file’s format rather than a guarantee.\n\n\n5.1.2.2 Text Files\nA text file is one that contains human-readable lines of text. You can check this by opening the file with a text editor such as Microsoft Notepad or macOS TextEdit. Many file formats use text in order to make the format easier to work with.\nOn the command line, you can get information about the type of a file by using the file command followed by the name of a file:\nfile dogs.csv\nNote that file uses a series of tests (learn more by reading man file), to determine the file type and may not always perfectly report the type of the file.\nThe output of file is the file name followed by a colon and then a description of the file type.\nIn this case, the output tells us that dogs.csv is a CSV text file.\nA comma-separated values (CSV) file records tabular data using one line per row, with commas separating columns.\nFrom the command line we can read text files with vim:\nvim dogs.csv\nTo see the type of all the files in the directory you can use the wildcard * operator:\nfile *\n\n\n5.1.2.3 Binary Files\nA binary file is one that’s not human-readable. You can’t just read off the data if you open a binary file in a text editor, but they have a number of other advantages. Compared to text files, binary files are often faster to read and take up less storage space (bytes).\nFor demonstrations sake, see what happens when you try to use vim to ‘read’ a binary data file:\nvim dogs.rds\nNotice that the editor displays data but it isn’t human readable, it looks like a bunch of random symbols with potentially the occasional recognizable word.\n\n\n5.1.2.4 Common Data File Types\n\n\n\nName\nExtension\nTabular?\nText?\n\n\n\n\nComma-separated Values\n.csv\nYes\nYes\n\n\nTab-separated Values\n.tsv\nYes\nYes\n\n\nFixed-width File\n.fwf\nYes\nYes\n\n\nMicrosoft Excel\n.xlsx\nYes\nNo\n\n\nMicrosoft Excel 1993-2007\n.xls\nYes\nNo\n\n\nApache Arrow\n.feather\nYes\nNo\n\n\nR Data\n.rds\nSometimes\nNo\n\n\nR Data\n.rda\nSometimes\nNo\n\n\nPlaintext\n.txt\nSometimes\nYes\n\n\nExtensible Markup Language\n.xml\nNo\nYes\n\n\nJavaScript Object Notation\n.json\nNo\nYes\n\n\n\n\n\n\n5.1.3 Reading and Writing Files in R\nR has many functions for working with file systems, reading and writing files.\n\n5.1.3.1 The Working Directory\nThe working directory is the starting point R uses for relative paths. Think of the working directory as the directory R is currently “at” or watching.\nThe function getwd returns the absolute path for the current working directory, as a string. It doesn’t require any arguments:\n\ngetwd()\n\nOn your computer, the output from getwd will likely be different. This is a very useful function for getting your bearings when you write relative paths. If you write a relative path and it doesn’t work as expected, the first thing to do is check the working directory.\nThe related setwd function changes the working directory. It takes one argument: a path to the new working directory. Here’s an example:\n\nsetwd(\"..\")\n# Now check the working directory.\ngetwd()\n\nGenerally, you should avoid using calls to setwd in your R scripts and R Markdown files. Calling setwd makes your code more difficult to understand, and can always be avoided by using appropriate relative paths. If you call setwd with an absolute path, it also makes your code less portable to other computers. It’s fine to use setwd interactively (in the R console), but avoid making your saved code dependent on it.\n\n\n\n\n\n\nTip\n\n\n\nWhen working in RStudio, you can set the working directory at the start of your session in Session -&gt; Set Working Directory -&gt; To Source File Location.\n\n\nAnother function that’s useful for dealing with the working directory and file system is list.files. The list.files function returns the names of all of the files and directories inside of a directory. It accepts a path to a directory as an argument, or assumes the working directory if you don’t pass a path. For instance:\n\n# List files and directories in ~/.\nlist.files(\"~/\")\n# List files and directories in the working directory.\nlist.files()\n\nIf you call list.files with an invalid path or an empty directory, the output is character(0):\n\nlist.files(\"/this/path/is/fake/\")\n\ncharacter(0)\n\n\nLater on, we’ll learn about what character(0) means more generally.\n\n\n5.1.3.2 Reading a CSV File\nLet’s go ahead and read the dogs.csv file we extracted from the zip file at the start.\nR provides a very easy built-in function for reading CSV files, and a variety of other formats for text files containing tabular data.\nTo read a CSV file into R, use read.csv:\n\ndogs = read.csv('dogs.csv')\n\n\n5.1.3.2.1 Inspecting the Data\n\ndogs = readRDS('data/dogs.rds')\n\nWhenever you import data into R, it is crucial to check that things went as expected. To check things went according to our expectation, look at the output of the read.csv function, which we saved into dogs.\nLet’s see what the output is. We can check what the object is with the class function:\n\nclass(dogs)\n\n[1] \"data.frame\"\n\n\nWe can see that the read.csv function returned a data frame. This makes sense because data frames represent tabular data, and csv files contain tabular data.\nWe can get more information with the str function. str concisely gives information about the content of an R object:\n\nstr(dogs)\n\n'data.frame':   172 obs. of  18 variables:\n $ breed            : chr  \"Border Collie\" \"Border Terrier\" \"Brittany\" \"Cairn Terrier\" ...\n $ group            : Factor w/ 7 levels \"herding\",\"hound\",..: 1 5 4 5 4 4 4 6 1 1 ...\n $ datadog          : num  3.64 3.61 3.54 3.53 3.34 3.33 3.3 3.26 3.25 3.22 ...\n $ popularity_all   : int  45 80 30 59 130 63 27 38 60 20 ...\n $ popularity       : int  39 61 30 48 81 51 27 33 49 20 ...\n $ lifetime_cost    : num  20143 22638 22589 21992 20224 ...\n $ intelligence_rank: int  1 30 19 35 31 18 20 8 10 6 ...\n $ longevity        : num  12.5 14 12.9 13.8 12.5 ...\n $ ailments         : int  2 0 0 2 1 0 2 5 1 5 ...\n $ price            : num  623 833 618 435 750 800 465 740 530 465 ...\n $ food_cost        : num  324 324 466 324 324 324 674 324 466 405 ...\n $ grooming         : Factor w/ 3 levels \"daily\",\"weekly\",..: 2 2 2 2 2 2 2 2 2 1 ...\n $ kids             : Factor w/ 3 levels \"high\",\"medium\",..: 3 1 2 1 1 1 1 2 3 1 ...\n $ megarank_kids    : int  1 2 3 4 5 6 7 8 9 11 ...\n $ megarank         : int  29 1 11 2 4 5 6 22 52 8 ...\n $ size             : Factor w/ 3 levels \"large\",\"medium\",..: 2 3 2 3 2 2 3 3 2 3 ...\n $ weight           : num  NA 13.5 35 14 NA 30 25 NA NA 22 ...\n $ height           : num  20 NA 19 10 18 16 14.5 9.5 18.5 14.5 ...\n\n\nLet’s check the dimensions of our dataset:\n\ndim(dogs)\n\n[1] 172  18\n\n\nRecall we can access the number of rows with:\n\nnrow(dogs)\n\n[1] 172\n\n\nAnd the number of columns:\n\nncol(dogs)\n\n[1] 18\n\n\nTo display the first rows from the dataset, use head:\n\nhead(dogs)\n\n                   breed    group datadog popularity_all popularity\n1          Border Collie  herding    3.64             45         39\n2         Border Terrier  terrier    3.61             80         61\n3               Brittany sporting    3.54             30         30\n4          Cairn Terrier  terrier    3.53             59         48\n5 Welsh Springer Spaniel sporting    3.34            130         81\n6 English Cocker Spaniel sporting    3.33             63         51\n  lifetime_cost intelligence_rank longevity ailments price food_cost grooming\n1         20143                 1     12.52        2   623       324   weekly\n2         22638                30     14.00        0   833       324   weekly\n3         22589                19     12.92        0   618       466   weekly\n4         21992                35     13.84        2   435       324   weekly\n5         20224                31     12.49        1   750       324   weekly\n6         18993                18     11.66        0   800       324   weekly\n    kids megarank_kids megarank   size weight height\n1    low             1       29 medium     NA     20\n2   high             2        1  small   13.5     NA\n3 medium             3       11 medium   35.0     19\n4   high             4        2  small   14.0     10\n5   high             5        4 medium     NA     18\n6   high             6        5 medium   30.0     16\n\n\nAnd to display the last rows from the dataset, use tail:\n\ntail(dogs)\n\n                          breed        group datadog popularity_all popularity\n167                      Vizsla     sporting      NA             37         NA\n168                  Weimaraner     sporting      NA             32         NA\n169               Welsh Terrier      terrier      NA             99         NA\n170            Wire Fox Terrier      terrier      NA            100         NA\n171 Wirehaired Pointing Griffon     sporting      NA             92         NA\n172              Xoloitzcuintli non-sporting      NA            155         NA\n    lifetime_cost intelligence_rank longevity ailments price food_cost grooming\n167            NA                25     12.50        0   935        NA     &lt;NA&gt;\n168            NA                21        NA        1   562        NA   weekly\n169            NA                53        NA        0   843        NA   weekly\n170            NA                51     13.17        0   668        NA     &lt;NA&gt;\n171            NA                46      8.80        0   755        NA     &lt;NA&gt;\n172            NA                NA        NA       NA   717        NA     &lt;NA&gt;\n    kids megarank_kids megarank   size weight height\n167 &lt;NA&gt;            NA       NA medium     NA   22.5\n168 high            NA       NA  large     NA   25.0\n169 high            NA       NA  small   20.0   15.0\n170 &lt;NA&gt;            NA       NA  small   17.5   15.0\n171 &lt;NA&gt;            NA       NA medium     NA   22.0\n172 &lt;NA&gt;            NA       NA medium     NA   16.5\n\n\n\n\n\n\n\n5.1.3.3 Writing an RDS\nYou can save any R object, such as a data frame, as an RDS file. RDS files are a great option for storing data that is intended to be loaded into R. Data saved as RDS can be quickly and accurately loaded out of and back into R without losing any information.\nThis isn’t always the case when saving data in plain text formats such as CSV. Any R-related metadata associated with the object you are saving will be maintained in the RDS format. This is useful in the case of data frames if your data contains factors, or dates, or other specific class attributes that won’t be represented in a csv. You would need to reproduce the process for parsing the data into R.\nAdditionally, RDS files often times take significantly less disk space to save, as they are a compressed format. RDS files in general are faster to read.\nHowever, its important to keep in mind that RDS files are meant to be used only in R. If you save data as an RDS, you are assuming that however is using that data will have access to and an understanding of R.\nAs a result, its common to use the RDS format for saving intermediary data in a project. While when exporting results to a collaborator, or the internet you would most likely want to use a commonly used plain-text format such as CSV.\nUse saveRDS to save our data as an RDS file with the rds file extension.\n\nsaveRDS(dogs, \"./outputs/dogs.rds\")\n\nYou can load data saved in RDS files with readRDS:\n\ndogs = readRDS(\"./outputs/dogs.rds\")\n\n\n\n5.1.3.4 Writing a CSV\nWe just saved and read the dogs data as an RDS file, and we can practice saving data in other forms, such as a comma separated values (CSV) file. Because we will be re-using the class survey data from the first week, let’s go ahead and save this data frame as a CSV in your working directory.\nFirst, you will want to create a folder called data/ in your working directory. You can do this in your console with the dir.create() function (this is like the mkdir command used in the command line). (Hint: make sure you are in your class working directory). You can run the following in your console:\ndir.create(\"data\")\nYou can also use a point-and-click method by finding the New Folder button in the bottom right pane of RStudio, under the Files tab.\nNext, let’s manually create the my.data data frame once more, by copying and pasting the code below.\n\npets &lt;- c(\"Cats rule, dogs drool\", \"Cats rule, dogs drool\",\n          \"Cats rule, dogs drool\", \"Cats rule, dogs drool\",\n          \"Cats rule, dogs drool\", \"Woof\", \"Woof\", \"Cats rule, dogs drool\",\n          \"Woof\", \"Woof\", \"Cats rule, dogs drool\")\nplace &lt;- c(\"Shah's\", \"Red 88 noodle bar\", \"UC Davis CoHo\", \"Thai Canteen\",\n           \"Tim's Hawaiian\", \"Peet's coffee and Blaze pizza\", \"Good Friends\",\n           \"in-n-out\", \"In n Out\", \"Mishka's!\", \"California Coffee\")\ntime.min &lt;- c(1, 5, 1, 4, 3, 1, 5, 4, 4, 4, 1)\ndistance.mi &lt;- c(472, 0.9, 1.2, 0.6, 0.6, 0.2, 1, 0.8, 0.8, 0.7, 0.3)\nmajor &lt;- c(\"Computer Science\", \"Genetics & Genomics\", \"Computer Science\",\n           \"Computer Science\", \"Science and Technology Studies\",\n           \"Biomedical Engineering\", \"Economics\", \"Computer science\",\n           \"Computer Science and Engineering\", \"Spanish Linguistics\",\n           \"Computer Science\")\n\nmy.data &lt;- data.frame(place, distance.mi, time.min, major, pets)\n\nNow that we have a data frame called my.data, we can use the write.csv function to save this data frame as a csv in our data folder. Let’s call it class_survey.csv.\n\nwrite.csv(my.data, \"data/class_survey.csv\", row.names = F)\n\nNow this data will be available to us for future use without having to copy and paste.\n\n\n5.1.3.5 Excel Files in R\nExcel is very popular in the data analysis world. Millions of people use Excel to input, clean, analyze, and store data. R doesn’t provide a built-in function to load Excel files. Fortunately, members of the R community share code for a variety of tasks, including loading Excel files.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Files, Packages, and Data</span>"
    ]
  },
  {
    "objectID": "chapters/05_files-packages-indexing.html#packages",
    "href": "chapters/05_files-packages-indexing.html#packages",
    "title": "5  Files, Packages, and Data",
    "section": "5.2 Packages",
    "text": "5.2 Packages\nLots of the most useful parts of R do not come pre-loaded when you install R. Packages bundle together code, documentation and data. It’s easy to share, and easy to include in your own code. Users have contributed thousands of R packages which can be found online.\nYou can think of a package as one or more functions that are related to a specific task, that you can include in your code.\nPackages need to be installed on your system and then loaded into your R session.\n\n5.2.1 CRAN\nThe Comprehensive R Archive Network (CRAN) is the main website that makes R packages accessible.\n\n5.2.1.1 readxl\nreadxl is a package written to provide functions for working with Excel files in R.\n\n\n\n5.2.2 Using Packages\nTo use an R package, it first needs to be installed on your system, and then loaded into the R session.\n\n5.2.2.1 Installing Packages\nYou can install packages from CRAN onto your system using install.packages. It will search for the package on CRAN, and download the code onto your computer in a place that R can access.\nTo install the readxl package, we pass the name to install.packages:\n\ninstall.packages(\"readxl\")\n\n\n\n5.2.2.2 Loading Packages\nEven if the package is on your system, it is not automatically loaded into R.\nEvery time you restart R you will need to reload each package that your script uses. Do so with library at the top of your script for each package that you will use.\nThis signals to you and anyone else that uses your script which packages are required to run the code, and will stop the execution of the script if any of the packages are not found.\nTo load in the readxl package we installed in the previous step, use library:\n\nlibrary(\"readxl\")\n\nThis will load in all the functions, data, and documentation from the readxl library, so we can now access them in our R session.\nTo see all the packages installed you can run library without any arguments:\n\nlibrary()\n\nThis displays all the installed libraries as well the path R is searching to find them.\n\n\n5.2.2.3 Example: Load Excel Data\nWith the excel_sheets function in readxl, we can list all the sheets in an Excel spreadsheet:\n\nsheets = excel_sheets(\"./data/dogs.xlsx\")\n\nWe can then load the data with read_xlsx:\n\ndata = read_xlsx(\"./data/dogs.xlsx\")",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Files, Packages, and Data</span>"
    ]
  },
  {
    "objectID": "chapters/05_files-packages-indexing.html#factors-special-values-and-indexing",
    "href": "chapters/05_files-packages-indexing.html#factors-special-values-and-indexing",
    "title": "5  Files, Packages, and Data",
    "section": "5.3 Factors, Special Values, and Indexing",
    "text": "5.3 Factors, Special Values, and Indexing\n\n5.3.1 Factors\nA feature in a data set is categorical if it measures a qualitative category. Some examples of categories are:\n\nMusic genres rock, blues, alternative, folk, pop\nColors red, green, blue, yellow\nAnswers yes, no\nMonths January, February, and so on\n\nIn some cases, a feature can be interpreted as categorical or quantitative. For instance, months can be interpreted as categories, but they can also be interpreted as numbers. There’s not necessarily a “correct” interpretation; each can be useful for different kinds of analyses.\nR uses the class factor to represent categorical data. For instance, in the dogs data set, the group column is a factor:\n\nclass(dogs$group)\n\n[1] \"factor\"\n\n\nVisualizations and statistical models sometimes treat factors differently than other data types, so it’s important to think about whether you want R to interpret data as categorical.\nWhen you load a data set, R usually can’t tell which features are categorical. That means identifying and converting the categorical features is up to you. For beginners, it can be difficult to understand whether a feature is categorical or not. The key is to think about whether you want to use the feature to divide the data into groups.\nFor example, if we want to know how many songs are in the rock genre, we first need to divide the songs by genre, and then count the number of songs in each group (or at least the rock group).\nAs a second example, months recorded as numbers can be categorical or not, depending on how you want to use them. You might want to treat them as categorical (for example, to compute max rainfall in each month) or you might want to treat them as numbers (for example, to compute the number of months time between two events).\nThe bottom line is that you have to think about what you’ll be doing in the analysis. In some cases, you might treat a feature as categorical only for part of the analysis.\nYou can use the factor function to convert a vector into a factor:\n\ncolors = c(\"red\", \"green\", \"red\", \"blue\")\ncolors = factor(colors)\ncolors\n\n[1] red   green red   blue \nLevels: blue green red\n\n\nNotice that factors are printed differently than strings.\nThe categories of a factor are called levels. You can list the levels with the levels function:\n\nlevels(colors)\n\n[1] \"blue\"  \"green\" \"red\"  \n\n\nFactors remember all possible levels even if you take a subset:\n\ncolors[1:3]\n\n[1] red   green red  \nLevels: blue green red\n\n\nThis is another way factors are different from strings. Factors “remember” all possible levels even if they aren’t present. This ensures that if you plot a factor, the missing levels will still be represented on the plot.\nYou can make a factor forget levels that aren’t present with the droplevels function:\n\ndroplevels(colors[1:3])\n\n[1] red   green red  \nLevels: green red\n\n\n\n\n5.3.2 Special Values\nR has four special values to represent missing or invalid data.\n\n5.3.2.1 Missing Values\nThe value NA is called the missing value. Most of the time, missing values originate from how the data were collected (as opposed to computer errors). As an example, imagine the data came from a survey, and respondents chose not to answer some questions. In the data set, their answers for those questions might be recorded as NA.\nOf course, there are sometimes exceptions where missing values are the result of a computation. When you see missing values in a data set, you should think carefully about what the cause might be. Sometimes documentation or other parts of the data set provide clues.\nThe missing value is a chameleon: it can be a logical, integer, numeric, complex, or character value. By default, the missing value is logical, and the other types occur through coercion (Section 3.8.2):\n\nclass(NA)\n\n[1] \"logical\"\n\nclass(c(1, NA))\n\n[1] \"numeric\"\n\nclass(c(\"hi\", NA, NA))\n\n[1] \"character\"\n\n\nThe missing value is also contagious: it represents an unknown quantity, so using it as an argument to a function usually produces another missing value. The idea is that if the inputs to a computation are unknown, generally so is the output:\n\nNA - 3\n\n[1] NA\n\nmean(c(1, 2, NA))\n\n[1] NA\n\n\nAs a consequence, testing whether an object is equal to the missing value with == doesn’t return a meaningful result:\n\n5 == NA\n\n[1] NA\n\nNA == NA\n\n[1] NA\n\n\nYou can use the is.na function instead:\n\nis.na(5)\n\n[1] FALSE\n\nis.na(NA)\n\n[1] TRUE\n\nis.na(c(1, NA, 3))\n\n[1] FALSE  TRUE FALSE\n\n\nMissing values are a feature that sets R apart from most other programming languages.\n\n\n5.3.2.2 Not a Number\nThe value NaN, called not a number, represents a quantity that’s undefined mathematically. For instance, dividing 0 by 0 is undefined:\n\n0 / 0\n\n[1] NaN\n\nclass(NaN)\n\n[1] \"numeric\"\n\n\nNaN can be numeric or complex.\nYou can use the is.nan function to test whether a value is NaN:\n\nis.nan(c(10.1, log(-1), 3))\n\nWarning in log(-1): NaNs produced\n\n\n[1] FALSE  TRUE FALSE\n\n\n\n\n5.3.2.3 Infinity\nThe value Inf represents infinity, and can be numeric or complex. You’re most likely to encounter it as the result of certain computations:\n\n13 / 0\n\n[1] Inf\n\nclass(Inf)\n\n[1] \"numeric\"\n\n\nYou can use the is.infinite function to test whether a value is infinite:\n\nis.infinite(3)\n\n[1] FALSE\n\nis.infinite(c(-Inf, 0, Inf))\n\n[1]  TRUE FALSE  TRUE\n\n\n\n\n\n5.3.3 Indexing\nThe way to get and set elements of a data structure is by indexing. Sometimes this is also called subsetting or (element) extraction. Indexing is a fundamental operation in R, key to reasoning about how to solve problems with the language.\nWe first saw indexing in Section 3.6.1, where we used [, the indexing or square bracket operator, to get and set elements of vectors. We saw indexing again in Section 3.7, where we used $, the dollar sign operator, to get and set data frame columns.\nThe indexing operator [ is R’s primary operator for indexing. It works in four different ways, depending on the type of the index you use:\n\nAn empty index selects all elements\nA numeric index selects elements by position\nA character index selects elements by name\nA logical index selects elements for which the index is TRUE\n\nLet’s explore each in more detail. We’ll use this vector as an example, to keep things concise:\n\nx = c(a = 10, b = 20, c = 30, d = 40, e = 50)\nx\n\n a  b  c  d  e \n10 20 30 40 50 \n\n\nEven though we’re using a vector here, the indexing operator works with almost all data structures, including factors, lists, matrices, and data frames. We’ll look at unique behavior for some of these later on.\n\n5.3.3.1 All Elements\nThe first way to use [ to select elements is to leave the index blank. This selects all elements:\n\nx[]\n\n a  b  c  d  e \n10 20 30 40 50 \n\n\nThis way of indexing is rarely used for getting elements, since it’s the same as entering the variable name without the indexing operator. Instead, its main use is for setting elements. Suppose we want to set all the elements of x to 5. You might try writing this:\n\nx = 5\nx\n\n[1] 5\n\n\nRather than setting each element to 5, this sets x to the scalar 5, which is not what we want. Let’s reset the vector and try again, this time using the indexing operator:\n\nx = c(a = 10, b = 20, c = 30, d = 40, e = 50)\nx[] = 5\nx\n\na b c d e \n5 5 5 5 5 \n\n\nAs you can see, now all the elements are 5. So the indexing operator is necessary to specify that we want to set the elements rather than the whole variable.\nLet’s reset x one more time, so that we can use it again in the next example:\n\nx = c(a = 10, b = 20, c = 30, d = 40, e = 50)\n\n\n\n5.3.3.2 By Position\nThe second way to use [ is to select elements by position. This happens when you use an integer or numeric index. We already saw the basics of this in Section 3.6.1.\nThe positions of the elements in a vector (or other data structure) correspond to numbers starting from 1 for the first element. This way of indexing is frequently used together with the sequence operator : to get ranges of values. For instance, let’s get the 2nd through 4th elements of x:\n\nx[2:4]\n\n b  c  d \n20 30 40 \n\n\nYou can also use this way of indexing to set specific elements or ranges of elements. For example, let’s set the 3rd and 5th elements of x to 9 and 7, respectively:\n\nx[c(3, 5)] = c(9, 7)\nx\n\n a  b  c  d  e \n10 20  9 40  7 \n\n\nWhen getting elements, you can repeat numbers in the index to get the same element more than once. You can also use the order of the numbers to control the order of the elements:\n\nx[c(2, 1, 2, 2)]\n\n b  a  b  b \n20 10 20 20 \n\n\nFinally, if the index contains only negative numbers, the elements at those positions are excluded rather than selected. For instance, let’s get all elements except the 1st and 5th:\n\nx[-c(1, 5)]\n\n b  c  d \n20  9 40 \n\n\nWhen you index by position, the index should always be all positive or all negative. Using a mix of positive and negative numbers causes R to emit error rather than returning elements, since it’s unclear what the result should be:\n\nx[c(-1, 2)]\n\nError in x[c(-1, 2)]: only 0's may be mixed with negative subscripts\n\n\n\n\n5.3.3.3 By Name\nThe third way to use [ is to select elements by name. This happens when you use a character vector as the index, and only works with named data structures.\nLike indexing by position, you can use indexing by name to get or set elements. You can also use it to repeat elements or change the order. Let’s get elements a, c, d, and a again from the vector x:\n\ny = x[c(\"a\", \"c\", \"d\", \"a\")]\ny\n\n a  c  d  a \n10  9 40 10 \n\n\nElement names are generally unique, but if they’re not, indexing by name gets or sets the first element whose name matches the index:\n\ny[\"a\"]\n\n a \n10 \n\n\nLet’s reset x again to prepare for learning about the final way to index:\n\nx = c(a = 10, b = 20, c = 30, d = 40, e = 50)\n\n\n\n5.3.3.4 By Condition\nThe fourth and final way to use [ is to select elements based on a condition. This happens when you use a logical vector as the index. The logical vector should have the same length as what you’re indexing, and will be recycled (that is, repeated) if it doesn’t.\n\nCongruent Vectors\nTo understand indexing by condition, we first need to learn about congruent vectors. Two vectors are congruent if they have the same length and they correspond element-by-element.\nFor example, suppose you do a survey that records each respondent’s favorite animal and age. These are two different vectors of information, but each person will have a response for both. So you’ll have two vectors that are the same length:\n\nanimal = c(\"dog\", \"cat\", \"iguana\")\nage = c(31, 24, 72)\n\nThe 1st element of each vector corresponds to the 1st person, the 2nd to the 2nd person, and so on. These vectors are congruent.\nNotice that columns in a data frame are always congruent!\n\n\nBack to Indexing\nWhen you index by condition, the index should generally be congruent to the object you’re indexing. Elements where the index is TRUE are kept and elements where the index is FALSE are dropped.\nIf you create the index from a condition on the object, it’s automatically congruent. For instance, let’s make a condition based on the vector x:\n\nis_small = x &lt; 25\nis_small\n\n    a     b     c     d     e \n TRUE  TRUE FALSE FALSE FALSE \n\n\nThe 1st element in the logical vector is_small corresponds to the 1st element of x, the 2nd to the 2nd, and so on. The vectors x and is_small are congruent.\nIt makes sense to use is_small as an index for x, and it gives us all the elements less than 25:\n\nx[is_small]\n\n a  b \n10 20 \n\n\nOf course, you can also avoid using an intermediate variable for the condition:\n\nx[x &gt; 10]\n\n b  c  d  e \n20 30 40 50 \n\n\nIf you create index some other way (not using the object), make sure that it’s still congruent to the object. Otherwise, the subset returned from indexing might not be meaningful.\nYou can also use indexing by condition to set elements, just as the other ways of indexing can be used to set elements. For instance, let’s set all the elements of x that are greater than 10 to the missing value NA:\n\nx[x &gt; 10] = NA\nx\n\n a  b  c  d  e \n10 NA NA NA NA \n\n\n\n\n\n5.3.3.5 Indexing Lists\nLists are a container for other types of R objects. When you select an element from a list, you can either keep the container (the list) or discard it. The indexing operator [ almost always keeps containers.\nAs an example, let’s get some elements from a small list:\n\nx = list(first = c(1, 2, 3), second = sin, third = c(\"hi\", \"hello\"))\ny = x[c(1, 3)]\ny\n\n$first\n[1] 1 2 3\n\n$third\n[1] \"hi\"    \"hello\"\n\nclass(y)\n\n[1] \"list\"\n\n\nThe result is still a list. Even if we get just one element, the result of indexing a list with [ is a list:\n\nclass(x[1])\n\n[1] \"list\"\n\n\nSometimes this will be exactly what we want. But what if we want to get the first element of x so that we can use it in a vectorized function? Or in a function that only accepts numeric arguments? We need to somehow get the element and discard the container.\nThe solution to this problem is the extraction operator [[, which is also called the double square bracket operator. The extraction operator is the primary way to get and set elements of lists and other containers.\nUnlike the indexing operator [, the extraction operator always discards the container:\n\nx[[1]]\n\n[1] 1 2 3\n\nclass(x[[1]])\n\n[1] \"numeric\"\n\n\nThe trade off is that the extraction operator can only get or set one element at a time. Note that the element can be a vector, as above. Because it can only get or set one element at a time, the extraction operator can only index by position or name. Blank and logical indexes are not allowed.\nThe final difference between the index operator [ and the extraction operator [[ has to do with how they handle invalid indexes. The index operator [ returns NA for invalid vector elements, and NULL for invalid list elements:\n\nc(1, 2)[10]\n\n[1] NA\n\nx[10]\n\n$&lt;NA&gt;\nNULL\n\n\nOn the other hand, the extraction operator [[ raises an error for invalid elements:\n\nx[[10]]\n\nError in x[[10]]: subscript out of bounds\n\n\nThe indexing operator [ and the extraction operator [[ both work with any data structure that has elements. However, you’ll generally use the indexing operator [ to index vectors, and the extraction operator [[ to index containers (such as lists).\n\n\n5.3.3.6 Indexing Data Frames\nFor two-dimensional objects, like matrices and data frames, you can pass the indexing operator [ or the extraction operator [[ a separate index for each dimension. The rows come first:\nDATA[ROWS, COLUMNS]\nFor instance, let’s get the first 3 rows and all columns of the dogs data:\n\ndogs[1:3, ]\n\n           breed    group datadog popularity_all popularity lifetime_cost\n1  Border Collie  herding    3.64             45         39         20143\n2 Border Terrier  terrier    3.61             80         61         22638\n3       Brittany sporting    3.54             30         30         22589\n  intelligence_rank longevity ailments price food_cost grooming   kids\n1                 1     12.52        2   623       324   weekly    low\n2                30     14.00        0   833       324   weekly   high\n3                19     12.92        0   618       466   weekly medium\n  megarank_kids megarank   size weight height\n1             1       29 medium     NA     20\n2             2        1  small   13.5     NA\n3             3       11 medium   35.0     19\n\n\nAs we saw in Section 5.3.3.1, leaving an index blank means all elements.\nAs another example, let’s get the 3rd and 5th row, and the 2nd and 4th column:\n\ndogs[c(3, 5), c(2, 4)]\n\n     group popularity_all\n3 sporting             30\n5 sporting            130\n\n\nMixing several different ways of indexing is allowed. So for example, we can get the same above, but use column names instead of positions:\n\ndogs[c(3, 5), c(\"breed\", \"longevity\")]\n\n                   breed longevity\n3               Brittany     12.92\n5 Welsh Springer Spaniel     12.49\n\n\nFor data frames, it’s especially common to index the rows by condition and the columns by name. For instance, let’s get the breed, popularity, and weight columns for all rows with toy dogs:\n\nresult = dogs[dogs$group == \"toy\", c(\"breed\", \"popularity\", \"weight\")]\nhead(result)\n\n           breed popularity weight\n8       Papillon         33     NA\n13 Affenpinscher         84     NA\n16     Chihuahua         14    5.5\n28       Maltese         23    5.0\n29    Pomeranian         17    5.0\n30      Shih Tzu         11   12.5\n\n\n\n\n\n\n\n\nThe Drop Parameter\n\n\n\nIf you use two-dimensional indexing with [ to select exactly one column, you get a vector:\n\nresult = dogs[1:3, 2]\nclass(result)\n\n[1] \"factor\"\n\n\nThe container is dropped, even though the indexing operator [ usually keeps containers. This also occurs for matrices. You can control this behavior with the drop parameter:\n\nresult = dogs[1:3, 2, drop = FALSE]\nclass(result)\n\n[1] \"data.frame\"\n\n\nThe default is drop = TRUE.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Files, Packages, and Data</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html",
    "href": "chapters/06_data-structures.html",
    "title": "6  Data Structures",
    "section": "",
    "text": "6.1 What Are Data?\nMerriam-Webster’s Dictionary defines data as:\nSeveral key principals are introduced in the above definition:\nData Scientists (as differentiated from statisticians or computer scientists, for example) are expert in understanding the nature of data itself and the steps necessary to assess the suitability of a given data set for answering specific research questions and the work required to properly prepare data for successful analysis. In the broadest terms, we call this process data forensics.\nThe first step in the data forensics process is understanding the format(s) through which data are stored and transferred.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#what-are-data",
    "href": "chapters/06_data-structures.html#what-are-data",
    "title": "6  Data Structures",
    "section": "",
    "text": "factual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation\ninformation in digital form that can be transmitted or processed\ninformation output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful\n\n\n\ndata is an intermediary step leading towards some form of analysis or or presentation, not typically an end in itself\ndata comes in multiple formats, both digital and analogue\ndata can be collected by both humans and machines\nnot all data in a given dataset is necessarily meaningful, correct nor useful",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#tabular-data",
    "href": "chapters/06_data-structures.html#tabular-data",
    "title": "6  Data Structures",
    "section": "6.2 Tabular Data",
    "text": "6.2 Tabular Data\nTabular data is the most ubiquitous form of data storage and the one most familiar to most users. Tabular data consists of organizing data in a table of rows and columns. Traditionally, each column in the table represents a field or variable and each row represents an observation or entity. For example, the table below shows a tabular organization of a subset of the mtcars dataset:\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n\n\nValiant\n18.1\n6\n225.0\n105\n\n\nDuster 360\n14.3\n8\n360.0\n245\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n\n\nMerc 230\n22.8\n4\n140.8\n95\n\n\nMerc 280\n19.2\n6\n167.6\n123",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#tree-document-data-structures",
    "href": "chapters/06_data-structures.html#tree-document-data-structures",
    "title": "6  Data Structures",
    "section": "6.3 Tree / Document Data Structures",
    "text": "6.3 Tree / Document Data Structures\nAnother popular form of data structure is the tree structure, sometimes referred to as a document-based data structure. Tree data structures present data in a hierarchical tree-like structure in which all items related back to a single, root node. A “Family Tree” is a good example of tree structured data:\n\nThe mtcars data from the above table can also be represented using a tree structure:\n\nThe above image visually depicts the mtcars data as a tree, which works well for a human reader but is not parsable by the computer. There are a variety of ways to represent tree data as a computer file (or data stream) so that it can be read and parsed by the computer. In this class, we will cover two of the most popular formats: XML and JSON.\n\n6.3.1 Structuring Data as XML\nXML stands for extensible markup language. Markup languages have been around since the 1960s and were originally developed as a means of adding structured information to an existing unstructured text. In the days of analog text preparation, professional editors typically used a blue or red pencil to make notes on typed manuscripts. The use of a specially colored pen or pencil for “marking up” documents, as the procedure was known in the industry, easily allowed subsequent readers to distinguish between editorial comments and formatting notes on typed manuscripts from the text itself. Computerized markup languages were developed as a means of allowing data specialists to markup a text in a manner that would allow the computer to distinguish between textual content and meta-information (information about the text) when both types of information appear in the same file.\nXML is the most widely used form of markup today. In fact, nearly every webpage that you have ever viewed is actually an XML document that contains both content to be displayed and instructions for the computer on how to display that content embedded in the file using XML tags, which are simply instructions contained with the special characters &lt; and &gt;. For example, consider the following short email text:\nTo: Tavi\nFrom: Jonna\nSubject: Meeting\nDate: Thursday, February 4, 2021 at 2:46 PM\n\nDon't forget about meeting with Sarah next week, 2pm in room 242.\n\nThanks,\n\nJonna\nThis email contains quite a bit of structured email (sender, receiver, date/time, etc.), but there is no easy way for the computer easily extract this structure. We can solve this problem by using XML to embed information about the structure directly in the document as follows:\n&lt;head&gt;\n   &lt;to&gt;Tavi&lt;/to&gt;\n   &lt;from&gt;Jonna&lt;/from&gt;\n   &lt;subject&gt;Meeting&lt;/subject&gt;\n   &lt;datetime&gt;\n      &lt;dayofweek&gt;Thursday&lt;/dayofweek&gt;\n      &lt;month&gt;February&lt;/month&gt;\n      &lt;day&gt;4&lt;/day&gt;\n      &lt;year&gt;2021&lt;/year&gt;\n      &lt;time&gt;2:46 PM&lt;/time&gt;\n   &lt;/datetime&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n   Don't forget about meeting with Sarah next week, 2pm in room 242.\n\n   Thanks,\n\n   &lt;signature&gt;Jonna&lt;/signuature&gt;\n&lt;/body&gt;\nBy using XML, we are able to identify specific information in the email in a way that the computer is a capable of parsing. This allows us to use computational methods to easily extract information in bulk from many emails and it also allows us to program a computer program, such as an email client, to organize and properly display all of the parts of the email.\nThe above XML example illustrates several important aspects of XML:\n\nAll XML tags are enclosed in &lt; and &gt; symbols.\nThere are 2 primary types of tags, opening tags, which designate the beginning character that is defined by the tag, and closing tags, which designate the end of the portion of the text to be associated with the opening tag.\nClosing tags are always indicated by slash character, as in &lt;/TAG&gt;, where TAG is the name of the opening tag that is being closed.\nTags be be embedded within each other in a tree-like structure. However, any tags opened within a tag must be closed before that tag can be closed. For example, &lt;name&gt;&lt;first&gt;John&lt;/first&gt; &lt;last&gt;Doe&lt;/last&gt;&lt;/name&gt; is valid, but &lt;name&gt;&lt;first&gt;John&lt;/first&gt; &lt;last&gt;Doe&lt;/name&gt;&lt;/last&gt; is not valid.\n\nWhile XML was originally developed as a means of embedding meta information about a text directly in a text, it also quickly evolved into a stand-alone means of representing tree-structured data for exchange between computer systems. To this end, many computer applications use XML to store, share, and retrieve data. For example, we can represent the data in our truncated mtcars dataset as XML as follows:\n&lt;cars&gt;\n   &lt;make id=\"mazda\"&gt;\n      &lt;model id=\"RX4\"&gt;\n         &lt;mpg&gt;21.0&lt;/mpg&gt;\n         &lt;cyl&gt;6&lt;/cyl&gt;\n         &lt;disp&gt;160.0&lt;/disp&gt;\n         &lt;hp&gt;110&lt;/hp&gt;\n      &lt;/model&gt;\n      &lt;model id=\"RX4 Wag\"&gt;\n         &lt;mpg&gt;21.0&lt;/mpg&gt;\n         &lt;cyl&gt;6&lt;/cyl&gt;\n         &lt;disp&gt;160.0&lt;/disp&gt;\n         &lt;hp&gt;110&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n   &lt;make id=\"Datsun\"&gt;\n      &lt;model id=\"710\"&gt;\n         &lt;mpg&gt;22.8&lt;/mpg&gt;\n         &lt;cyl&gt;4&lt;/cyl&gt;\n         &lt;disp&gt;108.0&lt;/disp&gt;\n         &lt;hp&gt;93&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n   &lt;make id=\"Hornet\"&gt;\n      &lt;model id=\"4 Drive\"&gt;\n         &lt;mpg&gt;21.4&lt;/mpg&gt;\n         &lt;cyl&gt;6&lt;/cyl&gt;\n         &lt;disp&gt;258.0&lt;/disp&gt;\n         &lt;hp&gt;110&lt;/hp&gt;\n      &lt;/model&gt;\n      &lt;model id=\"Sportabout\"&gt;\n         &lt;mpg&gt;18.7&lt;/mpg&gt;\n         &lt;cyl&gt;8&lt;/cyl&gt;\n         &lt;disp&gt;360.0&lt;/disp&gt;\n         &lt;hp&gt;175&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n   &lt;make id=\"Valiant\"&gt;\n      &lt;model id=\"valiant\"&gt;\n         &lt;mpg&gt;18.1&lt;/mpg&gt;\n         &lt;cyl&gt;6&lt;/cyl&gt;\n         &lt;disp&gt;225.0&lt;/disp&gt;\n         &lt;hp&gt;105&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n   &lt;make id=\"Duster\"&gt;\n      &lt;model id=\"360\"&gt;\n         &lt;mpg&gt;14.3&lt;/mpg&gt;\n         &lt;cyl&gt;8&lt;/cyl&gt;\n         &lt;disp&gt;360.0&lt;/disp&gt;\n         &lt;hp&gt;245&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n   &lt;make id=\"Merc\"&gt;\n      &lt;model id=\"240D\"&gt;\n         &lt;mpg&gt;24.4&lt;/mpg&gt;\n         &lt;cyl&gt;4&lt;/cyl&gt;\n         &lt;disp&gt;146.7&lt;/disp&gt;\n         &lt;hp&gt;62&lt;/hp&gt;\n      &lt;/model&gt;\n      &lt;model id=\"230\"&gt;\n         &lt;mpg&gt;22.8&lt;/mpg&gt;\n         &lt;cyl&gt;4&lt;/cyl&gt;\n         &lt;disp&gt;140.8&lt;/disp&gt;\n         &lt;hp&gt;95&lt;/hp&gt;\n      &lt;/model&gt;\n      &lt;model id=\"280\"&gt;\n         &lt;mpg&gt;19.2&lt;/mpg&gt;\n         &lt;cyl&gt;6&lt;/cyl&gt;\n         &lt;disp&gt;167.6&lt;/disp&gt;\n         &lt;hp&gt;123&lt;/hp&gt;\n      &lt;/model&gt;\n   &lt;/make&gt;\n&lt;/cars&gt;\nFor an XML dataset to be technically valid, the tags used to markup the dataset must themselves be defined according to a schema, another XML document that defines all tags that can be used in marking up a dataset and the allowable tree structure of the markup (for example, which tags can be parents of which other tags, etc.). You do not need to understand, or even know, the schema being used to present data in order to read and parse an XML document. However, schemas are extremely useful (and often necessary) for building applications that perform advanced processing of XML documents, such as web browsers, email clients, etc.\n\n\n\n\n\n\nSee also\n\n\n\nFor more information on XML and XML schemas, see the W3Schools XML Tutorial.\n\n\n\n\n6.3.2 Structuring Data as JSON\nXML provides an excellent framework for encoding, saving, and transferring all kinds of data, and it was the dominant mode of transferring data across the internet for many years. However, XML has an Achilles’ Heel from the data transfer perspective: a lack of sparsity. If you look closely at the XML mtcars data set example above, you will note that the markup accounts for more of the total characters in the document than the data itself. In a world where data is regularly being exchanged in real time across networks, the use of XML can result in the necessity to exchange a lot more data to accomplish the same task. This adds both time and cost to every data transaction.\nJavaScript object notation (JSON) was developed as a standard to address this problem and provides a sparse framework for representing data that introduces minimal, non-data elements into the overall data structure. JSON uses a key/value pair structure to represent data elements:\n\"model\": \"RX4\"\nIndividual data elements are then grouped to reflect more complex data structures:\n{\"model\": {\"id\": \"2\", \"hp\": \"120\"}}\nThe example below shows the subsetted mtcars dataset represented as JSON. Note the use of the [ character to indicated repeated elements in the data:\n{\n    \"cars\": [{\n            \"make\": \"Mazda\",\n            \"model\": [{\n                    \"id\": \"RX4\",\n                    \"mpg\": \"21.0\",\n                    \"cyl\": \"6\",\n                    \"disp\": \"160.0\",\n                    \"hp\": \"110\"\n                },\n                {\n                    \"id\": \"RX4 Wag\",\n                    \"mpg\": \"21.0\",\n                    \"cyl\": \"6\",\n                    \"disp\": \"160.0\",\n                    \"hp\": \"110\"\n                }\n            ]\n        },\n        {\n            \"make\": \"Datsun\",\n            \"model\": {\n                \"id\": \"710\",\n                \"mpg\": \"22.8\",\n                \"cyl\": \"4\",\n                \"disp\": \"108.0\",\n                \"hp\": \"93\"\n            }\n        },\n        {\n            \"make\": \"Hornet\",\n            \"model\": [{\n                    \"id\": \"4 Drive\",\n                    \"mpg\": \"21.4\",\n                    \"cyl\": \"6\",\n                    \"disp\": \"258.0\",\n                    \"hp\": \"110\"\n                },\n                {\n                    \"id\": \"Sportabout\",\n                    \"mpg\": \"18.7\",\n                    \"cyl\": \"8\",\n                    \"disp\": \"360.0\",\n                    \"hp\": \"175\"\n                }\n            ]\n        },\n        {\n            \"make\": \"Valiant\",\n            \"model\": {\n                \"id\": \"valiant\",\n                \"mpg\": \"18.1\",\n                \"cyl\": \"6\",\n                \"disp\": \"225.0\",\n                \"hp\": \"105\"\n            }\n        },\n        {\n            \"make\": \"Duster\",\n            \"model\": {\n                \"id\": \"360\",\n                \"mpg\": \"14.3\",\n                \"cyl\": \"8\",\n                \"disp\": \"360.0\",\n                \"hp\": \"245\"\n            }\n        },\n        {\n            \"make\": \"Merc\",\n            \"model\": [{\n                    \"id\": \"240D\",\n                    \"mpg\": \"24.4\",\n                    \"cyl\": \"4\",\n                    \"disp\": \"146.7\",\n                    \"hp\": \"62\"\n                },\n                {\n                    \"id\": \"230\",\n                    \"mpg\": \"22.8\",\n                    \"cyl\": \"4\",\n                    \"disp\": \"140.8\",\n                    \"hp\": \"95\"\n                },\n                {\n                    \"id\": \"280\",\n                    \"mpg\": \"19.2\",\n                    \"cyl\": \"6\",\n                    \"disp\": \"167.6\",\n                    \"hp\": \"123\"\n                }\n            ]\n        }\n    ]\n}\n\n\n\n\n\n\nSee also\n\n\n\nFor information on the JSON format, see the Tutorials Point JSON Tutorial.\nYou can also use the JSONLint JSON Validator to check the syntax of any JSON representation.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#relational-databases",
    "href": "chapters/06_data-structures.html#relational-databases",
    "title": "6  Data Structures",
    "section": "6.4 Relational Databases",
    "text": "6.4 Relational Databases\n*Relational databases, frequently referred to as relational database management systems** (RDBMS), provide another way of structuring data. Unlike tabular, XML, and JSON data representations, RDBMS data is not easily human readable, and specialized software is usually required to interact with data stored as relational data. Most programming environments (including R) provide specialized drivers for communicating with RDBMS in order to facilitate working with data stored in these systems.\nRDBMS have three primary purposes as a data storage format:\n\nTo reduce duplication of data;\nTo speed-up access and insertion of new data;\nTo insure data integrity.\n\nItems 2 and 3 above are accomplished at the software level, by deploying strict checks on data input, complex data indexing systems, and implementing redundant, automated, backup systems, to name just a few of the functionalities offered by RDBMS. Item 1 above, reducing duplication of data, is accomplished by using a specific, relational data structure that encourages the use of controlled lists of data mapped to individual observations. Looking at our mtcars subset data, for example, we see that while there are ten observations, there are only 6 makes of cars. To represent this in RDBMS, we first create a table, a named collection of data, that contains a unique list of car makes:\n\n\n\n\n\n\n\n\n\nid\nMake\n\n\n\n\n1\nMazda\n\n\n2\nDatsun\n\n\n3\nHornet\n\n\n4\nValiant\n\n\n5\nDuster\n\n\n6\nMerc\n\n\n\n\n\n\n\n\nFigure 6.1: MAKE_TABLE\n\n\n\nOnce we have a table of unique lists, we then create and populate a table of our cars, associating each car with its appropriate make from the MAKE_TABLE table:\n\n\n\n\n\n\n\n\n\nMake\nModel\nmpg\ncyl\ndisp\nhp\n\n\n\n\n1\nRX4\n21.0\n6\n160.0\n110\n\n\n1\nRX4 Wag\n21.0\n6\n160.0\n110\n\n\n2\n710\n22.8\n4\n108.0\n93\n\n\n3\n4 Drive\n21.4\n6\n258.0\n110\n\n\n3\nSportabout\n18.7\n8\n360.0\n175\n\n\n4\nValiant\n18.1\n6\n225.0\n105\n\n\n5\n360\n14.3\n8\n360.0\n245\n\n\n6\n240D\n24.4\n4\n146.7\n62\n\n\n6\n230\n22.8\n4\n140.8\n95\n\n\n6\n280\n19.2\n6\n167.6\n123\n\n\n\n\n\n\n\n\nFigure 6.2: CARS_TABLE\n\n\n\nIn the above table, we only normalized the car Make field. In a fully normalized RDBMS data structure, we would also create a control table for the Model field in anticipation of the fact that we could have more than one observation for a given model. Fully normalized RBDMS data structures use control tables for all fields that contain string data.\nThe image below shows a sample entry relationship diagram (ERD) for a more complex dataset relating to course offerings and enrollments. Each line connecting two tables marks a field in a “join” table that uses the id field in a control table (known as a foreign key) to associate information in the control table with the records in the join table.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#non-hierarchical-relational-data",
    "href": "chapters/06_data-structures.html#non-hierarchical-relational-data",
    "title": "6  Data Structures",
    "section": "6.5 Non-Hierarchical Relational Data",
    "text": "6.5 Non-Hierarchical Relational Data\nIn the era of the social network, it is becoming increasingly necessary to represent relationships between entities that are not hierarchical. Unlike a family tree, the fact that you are connected to someone on Facebook or Instagram does not imply any type of hierarchical relationship. Such networks are typically represented using the graph data structure:\n\nGraphs consist of collections of vertices or nodes, the entities being graphed, and edges, the relationships between nodes.\n\nAnother important aspect of graph data is the concept of directionality. A directed graph indicates the direction of the relationship identified by the edge. We might, for example, wish to draw edges that indicate that one node was influenced by another node, in which case we could identify an “influence” edge and use directionality to indicate who influenced whom:\n\nGraph data can be stored and or transferred using any of the data formats discussed above or using specialized graph databases management software.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-structures.html#geospatial-data",
    "href": "chapters/06_data-structures.html#geospatial-data",
    "title": "6  Data Structures",
    "section": "6.6 Geospatial Data",
    "text": "6.6 Geospatial Data\nGeospatial data represents a final type of data with its own unique data structure. Geospatial data is unique because it always relates directly to the physical world, and because it relies on world-wide standards which have been in development and communally accepted for hundreds of years. Because of its uniqueness as a data type, geospatial data is covered as a stand-alone topic in Chapter 16.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/07_data-forensics.html",
    "href": "chapters/07_data-forensics.html",
    "title": "7  Data Forensics",
    "section": "",
    "text": "7.1 Structural Summaries & Cleaning\nWhenever you load a data set into R, your next step should be to investigate the data’s structure. This step is important because it can help you identify whether:\nSection 3.7.2 and Section 5.1.3.2.1 demonstrated several functions for getting structural summaries of data. Some of these are:\nLet’s look at some examples using a data set collected from the classified advertisements website Craigslist. The data set contains information from ads for rentals in the Sacramento area. First we need to load the data set:\ncl = read.csv(\"data/cl_rentals.csv\")\nNow we can use the str function to check the classes of the columns:\nstr(cl)\n\n'data.frame':   2987 obs. of  20 variables:\n $ title       : chr  \"$1,125 / 1br - 550ft2 - 1Bedroom Prime Location -2520 S Limited Access/Gated $1125 Avail Now (2520 S St)\" \"$1,449 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\" \"$1,449 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\" \"$1,479 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\" ...\n $ text        : chr  \"QR Code Link to This Post\\n            \\n        \\n* SEE MY OTHER MIDTOWN 1 bedroom apts-text for web site\\n*An\"| __truncated__ \"QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1449+    Pric\"| __truncated__ \"QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1449+    Pric\"| __truncated__ \"QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1479+    Pric\"| __truncated__ ...\n $ latitude    : num  38.6 38.6 38.6 38.6 38.6 ...\n $ longitude   : num  -121 -121 -121 -121 -121 ...\n $ city        : chr  \"2520 S St\" \"The Phoenix/Sacramento/Folsom/SF\" \"The Phoenix/Sacramento/Folsom/SF\" \"The Phoenix/Sacramento/Folsom/SF\" ...\n $ date_posted : chr  \"2021-02-04 15:03:12\" \"2021-03-02 12:41:17\" \"2021-03-02 13:26:17\" \"2021-03-03 10:02:05\" ...\n $ date_updated: chr  \"2021-03-03 08:41:39\" NA NA NA ...\n $ price       : int  1125 1449 1449 1479 1414 1441 1615 1660 1877 1611 ...\n $ deleted     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ sqft        : int  550 680 680 680 680 680 816 816 916 916 ...\n $ bedrooms    : int  1 1 1 1 1 1 2 2 2 2 ...\n $ bathrooms   : num  1 1 1 1 1 1 1 1 2 2 ...\n $ pets        : chr  NA \"both\" \"both\" \"both\" ...\n $ laundry     : chr  \"shared\" \"in-unit\" \"in-unit\" \"in-unit\" ...\n $ parking     : chr  \"off-street\" \"covered\" \"covered\" \"covered\" ...\n $ craigslist  : chr  \"sacramento\" \"sacramento\" \"sacramento\" \"sacramento\" ...\n $ shp_place   : chr  \"Sacramento\" \"Sacramento\" \"Sacramento\" \"Sacramento\" ...\n $ shp_city    : chr  \"Sacramento\" \"Sacramento\" \"Sacramento\" \"Sacramento\" ...\n $ shp_state   : chr  \"CA\" \"CA\" \"CA\" \"CA\" ...\n $ shp_county  : chr  \"Sacramento\" \"Sacramento\" \"Sacramento\" \"Sacramento\" ...\nOften when you load a new data set, some of the columns won’t have the correct data type (or class) for what you want to do. For instance, in the Craigslist data, the pets, laundry, and parking columns all contain categorical data, so they should be factors.\nYou can convert these columns to factors with the factor function from Section 5.3.1:\ncl$pets = factor(cl$pets)\ncl$laundry = factor(cl$laundry)\ncl$parking = factor(cl$parking)\nThere’s another way we could’ve done this that uses only two lines of code, no matter how many columns there are:\ncols = c(\"pets\", \"laundry\", \"parking\")\ncl[cols] = lapply(cl[cols], factor)\nWe’ll learn more about the lapply function in Section 7.3.\nYou can use whichever approach is more convenient and makes more sense to you. If there were other columns to convert, we’d go through the same steps with the appropriate conversion function.\nR provides as. functions to convert to the most common data types. For instance, as.character converts an object to a string:\nx = 3.1\nclass(x)\n\n[1] \"numeric\"\n\ny = as.character(x)\ny\n\n[1] \"3.1\"\n\nclass(y)\n\n[1] \"character\"\nThe read.csv function does a good job at identifying columns of numbers, so it’s rarely necessary to convert columns of numbers manually. However, you may have to do this for data you got some other way (rather than loading a file). For instance, it’s common to make these conversions when scraping data from the web.\nIt’s also a good idea to convert categorical columns into factors with the factor function, and to convert columns of dates into dates (more about this in the next section).",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Forensics</span>"
    ]
  },
  {
    "objectID": "chapters/07_data-forensics.html#structural-summaries-cleaning",
    "href": "chapters/07_data-forensics.html#structural-summaries-cleaning",
    "title": "7  Data Forensics",
    "section": "",
    "text": "The data was loaded correctly\nThere are structural problems with the data that will make it difficult to use if they aren’t fixed\n\n\n\nstr to get a detailed structural summary\nhead, tail to preview the data\nnrow, ncol, dim, length to get dimension information\nnames, colnames, rownames to get element names\nclass, typeof to get classes and types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.1 Dates\nThere several built-in functions and also many packages for date processing. In particular, there are three Tidyverse packages for processing dates and times:\n\nlubridate, the primary package for working with dates and times\nhms, a package specifically for working with times\nclock, a new package for working with dates and times\n\nWe’ll focus on the lubridate package. As always, you’ll have to install the package if you haven’t already, and then load it:\n\n# install.packages(\"lubridate\")\nlibrary(\"lubridate\")\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nThe most common task is to convert a string into a date or time class. For instance, when you load a data set, you might have dates that look like this:\n\ndates = c(\"Jan 10, 2021\", \"Sep 3, 2018\", \"Feb 28, 1982\")\ndates\n\n[1] \"Jan 10, 2021\" \"Sep 3, 2018\"  \"Feb 28, 1982\"\n\n\nThese are strings, so it’s relatively difficult to sort the dates, do arithmetic on them, or extract just one part (such as the year). There are several lubridate functions to automatically convert strings into dates. They are named with one letter for each part of the date. For instance, the dates in the example have the month (m), then the day (d), and then the year (y), so we can use the mdy function:\n\nresult = mdy(dates)\nresult\n\n[1] \"2021-01-10\" \"2018-09-03\" \"1982-02-28\"\n\nclass(result)\n\n[1] \"Date\"\n\n\nNotice that the dates now have class Date, one of R’s built-in classes for representing dates, and that they print differently. You can find a full list of the automatic string to date conversion functions in the lubridate documentation.\nOccasionally, a date string may have a format that lubridate can’t convert automatically. In that case, you can use the fast_strptime function to describe the format in detail. At a minimum, the function requires two arguments: the vector of strings to convert and a format string.\nThe format string describes the format of the dates, and is based on the syntax of strptime, a function provided by many programming languages for converting strings to dates (including R). In a format string, a percent sign % followed by a character is called a specification and has a special meaning. Here are a few of the most useful ones:\n\n\n\nSpecification\nDescription\nJanuary 29, 2015\n\n\n\n\n%Y\n4-digit year\n2015\n\n\n%y\n2-digit year\n15\n\n\n%m\n2-digit month\n01\n\n\n%B\nfull month name\nJanuary\n\n\n%b\nshort month name\nJan\n\n\n%d\nday of month\n29\n\n\n%%\nliteral %\n%\n\n\n\nYou can find a complete list in ?fast_strptime. Other characters in the format string do not have any special meaning. Write the format string so that it matches the format of the dates you want to convert.\nFor example, let’s try converting an unusual time format:\n\nodd_time = \"6 minutes, 32 seconds after 10 o'clock\"\nfast_strptime(odd_time, \"%M minutes, %S seconds after %H o'clock\")\n\n[1] \"0-01-01 10:06:32 UTC\"\n\n\nR usually represents dates with the class Date, and date-times with the classes POSIXct and POSIXlt. The difference between the two date-time classes is somewhat technical, but you can read more about it in ?POSIXlt.\nThere is no built-in class to represent times alone, which is why the result in the example above includes a date. Nonetheless, the hms package provides the hms class to represent times without dates.\nOnce you’ve converted a string to a date, the lubridate package provides a variety of functions to get or set the parts individually. Here are a few examples:\n\nday(result)\n\n[1] 10  3 28\n\nmonth(result)\n\n[1] 1 9 2\n\n\nYou can find a complete list in the lubridate documentation.\nNow let’s convert the date_updated column in the Craigslist data. It’s always a good idea to test your format string before saving the results back into the data frame:\n\ndates = ymd_hms(cl$date_updated)\nhead(dates)\n\n[1] \"2021-03-03 08:41:39 UTC\" NA                       \n[3] NA                        NA                       \n[5] NA                        NA                       \n\n\nThe as.Date function returns NA if conversion failed, so in this case it looks like the dates were converted correctly. Now we can save the dates back into the data frame.\n\ncl$date_updated = dates\n\n\n\n7.1.2 Tidy Data\nMany functions require data frames that are in tidy form. Before we see the requirements for a data set to be tidy, we need to define or review some terminology from statistics.\nA feature (also called a covariate) is measurement of something, usually across multiple subjects. For example, we might decide to measure the heights of everyone in the class. Each person in the class is a subject, and the height measurement is a feature. Features don’t have to be quantitative. If we also asked each person their favorite color, then favorite color would be another feature in our data set. Features are usually, but not always, the columns in a tabular data set.\nAn observation is a set of features measured for a single subject or at a single time. So in the preceding example, the combined height and favorite color measurement for one student is one observation. Observations are usually, but not always, the rows in a tabular data set.\nNow we can define what it means to be tidy. A tabular data set is tidy if and only if:\n\nEach observation has its own row.\nEach feature has its own column.\nEach value has its own cell.\n\nThese rules ensure that all of the values are visually organized and are easy to access with R’s built-in indexing operations. For instance, the $ operator gets a column, and in a tidy data set, columns are features. The rules also reflect the way statisticians traditionally arrange tabular data sets.\nWhen you first look at a data set, think about what the observations are and what the features are. If the data set comes with documentation, it may help you figure this out. Since this data set is a tidy data set, we already know each row is an observation and each column is a feature.\nChapter 13 gives examples of tidy and untidy data, as well as explanations of how to make untidy data tidy.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Forensics</span>"
    ]
  },
  {
    "objectID": "chapters/07_data-forensics.html#statistical-forensics",
    "href": "chapters/07_data-forensics.html#statistical-forensics",
    "title": "7  Data Forensics",
    "section": "7.2 Statistical Forensics",
    "text": "7.2 Statistical Forensics\nAfter investigating the data’s structure, it’s a good idea to check some basic statistical properties. This step is important because it can help you identify limitations of and patterns in the data.\nWhich statistics are appropriate for a given feature often depends on the type of the feature. Recall from Section 3.8 that the types statisticians typically think about are:\n\nCategorical\n\nNominal - data separated into specific categories, with no order. For example, hair color (red, brown, blonde, …) is categorical.\nOrdinal - data separated into specific categories, with an order. For example, school level (elementary, middle, high, college) is ordinal.\n\nNumerical\n\nDiscrete - integers, or a finite set of decimal numbers with no values in between. Sometimes discrete values can also be treated as ordinal. For example, month as a number (1, 2, …, 12) is discrete.\nContinuous - decimal numbers. There are no specific categories, but there is an order. For example, height in inches is numerical.\n\n\nThe table function, which was introduced in Section 3.7.2, is great for summarizing categorical (and sometimes discrete) data. For example:\n\ntable(cl$pets)\n\n\nboth cats dogs none \n2511   46   31  385 \n\n\nWhat about numerical data?\nTwo important questions to ask about data are:\n\nWhere is it? This is the location of the data.\nHow spread out is it? This is the scale of the data.\n\nLet’s use the data\nx = c(-2, -1, -1, -1, 0, 2, 6)\nas an example.\nLocation is generally summarized with a number near the middle or center of the data. A few options are:\n\nMode - the value that appears most frequently. The mode can be calculated for any kind of data, but doesn’t work well for continuous data.\nFor our example, the mode of x is -1. You can compute the mode with table:\ntable(x)\nMedian - sort the data, then find the value in the middle. The median can be calculated for ordinal or numerical data.\nFor our example, the median is -1. Compute this with median:\nmedian(x)\nMean - the balancing point of the data, if a waiter was trying to balance the data on a tray. The mean can only be calculated for numerical data.\nFor our example the mean is 0.4285. Compute this with mean:\nmean(x)\n\nAdding large values to the data affects the mean more than the median:\ny = c(x, 100)\nmean(y)\nmedian(y)\nBecause of this, we say that the median is robust.\nThe mean is good for getting a general idea of where the center of the data is, while comparing it with the median reveals whether there are any unusually large or small values.\nScale is generally summarized by a number that says how far the data is from the center (mean, median, etc…). Two options are:\n\nStandard Deviation - square root of the average squared distance to the mean (the distance from a point to a mean is called a deviation). You can think of this as approximately the average distance from a data point to the mean. As a rule of thumb, most of the data will be within 3 standard deviations of the mean.\nYou can compute the standard deviation with sd:\nsd(x)\nInterquartile Range (IQR) - difference between the 75th and 25th percentile. The median is the 50th percentile of the data; it’s at the middle of the sorted data. We can also consider other percentiles. For instance, the 25th percentile is the value one-quarter of the way through the sorted data.\nQuantile is another word for percentile. Quartile specifically refers to the 25th, 50th, and 75th percentiles because they separate the data into four parts (hence “quart-”).\nYou can compute quantiles with quantile, or compute the IQR directly with IQR:\nquantile(x)\n\n# IQR\nIQR(x)\n\nThe IQR is more robust than the standard deviation.\nMany of the functions for computing statistical summaries have a parameter na.rm to ignore missing values. Setting na.rm = TRUE is often useful when you’re just trying to do an initial investigation of the data. However, in a more complete analysis, you should think carefully about what the missing values mean, whether they follow any patterns, and whether there are enough non-missing values for statistical summaries to be good representatives of the data.\nFinally, the summary function computes a detailed statistical summary of an R object. For data frames, the function computes a summary of each column, guessing an appropriate statistic based on the column’s data type.\n\n7.2.1 Missing Values\nIf your data contains missing values, it’s important to think about why the values are missing. Statisticians use two different terms to describe why data is missing:\n\nmissing at random (MAR)\nmissing not at random (MNAR) - causes bias!\n\nWhen values are missing at random, the cause for missingness is not related to any of the other features. This is rare in practice. For example, if people in a food survey accidentally overlook some questions.\nWhen values are missing not at random, the cause for missingness depends on other features. These features may or may not be in the data set. Think of this as a form of censorship. For example, if people in a food survey refuse to report how much sugar they ate on days where they ate junk food, data is missing not at random. Values MNAR can bias an analysis.\nThe default way to handle missing values in R is to ignore them. This is just a default, not necessarily the best or even an appropriate way to deal with them. You can remove missing values from a data set by indexing:\n\ncl_no_sqft_na = cl[!is.na(cl$sqft), ]\n\nhead(cl_no_sqft_na)\n\n                                                                                                       title\n1   $1,125 / 1br - 550ft2 - 1Bedroom Prime Location -2520 S Limited Access/Gated $1125 Avail Now (2520 S St)\n2 $1,449 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\n3 $1,449 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\n4 $1,479 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\n5 $1,414 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\n6 $1,441 / 1br - 680ft2 - 1x1 with washer & dryer in unit! Move in ready! (The Phoenix/Sacramento/Folsom/SF)\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     QR Code Link to This Post\\n            \\n        \\n* SEE MY OTHER MIDTOWN 1 bedroom apts-text for web site\\n*An upstairs apt @ 2520 S is coming available 3/18/21\\n*I have 4 apts coming avail in midtown\\n*New flooring in lower apt and redone hardwood flooring in upper unit\\n*1 Bedroom  lower unit in 20 unit complex (2-10 unit buildings-courtyard in middle) with manager on site\\n*Gated front and back\\n*9 parking spots in back\\n*Laundry on site with new washers and dryers (coin op)\\n*Owner pays water/sewer/garbage\\n*Wall heat and window air\\n*New paint and new Pergo-type wood flooring \\n*Updated lighting\\n*Nicely maintained building and grounds\\n*$500 deposit\\n*Non-Smoking/vaping Complex\\n*Long time Mgr on Site\\n*No dogs\\n*Pictures of a like unit\\n*Text/call showing Wes  show contact info\\n to get copy of video\\n*You need to make 3X rent, have good rental history and credit score of 600 or greater to qualify-no dogs.\n2    QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1449+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n3    QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1449+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n4    QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1479+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n5 QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Juliet starting at $1414+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n6    QR Code Link to This Post\\n            \\n        \\n Lease our 1x1 Apartment with Che starting at $1441+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n  latitude longitude                             city         date_posted\n1  38.5728 -121.4675                        2520 S St 2021-02-04 15:03:12\n2  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-02 12:41:17\n3  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-02 13:26:17\n4  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-03 10:02:05\n5  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-04 08:47:21\n6  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-04 10:20:09\n         date_updated price deleted sqft bedrooms bathrooms pets laundry\n1 2021-03-03 08:41:39  1125   FALSE  550        1         1 &lt;NA&gt;  shared\n2                &lt;NA&gt;  1449   FALSE  680        1         1 both in-unit\n3                &lt;NA&gt;  1449   FALSE  680        1         1 both in-unit\n4                &lt;NA&gt;  1479   FALSE  680        1         1 both in-unit\n5                &lt;NA&gt;  1414   FALSE  680        1         1 both in-unit\n6                &lt;NA&gt;  1441   FALSE  680        1         1 both in-unit\n     parking craigslist  shp_place   shp_city shp_state shp_county\n1 off-street sacramento Sacramento Sacramento        CA Sacramento\n2    covered sacramento Sacramento Sacramento        CA Sacramento\n3    covered sacramento Sacramento Sacramento        CA Sacramento\n4    covered sacramento Sacramento Sacramento        CA Sacramento\n5    covered sacramento Sacramento Sacramento        CA Sacramento\n6    covered sacramento Sacramento Sacramento        CA Sacramento\n\n\nThe na.omit function is less precise than indexing, because it removes rows that have a missing value in any column. This means lots of information gets lost.\nAnother way to handle missing values is to impute, or fill in, the values with estimates based on other data in the data set. We won’t get into the details of how to impute missing values here, since it is a fairly deep subject. Generally it is safe to impute MAR values, but not MNAR values.\n\n\n7.2.2 Outliers\nAn outlier is an anomalous or extreme value in a data set. We can picture this as a value that’s far away from most of the other values. Sometimes outliers are a natural part of the data set. In other situations, outliers can indicate errors in how the data were measured, recorded, or cleaned.\nThere’s no specific definition for “extreme” or “far away”. A good starting point for detecting outliers is to make a plot that shows how the values are distributed. Box plots and density plots work especially well for this (you’ll learn about how to make plots in a later lesson):\n\nlibrary(\"ggplot2\")\n\nggplot(cl, aes(x = sqft)) + geom_boxplot()\n\nWarning: Removed 347 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nStatisticians tend to use the rule of thumb that any value more than 3 standard deviations away from the mean is an outlier. You can use the scale function to compute how many standard deviations the elements in a column are from their mean:\n\nz = scale(cl$sqft)\nhead(z)\n\n           [,1]\n[1,] -0.1910838\n[2,] -0.1161393\n[3,] -0.1161393\n[4,] -0.1161393\n[5,] -0.1161393\n[6,] -0.1161393\n\nwhich(z &lt;= -3 | 3 &lt;= z)\n\n[1] 1261 2461\n\n\nBe careful to think about what your specific data set measures, as this definition isn’t appropriate in every situation.\nHow can you handle outliers? First, try inspecting other features from the row to determine whether the outlier is a valid measurement or an error. When an outlier is valid, keep it.\nIf the outlier interferes with a plot you want to make, you can adjust the x and y limits on plots as needed to “ignore” the outlier. Make sure to mention this in the plot’s title or caption.\nWhen an outlier is not valid, first try to correct it. For example:\n\nCorrect with a different covariate from the same observation.\nEstimate with a mean or median of similar observations. This is another example of imputing values.\n\nFor example, in the Craigslist data, we can use the text column to try to correct outliers:\n\nmessage(cl$text[1261])\n\nQR Code Link to This Post\n            \n        \nVillages of the Galleria\n701 Gibson Drive, Roseville, CA, 95678\nWant more information? Follow this link:\nhttp://rcmi.aptdetails.com/49u13n\nCall Now:  show contact info\n\nRoseville's Premier Luxury Condominium Rentals\nThis is a 1 Bedroom, 1 Bath, approximately 819 Sq. Ft. \nSignature Collection\nThis collection of fully renovated homes is limited to a select few. These unique homes are renting quickly. \nThe beautifully remodeled floor plan offers an entertainment style kitchen, gracious living area, formal dining room with access to your outdoor balcony, designer two tone paint with crown molding, spacious bathroom with relaxing oval bath tub, linen closet and large vanity. The bedroom offers a sliding glass door giving you additional access to the private balcony over looking the picturesque courtyard. \nBrand New Featured Interiors:\nEntertainment Style Kitchen\n•   Beautiful warm espresso custom built cabinets with brush nickel hardware\n•   Opulent Granite Countertops with backsplash\n•   Satin finish under mount sink with disposal and upgraded Moen faucet and fixtures\n•   Stainless steel appliances, spacious built in microwave, multi-cycle dishwasher and self-cleaning oven\n•   Plant/décor cabinet ledge \n•   Spacious pantry and personalized custom shelving in all cabinets\n•   Attractive bright recessed lighting\n•   Private in home personal laundry room with full size washer & dryer\nLiving and Dining\n•   Hand laid tile resembling hard wood flooring \n•   Designer two-tone paint with white accent crown molding and baseboards\n•   Upgraded wooden style blinds\n•   Dual pane windows featuring custom framed molding\n•   Spacious coat closet\nBath\n•   Oval Roman soaking tub with surround Opulent granite walls \n•   Warm espresso custom built cabinets with brush nickel hardware\n•   Spacious linen closet and personal cabinet storage\n•   Hand selected Opulent Granite countertops\n•   Unique hand crafted above counter sink\n•   Contemporary waterfall faucet\n•   Custom wood-look framed mirror\n•   White glass contemporary light fixture with brush nickel base\n•   Upgraded brush nickel accents (towel bars and holders)\n•   Hand laid tile resembling hard wood flooring \nBedroom and Closet\n•   Rich plush carpeting\n•   Spacious walk in closets with personalized built in custom organizers and compartments\nOther Features and Amenities \n•   Brilliant bright recessed lighting\n•   Central heat and air\n•   Private balcony or terrace\n•   Pre-wired for high-speed internet, multi-line phone and cable\n•   Brushed nickel hardware accents (door knobs, latches, deadbolts, locks, door knocker and light fixtures)\n•   Covered parking\n•   Additional patio storage\nSelect Homes Offer\n•   Private detached garage\n•   Additional linen or storage space\n•   Cozy Gas Fireplace with carved stone-look mantel and molding\nStyle, sophistication, beautiful landscaping and stunning architecture accent the Villages of the \nGalleria apartment homes, located in dynamic Roseville, California. Villages of the Galleria is just minutes from the Galleria Mall and Fountains at Roseville and offers easy freeway access to downtown, Sacramento International Airport, Arco Arena and major employers such as NEC, Oracle and HP. Select from a variety of one, two or three bedroom floor plans. All apartment homes offer gracious living areas with designer two-tone paint, crown molding, large walk-in closets and in home full size washer and dryer. Enjoy the many fine conveniences offered, such as an expansive fitness center, executive business center and refreshing pool. Villages of the Galleria is the perfect place to call home. \nFeatures\n- Contemporary Recessed Lighting \n- Built-In Linen Closet in Bathroom * \n- Entertainment Style Kitchens \n- Private Balconies and Patios \n- Crown Molding Accents \n- Six-Panel Interior Doors \n- Custom Maple-Front Cabinetry \n- Nine-Foot Ceilings \n- Microwave \n- Pre-Wired for High Speed Internet \n- Private Garages * \n- Full Size Washer/Dryer \n- Pantry * \n- Oval Roman Soaking Tub * \n- Cozy Gas Fireplace with Mantel * \n- Covered Parking * \n- Spacious Walk-In Closet(s) * \n- Energy-Saving Multi-Cycle Dishwasher \nCommunity Amenities\n- Community Garden \n- Executive Business Center \n- Sand Volleyball \n- Close to Shopping \n- Beautiful Landscaped Court Yards \n- Playground \n- Fitness Center \n- Clubhouse \n- Open Air Cabanas \n- Easy Access to Freeways \n- Pool and Spa \n- Gated Community \n- Professional Onsite Management w/ 24-Hour Emergency Maintenance \n- Picnic Area with Barbecue \nOffice Hours\nMonday - Friday 9:00 AM - 6:00 PM\nSaturday 10:00 AM - 5:00 PM\nSunday 12:00 PM - 5:00 PM \nPet Policy\nMaximum of 2 pets cats or dogs. No weight limit. Additional $25 rent per month and additional $500 deposit per pet. Inquire about our breed restrictions. \nEqual Housing Opportunity \nVJWLzl1wXG\n\n\nBased on the text, this apartment is 819 square feet, not 8190 square feet. So we can reassign the value:\n\ncl$sqft[1261] = 819\n\nIf other features don’t help with correction, try getting information from external sources. If you can’t correct the outlier but know it’s invalid, replace it with a missing value NA.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Forensics</span>"
    ]
  },
  {
    "objectID": "chapters/07_data-forensics.html#sec-apply-functions",
    "href": "chapters/07_data-forensics.html#sec-apply-functions",
    "title": "7  Data Forensics",
    "section": "7.3 Apply Functions",
    "text": "7.3 Apply Functions\nSection 3.6.2 introduced vectorization, a convenient and efficient way to compute multiple results. That section also mentioned that some of R’s functions—the ones that summarize or aggregate data—are not vectorized.\nThe class function is an example of a function that’s not vectorized. If we call the class function on the Craigslist data set, we get just one result for the data set as a whole:\n\nclass(cl)\n\n[1] \"data.frame\"\n\n\nWhat if we want to get the class of each column? We can get the class for a single column by selecting the column with $, the dollar sign operator:\n\nclass(cl$pets)\n\n[1] \"factor\"\n\n\nBut what if we want the classes for all the columns? We could write a call to class for each column, but that would be tedious. When you’re working with a programming language, you should try to avoid tedium; there’s usually a better, more automated way.\nSection 3.8.1 pointed out that data frames are technically lists, where each column is one element. With that in mind, what we need here is a line of code that calls class on each element of the data frame. The idea is similar to vectorization, but since we have a list and a non-vectorized function, we have to do a bit more than just call class(cl).\nThe lapply function calls, or applies, a function on each element of a list or vector. The syntax is:\nlapply(X, FUN, ...)\nThe function FUN is called once for each element of X, with the element as the first argument. The ... is for additional arguments to FUN, which are held constant across all the elements.\nLet’s try this out with the Craigslist data and the class function:\n\nlapply(cl, class)\n\n$title\n[1] \"character\"\n\n$text\n[1] \"character\"\n\n$latitude\n[1] \"numeric\"\n\n$longitude\n[1] \"numeric\"\n\n$city\n[1] \"character\"\n\n$date_posted\n[1] \"character\"\n\n$date_updated\n[1] \"POSIXct\" \"POSIXt\" \n\n$price\n[1] \"integer\"\n\n$deleted\n[1] \"logical\"\n\n$sqft\n[1] \"numeric\"\n\n$bedrooms\n[1] \"integer\"\n\n$bathrooms\n[1] \"numeric\"\n\n$pets\n[1] \"factor\"\n\n$laundry\n[1] \"factor\"\n\n$parking\n[1] \"factor\"\n\n$craigslist\n[1] \"character\"\n\n$shp_place\n[1] \"character\"\n\n$shp_city\n[1] \"character\"\n\n$shp_state\n[1] \"character\"\n\n$shp_county\n[1] \"character\"\n\n\nThe result is similar to if the class function was vectorized. In fact, if we use a vector and a vectorized function with lapply, the result is nearly identical to the result from vectorization:\n\nx = c(1, 2, pi)\n\nsqrt(x)\n\n[1] 1.000000 1.414214 1.772454\n\nlapply(x, sqrt)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1.414214\n\n[[3]]\n[1] 1.772454\n\n\nThe only difference is that the result from lapply is a list. In fact, the lapply function always returns a list with one element for each element of the input data. The “l” in lapply stands for “list”.\nThe lapply function is one member of a family of functions called apply functions. All of the apply functions provide ways to apply a function repeatedly to different parts of a data structure. We’ll meet a few more apply functions soon.\nWhen you have a choice between using vectorization or an apply function, you should always choose vectorization. Vectorization is clearer—compare the two lines of code above—and it’s also significantly more efficient. In fact, vectorization is the most efficient way to call a function repeatedly in R.\nAs we saw with the class function, there are some situations where vectorization is not possible. That’s when you should think about using an apply function.\n\n7.3.1 The sapply Function\nThe related sapply function calls a function on each element of a list or vector, and simplifies the result. That last part is the crucial difference compared to lapply. When results from the calls all have the same type and length, sapply returns a vector or matrix instead of a list. When the results have different types or lengths, the result is the same as for lapply. The “s” in sapply stands for “simplify”.\nFor instance, if we use sapply to find the classes of the columns in the Craigslist data, we get a character vector:\n\nsapply(cl, class)\n\n$title\n[1] \"character\"\n\n$text\n[1] \"character\"\n\n$latitude\n[1] \"numeric\"\n\n$longitude\n[1] \"numeric\"\n\n$city\n[1] \"character\"\n\n$date_posted\n[1] \"character\"\n\n$date_updated\n[1] \"POSIXct\" \"POSIXt\" \n\n$price\n[1] \"integer\"\n\n$deleted\n[1] \"logical\"\n\n$sqft\n[1] \"numeric\"\n\n$bedrooms\n[1] \"integer\"\n\n$bathrooms\n[1] \"numeric\"\n\n$pets\n[1] \"factor\"\n\n$laundry\n[1] \"factor\"\n\n$parking\n[1] \"factor\"\n\n$craigslist\n[1] \"character\"\n\n$shp_place\n[1] \"character\"\n\n$shp_city\n[1] \"character\"\n\n$shp_state\n[1] \"character\"\n\n$shp_county\n[1] \"character\"\n\n\nLikewise, if we use sapply to compute the sqrt values, we get a numeric vector, the same as from vectorization:\n\nsapply(x, sqrt)\n\n[1] 1.000000 1.414214 1.772454\n\n\nIn spite of that, vectorization is still more efficient than sapply, so use vectorization instead when possible.\nApply functions are incredibly useful for summarizing data. For example, suppose we want to compute the medians for all of the columns in the Craigslist data set that are numeric.\nFirst, we need to identify the columns. One way to do this is with the is.numeric function. Despite the name, this function actually tests whether its argument is a real number, not whether it its argument is a numeric vector. In other words, it also returns true for integer values. We can use sapply to apply this function to all of the columns in the Craigslist data set:\n\nis_number = sapply(cl, is.numeric)\nis_number\n\n       title         text     latitude    longitude         city  date_posted \n       FALSE        FALSE         TRUE         TRUE        FALSE        FALSE \ndate_updated        price      deleted         sqft     bedrooms    bathrooms \n       FALSE         TRUE        FALSE         TRUE         TRUE         TRUE \n        pets      laundry      parking   craigslist    shp_place     shp_city \n       FALSE        FALSE        FALSE        FALSE        FALSE        FALSE \n   shp_state   shp_county \n       FALSE        FALSE \n\n\nIn general, it’s a good habit to use R to do things rather than do them manually. You’ll get more practice programming, and your code will be more flexible if you want to adapt it to other data sets.\nNow that we know which columns are numeric, we can use the median function to compute medians. We only want to compute medians for those columns, so we need to subset the data:\n\nsapply(cl[, is_number], median, na.rm = TRUE)\n\n latitude longitude     price      sqft  bedrooms bathrooms \n  38.5878 -121.4410 1730.0000  801.0000    2.0000    1.0000 \n\n\n\n\n7.3.2 The Split-Apply Pattern\nIn a data set with categorical features, it’s often useful to compute something for each category. The lapply and sapply functions can compute something for each element of a data structure, but categories are not necessarily elements.\nFor example, the Craigslist data set has four different categories in the laundry column. If we want all of the rows in one category, one way to get them is by indexing:\n\nshared = cl[cl$laundry == \"shared\", ]\nhead(shared)\n\n                                                                                                            title\n1        $1,125 / 1br - 550ft2 - 1Bedroom Prime Location -2520 S Limited Access/Gated $1125 Avail Now (2520 S St)\n7  $1,615 / 2br - 816ft2 - 2x1 with w/d in unit..  available NOW! APPLY TODAY! (The Phoenix/Sacramento/Folsom/SF)\n8  $1,660 / 2br - 816ft2 - 2x1 with w/d in unit..  available NOW! APPLY TODAY! (The Phoenix/Sacramento/Folsom/SF)\n9  $1,877 / 2br - 916ft2 - 2x2 with w/d in unit..  available NOW! APPLY TODAY! (The Phoenix/Sacramento/Folsom/SF)\n10 $1,611 / 2br - 916ft2 - 2x2 with w/d in unit..  available NOW! APPLY TODAY! (The Phoenix/Sacramento/Folsom/SF)\n11 $1,736 / 2br - 916ft2 - 2x2 with w/d in unit..  available NOW! APPLY TODAY! (The Phoenix/Sacramento/Folsom/SF)\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      QR Code Link to This Post\\n            \\n        \\n* SEE MY OTHER MIDTOWN 1 bedroom apts-text for web site\\n*An upstairs apt @ 2520 S is coming available 3/18/21\\n*I have 4 apts coming avail in midtown\\n*New flooring in lower apt and redone hardwood flooring in upper unit\\n*1 Bedroom  lower unit in 20 unit complex (2-10 unit buildings-courtyard in middle) with manager on site\\n*Gated front and back\\n*9 parking spots in back\\n*Laundry on site with new washers and dryers (coin op)\\n*Owner pays water/sewer/garbage\\n*Wall heat and window air\\n*New paint and new Pergo-type wood flooring \\n*Updated lighting\\n*Nicely maintained building and grounds\\n*$500 deposit\\n*Non-Smoking/vaping Complex\\n*Long time Mgr on Site\\n*No dogs\\n*Pictures of a like unit\\n*Text/call showing Wes  show contact info\\n to get copy of video\\n*You need to make 3X rent, have good rental history and credit score of 600 or greater to qualify-no dogs.\n7  QR Code Link to This Post\\n            \\n        \\n Lease our 2x1 Apartment with Juliet starting at $1615+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n8  QR Code Link to This Post\\n            \\n        \\n Lease our 2x1 Apartment with Juliet starting at $1660+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n9  QR Code Link to This Post\\n            \\n        \\n Lease our 2x2 Apartment with Juliet starting at $1877+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n10    QR Code Link to This Post\\n            \\n        \\n Lease our 2x2 Apartment with Che starting at $1611+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n11    QR Code Link to This Post\\n            \\n        \\n Lease our 2x2 Apartment with Che starting at $1736+    Prices Subject to change daily!  \\n Apartment Features:  \\nPrivate Balconies & Patios \\nLuxury Vinyl Wood Flooring \\nDesigner Interior Paint \\nUpgraded cabinets and countertops \\nModern white doors and trim \\nModern white base boards  \\nEnergy efficient appliances \\nSpacious bathroom \\nTONS of closet and storage space \\nSac State Shuttle-including Sac State Shuttle App! PET FRIENDLY - MEOW! WOOF!   \\n\\nUpgraded Fitness Centers \\nTanning Booth \\nHydro Massage Table \\nResident Business Center \\nResort-Style Pool Furniture \\nSparkling Waterfall Wall \\nFire pit locations \\nBeach Area for lounging \\nOutdoor Recreation Area \\nSand Volleyball Court \\nGrilling Locations   Call today to schedule your tour ... show contact info\\n -or- \\nStop in to visit Mon - Sat 10:00a - 5:00p for more info! :D  \\n\\n\\nCommunity Amenities:  \\nComplete fitness center \\nFour sparkling pools  \\nLighted tennis courts  \\nFull basketball court  \\nWhirlpool Jacuzzi  \\n24 hour Emergency Maintenance  Hornet Shuttle Access to Sacramento State University  \\n Easy Access to Public Transportation (lightrail and bus) \\n Easy Access to the American River Trail   And so much more!  \\n\\n Check us out online @ www.thephoenixsacramento.com TODAY!  \\n  Connect with us:   \\nFacebook = The Phoenix Apartment Living \\nTwitter = @thephoenixlife     Prices and availability are subject to change. Offered prices are starting prices for base rent only. Other charges, conditions, fees, and terms may apply. Equal housing opportunity provider\n   latitude longitude                             city         date_posted\n1   38.5728 -121.4675                        2520 S St 2021-02-04 15:03:12\n7   38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-02 08:36:51\n8   38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-04 08:57:47\n9   38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-02 08:36:17\n10  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-02 13:16:29\n11  38.5511 -121.4068 The Phoenix/Sacramento/Folsom/SF 2021-03-03 10:02:38\n          date_updated price deleted sqft bedrooms bathrooms pets laundry\n1  2021-03-03 08:41:39  1125   FALSE  550        1         1 &lt;NA&gt;  shared\n7                 &lt;NA&gt;  1615   FALSE  816        2         1 both  shared\n8                 &lt;NA&gt;  1660   FALSE  816        2         1 both  shared\n9                 &lt;NA&gt;  1877   FALSE  916        2         2 both  shared\n10                &lt;NA&gt;  1611   FALSE  916        2         2 both  shared\n11                &lt;NA&gt;  1736   FALSE  916        2         2 both  shared\n      parking craigslist  shp_place   shp_city shp_state shp_county\n1  off-street sacramento Sacramento Sacramento        CA Sacramento\n7     covered sacramento Sacramento Sacramento        CA Sacramento\n8     covered sacramento Sacramento Sacramento        CA Sacramento\n9     covered sacramento Sacramento Sacramento        CA Sacramento\n10    covered sacramento Sacramento Sacramento        CA Sacramento\n11    covered sacramento Sacramento Sacramento        CA Sacramento\n\n\nTo get all four categories, we’d have to do this four times. If we want to compute something for each category, say the mean of the price column, we also have to repeat that computation four times. Here’s what it would look like for just the shared category:\n\nmean(shared$price, na.rm = TRUE)\n\n[1] 1522.869\n\n\nIf the categories were elements, we could avoid writing code to index each category, and just use the sapply (or lapply) function to apply the mean function to each.\nThe split function splits a vector or data frame into groups based on a vector of categories. The first argument to split is the data, and the second argument is a congruent vector of categories.\nWe can use split to elegantly compute means of price broken down by laundry. First, we split the data by category. Since we only want to compute on the price column, we only split that column:\n\nby_laundry = split(cl$price, cl$laundry)\nclass(by_laundry)\n\n[1] \"list\"\n\nnames(by_laundry)\n\n[1] \"hookup\"  \"in-unit\" \"none\"    \"shared\" \n\n\nThe result from split is a list with one element for each category. The individual elements contain pieces of the original price column:\n\nhead(by_laundry$hookup)\n\n[1] 1250 3300 3328 3300 3280 3328\n\n\nSince the categories are elements in the split data, now we can use sapply the same way we did in previous examples:\n\nsapply(by_laundry, mean, na.rm = TRUE)\n\n   hookup   in-unit      none    shared \n2059.6111 1880.8592  982.2381 1522.8691 \n\n\nThis two-step process is a data science idiom called the split-apply pattern. First you use split to convert categories into list elements, then you use an apply function to compute something on each category. Any time you want to compute results by category, you should think of this pattern.\nThe split-apply pattern is so useful that R provides the tapply function as a shortcut. The tapply function is equivalent to calling split and then sapply. Like split, the first argument is the data and the second argument is a congruent vector of categories. The third argument is a function to apply, like the function argument in sapply.\nWe can use tapply to compute the price means by laundry type for the Craigslist data:\n\ntapply(cl$price, cl$laundry, mean, na.rm = TRUE)\n\n   hookup   in-unit      none    shared \n2059.6111 1880.8592  982.2381 1522.8691 \n\n\nNotice that the result is identical to the one we computed before.\nThe “t” in tapply stands for “table”, because the tapply function is a generalization of the table function. If you use length as the third argument to tapply, you get the same results as you would from using the table function on the category vector.\nThe aggregate function is closely related to tapply. It computes the same results, but organizes them into a data frame with one row for each category. In some cases, this format is more convenient. The arguments are the same, except that the second argument must be a list or data frame rather than a vector.\nAs an example, here’s the result of using aggregate to compute the price means:\n\naggregate(cl$price, list(cl$laundry), mean, na.rm = TRUE)\n\n  Group.1         x\n1  hookup 2059.6111\n2 in-unit 1880.8592\n3    none  982.2381\n4  shared 1522.8691\n\n\nThe lapply, sapply, and tapply functions are the three most important functions in the family of apply functions, but there are many more. You can learn more about all of R’s apply functions by reading this Stack Overflow post.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Forensics</span>"
    ]
  },
  {
    "objectID": "chapters/08_data-visualization.html",
    "href": "chapters/08_data-visualization.html",
    "title": "8  Data Visualization",
    "section": "",
    "text": "8.1 Principles & Perception\nData visualization is the graphical display of abstract information to help us make sense of phenomena and to communicate these findings. It is a powerful tool to help us uncover and share the stories of our data. Visualizations help us retain and analyze all the information in our data, uncover and share our insights, and describe our research in a useful way. If a picture is worth a thousand words, then a good data visualization is worth millions.\nBut how many of us have ever taken a course explicitly on data visualization? It’s typically not taught in standard data analysis courses, yet it is a mainstay for nearly every sector in today’s data-driven world. Today we’ll dive into the what, how, and why of data visualization and describe some best practices that you can immediately implement into your research workflows. Along the way we’ll also focus on building up our collective data literacy skills, and employ critical approaches to produce science that is more robust, transparent, and equitable.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/08_data-visualization.html#principles-perception",
    "href": "chapters/08_data-visualization.html#principles-perception",
    "title": "8  Data Visualization",
    "section": "",
    "text": "8.1.1 A Brief History of Data Visualization\n\n\n\n\n\n\nFigure 8.1: (source)\n\n\n\nData visualization is not a modern invention. Quantitative information display has been traced back to prehistory with the locations of stars mapped on the Lasaux cave drawings. Clay tokens, quipu, and stick charts dating back as far as 5500 BC also illustrate our long history of creating shared representations of data. The oldest known data visualization dates to 1160 BC with the Turin Papyrus Map, which accurately illustrates the distribution of geological resources in a region in Egypt. These earliest forms of data visualization served purposes of navigating culture and living within society—from accounting to agriculture, transportation, religion, and medicine. They were used to help us explore and understand natural phenomena and the workings of the universe.\nThe French philosopher Rene Descartes is attributed as developing the precursor to today’s modern plot in the 17th century—a two-dimensional coordinate system for displaying values. Later in the 18th century William Playfair began creating left to right oriented plots, allowing the viewer to explore how values change over time. He’s also attributed to inventing the bar graph and, unfortunately, the pie chart (we’ll get to why that’s unfortunate, later). Into the 19th and 20th centuries we see an explosion of chart types\nUnsurprisingly, the invention of tools like paper and computers shaped our relationship with knowledge and information, playing a strong role in how we collect, analyze, store and visualize data. As we gather more and more complex data, we seek more ways to visualize its meaning and in the 19th and 20th centuries we see an explosion of chart types and techniques for communicating with statistical graphics.\n\n\n\n\n\n\nSee also\n\n\n\nFor a more complete history of data visualization, check out A Brief History of Data Visualization by M. Friendly.\n\n\nIn particular, check out the following famous data visualizations.\n\n8.1.1.1 Famous Data Visualizations\nFlorence Nightingale, the “mother of nursing,” produced in 1857 a rose diagram depicting seasonal sources of British soldier’s fatalities in the Crimean War. Out of the 18,000 soldiers who had died, 16,000 had died of disease in a hospital (blue shading) rather than from their wounds (black shading). This image is credited with helping to persuade the British government to improve conditions in military hospitals.\n\n\n\n\n\n\nFigure 8.2: The context surrounding this rose diagram is actually quite bit more complex. For additional background, check out this podcast based on the book The Data Detective by Tim Harford.\n\n\n\nJohn Snow, a London physician, traced the source of an 1854 cholera outbreak in Soho. By examining the locations of reported cholera deaths, Snow demonstrated that the disease was connected to a contaminated well on Broad Street, contributing to growing understanding that cholera was a waterborne disease and not caused by foul ‘miasmas’ in the air. He later used a map in his publication to show the concentration of the cholera cases around the contaminated pump. On this map, the height of the dark bars correspond to the number of deaths at a given location. While Snow didn’t invent the mapping technique of layering thematic data on top of topographic maps, nor actually compose the map himself (it was created by cartographer Charles Cheffins), this map was so effective that history often calls Snow the “father of epidemiology.” Learn more about the history of the map in this recent post by Kenneth Field.\n\n\n\n\n\n\nFigure 8.3\n\n\n\nLastly, no discussion of the history of data visualization is complete without a nod to Charles Minard’s acclaimed depiction of Napoleon Bonaparte’s ill-fated invasion of Russia. Edward Tufte declared in his popular 1983 book The Visual Display of Quantitative Information that Napoleon’s March “may well be the best statistical graphic ever produced.” The thick band denotes the size of the army at each position, beginning at the Polish-Russian border. The dark lower band is tied to temperature and time scales, and shows the path of Napoleon’s retreat from Moscow and shrinking army size during the bitterly cold winter.\n\n\n\n\n\n\nFigure 8.4\n\n\n\nThis image has also been recreated with modern plotting software, including the ggplot2 package in R, which you will learn about in the next lesson.\n\n\n\n\n\n\nFigure 8.5: (source: ggplot2: Grammar of Graphics in R by Hadley Wickam)\n\n\n\n\n\n\n8.1.2 What is Data Visualization?\nAt their core, data visualizations are products that:\n\nRepresent data.\nHave a specific purpose.\nTell a data-driven story.\n\nThere are two main types of data visualizations:\n\nInformation visualizations (aka infographics or infoviz) tend to be visually striking, dramatizing a problem with unique and visually appealing imagery that draws the casual viewer in.\nStatistical graphics aim to make comparisons, to reveal patterns and discrepancies. We use statistical graphs to communicate our research results, often for viewers who are already immersed or interested in the problem.\n\nWhile many topics within this reader will apply to infoviz as well, our emphasis is on creating judicious and accurate statistical graphics.\n\n\n\n\n\n\nSee also\n\n\n\nFor more info comparing infoviz and statistical graphs, see Gelman and Unwin 2013.\n\n\n\n8.1.2.1 Why Viz?\nThere are lots of ways to represent our data. In fact, tables are often the most common way to report data, and they are great at conveying exact values. But interpretation of data displayed in a table is largely up to the viewer. It’s hard to perceive the overall summary of the data from a table, unless it’s really simple and, in that case, you often don’t even need a table and can just report those statistics as text.\nData visualization, on the other hand, takes advantage of our ability to process information by shifting the balance between our natural perceptive and cognitive abilities to convey a specific message. Most of the information that’s sent to our brains is visual. In fact, it’s been found that the human brain processes visual imagery 60,000 times faster than text! Data visualizations allow us to move from a predominantly thinking perspective to a seeing perspective. The cerebral cortex, which primarily handles our cognition, is slow and less efficient than the visual cortex, which processes images. Thus, visual diagrams are often easier for us to process than pages of words describing our research. Absorbing information quickly allows us to make novel inferences, and make more productive and informed decisions. Not surprisingly, well composed data visualizations are the most effective type of scientific communication.\n\n\n\n\n\n\nSee also\n\n\n\nFor guidance on how to convert a table into a plot, see this paper by Andrew Gelman.\n\n\nUltimately, the utility of a data visualization depends on how well it’s composed.\n\n\n8.1.2.2 Good Data Visualizations\n\nProvide rapid access to data.\nFaithfully represent the data and tell a story.\nAre expressive.\nAre effective.\n\nHelpful data visualizations intuitively, clearly, accurately, and efficiently explain complex ideas. The patterns and relationships presented must be valid, and the visual relevant to the data it presents. A data visualization cannot exist without a narrative, and good data visualizations always include context. Good plots grab our attention and create a positive visual impact. This aids our ability to make connections and recall the features of the data. They can be aesthetically pleasing but that’s not the end goal. Good plots are accessible (not everyone perceives the visual world the same way). They leverage aspects of human perception to allow for intuitive inference of relationships between abstract concepts (our data).\n\n\n\n\n\n\nSee also\n\n\n\nWant to feel inspired? Check out Information is Beautiful and Flowing Data.\n\n\n\n\n\n\n\n\nFigure 8.6: (source)\n\n\n\n\n\n8.1.2.3 Bad Data Visualizations\n\nHave too much, or too little, information.\nAre inconsistent.\nIgnore limits of human perception.\nMisrepresent the data.\nUse inappropriate (or garbage) data.\n\nHave you ever seen a pie chart where the labeled slices add up to something other than 100%? That’s a poorly executed data visualization. Goal: don’t end up on WTF Viz.\n\n\n\n\n\n\nFigure 8.7: (source)\n\n\n\n\n\n\n8.1.3 Before You Viz, Make a Plan\nModern software makes it easy to quickly create a plot. But before you fire up your computer and start plotting, stop and think. Write out your visualization plan. This will save you time in the long run, and result in a more robust data visualization.\nAsk yourself:\n\nWhy am I making this visualization? (purpose)\nWho am I making it for? (audience)\nHow will I use and share it? (medium)\nWhat can I use to make it? (tools)\nWhat story does it tell? (message)\nWho does it affect? Who is left out? (critical approach)\n\n\n\n\n\n\n\nTip\n\n\n\nHow many plots you need is always the wrong question. You need exactly as many as you need to tell your story.\n\n\n\n8.1.3.1 Purpose\nFirst, identify why you are making a visualization. We use data visualizations in different ways across the iterative steps of the research data pipeline:\n\n\n\n\n\n\nFigure 8.8\n\n\n\n\nCollection: plots can help us understand who, what, and where the data represent. It can help us track our progress, and help us project required effort to complete this phase of the project.\nCleaning: plotting is a quick and effective way to spot errors in our data. It allows us to grasp the extent of issues such as outliers and missing data.\nExploration: plots are a powerful tool for exploratory data analysis (EDA). Plots help us identify patterns, summarize variables and relationships. (see Tukey 1960)\nConfirmation: plots also help us conduct confirmatory data analysis (CDA). We can plot diagnostics like the model fit, residuals, and model comparisons that confirm whether a model is correct. CDA is an iterative process over the course of research, one reason why we advocate using scripting languages and other reproducible workflows for generating graphics.\nValidation: plots also help us to debug and validate our code. We can visually inspect the results at each step of the code we are writing and verify whether it satisfies our expectations.\nCommunication: sharing the insights from our data with others is probably the most commonly understood and emphasized purpose of data visualizations. This is also often the hardest type of data visualization to “get right,” because we don’t always remember to design the visual to speak specifically to who we are sharing it with.\n\n\n\n8.1.3.2 Audience\nWho are you making the data visualization for? There is no such thing as a “generic” data visualization. Are you making the figure for:\n\nYourself, to help you clean or explore your data?\nYour immediate colleagues or research team to update them on your research progress?\nExperts in your field reading your publication or listening to your presentation?\nA general audience as part of your public outreach?\nPolicy makers who might not know all the details but might be making big decisions based on your results?\n\nKnowing who you’re making the visualization for will help you think through the following steps to create something of value for your intended purpose. It will also help you determine how effort is needed to compose a plot to achieve your goal.\n\n\n8.1.3.3 Medium\nThere are always constraints when creating a data visualization. It’s best to discover these before you start, rather than after you’ve created a beautiful data visualization that’s completely inappropriate for your intended use.\nIf you’re creating the visual to accompany a journal article, you probably need to use a static figure and not an interactive or dynamic dashboard. Does your journal allow for color figures? When in doubt, start with greyscale—it’s a lot easier to add color, rather than take it away, as you revise your figures.\nIf you’re showing the figure during a presentation, you probably want to simplify it—you audience will have 5 seconds max to read, understand, and interpret your visualization. A really complex figure that requires minutes to comprehend will just distract your audience away from what you—and your data—are saying. It might be more effective to compose and display the same plot in different ways to best communicate your points.\nFor a poster presentation where your audience is expected to spend significant time pondering over your findings, you might want to have one very large, clear figure that disentangles the complexity of your project.\nIf you’re creating a visual for a website, you might be able to go nuts—bring on the interactivity, the dynamic data display—until you crash the server because it requires too much compute time.\n\n\n\n\n\n\nChecklist\n\n\n\n\nStatic or dynamic/interactive?\nDashboard/apps?\nProjector, paper, website?\nResolution?\nColor?\n\n\n\n\n\n8.1.3.4 Tools\nAt the UC Davis DataLab, we advocate for the use of open-source software and scripting languages for data-driven research projects, including for generating data visualizations.\nUsing scripting languages makes it easy for you to reproduce your data visualizations. As you clean and update your data, you can re-create your visuals easily by re-running your code. You can also return to a figure later and know exactly what it represents and how you made it. You don’t have to worry about remembering which buttons you clicked, and in what order, like you would when using a GUI based software.\nUsing free, open-source software also means that you can easily and freely share your data, code, and output with your collaborators, reducing the equity and reproducibility barriers posed by the use of proprietary software. Open-source software that’s great for plotting—like R—also has amazing user communities and resources to help you learn the code and create your ideal visualization.\n\n\n\n\n\n\nTip\n\n\n\nBe practical with yourself: you probably aren’t going to learn a new package or other plotting software overnight. If your conference talk is tomorrow, using familiar software like Excel for plotting can be fine, especially if you know some tricks to clean up and customize the appearance of your plots.\n\n\n\n\n\n\n\n\nSee also\n\n\n\n\n\nHere’s a non-exhaustive list of open source tools we recommend for data visualization:\n\nStatic visualizations:\n\nggplot for R, Python, and Julia\nSeaborn for Python\n\nGeospatial visualizations:\n\nQGIS\n\nDynamic and interactive visualizations:\n\nLeaflet for mapping\nD3\nPlotly for R, Python, and Julia\nBokeh for R and Python\n\n\n\n\n\n\n\n8.1.3.5 Message\nResearch is storytelling with data. Every data visualization is an important piece of that story. It may help you confirm (or reject) a hypothesis, discover new correlations, or predict the likelihood of a future event.\nCreating statistical graphics is like writing a novel—you get to decide who and what will be featured in your data story. And just like one page of a novel, your data visualization alone doesn’t tell the whole story. Every data visualization should contain the details required for explanation, and they require narratives.\nWrite out captions for each plot before you make it. What does the plot show? After creating the plot, go back and update the caption with the take home points for your viewer. How might others focus on a different message? If you can’t articulate what the plot is about then you probably should rethink what you are choosing to display and how you are showing it.\n\n\n8.1.3.6 Critical Approaches\n\n\n\n\n\n\nImportant\n\n\n\nDon’t skip this step. It’s last on this list but is the most important on your journey to making useful data visualizations. Data are information, and information is power. Use this power intentionally and mindfully throughout the process of creating and sharing your visualizations.\n\n\nAs you reflect on your answers to the planning prompts above, critically review the features of your data:\n\nWhat do the variables you’ve selected for your visualization mean? How are they defined? How did those definitions come to be? Why did you select them?\nWho will your data visualizations affect? What groups are left out? How does this affect the story your data tells? How might someone misrepresent or misunderstand your story? Bring back the bodies.\n\nConducting these connotative and denotative explorations of your data will not only result in a more robust visualization, but will make you a better researcher and support a more inclusive and equitable society.\n\n\n\n\n\n\nSee also\n\n\n\nTo learn more and practice these steps on some case studies, check out our Critical Approach to Data Visualization workshop and Data Feminism research and learning cluster.\n\n\n\n\n\n8.1.4 Graphical Elements of a Plot\nA data visualization is useful only if it encodes information in a way that our eyes can perceive and our brain can understand. Marks and channels are the building blocks of all data visualizations and are employed to accomplish this encoding.\nMarks are the the basic geometries, or graphical elements, in a plot that depict our data items or their linkages. Marks indicate “where” something is and include points (0d), lines (1d), areas (2d), and volumes (3d).\nChannels are the attributes of that control how the marks appear. Channels are used to encode (or indicate) the values or meaning of our data. Channels were first described in the mid-20th century by Jacques Bertin in his book Semilogie graphique (the Semiology of Graphics [1967]), which argues that visual perception operates according to rules that can be followed to express information visually in intuitive, accurate and efficient ways. He described seven main categories of visual variables (channels): location or position, size, shape, orientation, color, and texture. More recent publications list up to 12 channels useful for encoding meaning in data visualizations (Roth 2017).\nBy understanding the nature of our data in combination with the principles of visual perception, we can decide which marks and channels to use for a given data visualizations.\n\n\n\n\n\n\nFigure 8.9: (source: Visualization Analysis and Design by Tamara Munzner)\n\n\n\n\n\n8.1.5 Principles of Visual Perception\nLeveraging principles of visual perception (the ability to see and interpret surrounding visual information) will help us identify appropriate plot types and design better, more informative graphics. Humans are wired to look for structure, patterns, and logic. Our brains are amazing—they take ambiguous visual information and transform it into something organized, symmetrical, or familiar so we can understand it. But, we don’t process all visual information equally.\n\n8.1.5.1 Visual Magic Tricks\nTake a look at the following questions and images.\n\n\n\n\n\n\nFigure 8.10: Which line is bigger?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThey’re the same length, if you pay careful attention to the scales of the axes!\n\n\n\n\n\n\n\n\n\nFigure 8.11: Which inner circle is bigger?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe circles are the same size.\n\n\n\n\n\n\n\n\n\nFigure 8.12: Do these lines connect?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe lines do NOT connect. Hold up a ruler or straight edge and prove it for yourself.\n\n\n\n\n\n\n\n\n\nFigure 8.13: Is the center bar in this image by Dodek a gradient?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNope! It’s a solid color.\n\n\n\n\n\n\n\n\n\nFigure 8.14: What shape(s) do you see in this image?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDid you see a vase or two faces?\n\n\n\nThese visual “magic tricks” work because they capitalize on innate weaknesses in our visual perception.\n\n\n8.1.5.2 Steven’s Psychophysical Power Law\nResearch studies by Stanley Smith Stevens and others have shown that we exhibit innate biases in how we perceive magnitude changes in the intensity of various types of stimuli.\nFor example, we perceive the intensity of an electrical shock to a greater degree than its actual, physical intensity would seem to warrant. We’re also poor at accurately perceiving changes in brightness and estimate it to increasing less than it actually does. However, we have near perfect perception of length proportional to its actual increase. This is especially true if lengths are aligned and on the same scale. Knowing this can help us design more intuitively useful plots.\n\n\n\n\n\n\nFigure 8.15: (source: Figure 5.7 in Visualization Analysis and Design by Tamara Munzner)\n\n\n\n\n\n8.1.5.3 Perception and Encodings\nBased on psychophysics, we can rank encodings to help us identify which ones will more accurately allow us to judge differences in relative magnitudes, which is important when working with ordinal, interval or ratio data.\n\n\n\n\n\n\nFigure 8.16: (source: Jock Mackinlay, 1986, Computer Science ACM Trans. Graph.)\n\n\n\nFrom most to least accurate by magnitude perception:\n\nPosition along a common scale. Spatial position is the easiest feature for us to recognize and evaluate, and unsurprisingly is used in the most common plot types: bar charts, scatterplots.\nPositions along identical but nonaligned scales. Small multiples, grid, lattice, panel, and Rellis charts.\nLength. We can easily recognize proportions and evaluate lengths, especially when they are aligned, such as in bar charts.\nDirection. We recognize directionality fairly easily. Trend charts utilize this to demonstrate changes over time.\nAngle, slope. It’s harder to evaluate angles than length or position. Pie charts can be as efficient as stacked bar charts, unless there are more than 3 parts to the whole. But ask yourself—if there are fewer than 3 or fewer parts, do you really need a visualization?\nArea. Determining the relative magnitude of areas is much harder compared to lengths, and should be used (like in bubble charts) for indicating the relative importance, and not absolute magnitude changes.\nVolume. 3D objects as represented in 2-D space are hard to evaluate. Avoid them. I’m looking at you, exploding 3D pie chart.\nCurvature. Perceiving changes in the degree of a curve magnifies the difficulties in detecting direction, angle, and non-aligned lengths.\nDensity, color saturation and shading. Color is the least accurate way to convey patterns. Saturation is the intensity of a single hue, and increasing color intensity is intuitively perceived as correlating to an increasing value. But individual hues are hard to compare to one another. Heatmaps along the same color gradient can be a good way to convey an overall picture of change in values over a range. We’ll talk more about color later on.\nColor hue. For data visualizations, color hue is the most challenging encoding to detect changes in magnitude.\n\n\n\n8.1.5.4 Evaluating Graphics\n\nNo matter how clever the choice of the information, and no matter how technologically impressive the encoding, a visualization fails if the decoding fails. (Cleveland 1983)\n\nHow do we detect if our encodings have failed? Munzner uses the principles of expressiveness and effectiveness to help us evaluate our data visualizations.\nThe expressiveness of a visual encoding should “express all of, and only, the attributes of the data.” It is violated when we use encodings that do not match our data type or our visualization goals. When it fails, a chart is not only sub-optimal and confusing, it can be incorrect and misleading. Charts can fail the expressiveness test if their encodings imply ordering when there actually is none, or they mis-order a variable.\nThe effectiveness of a visual encoding addresses how accurately can the interpreter of the chart decode the encodings within it and derive accurate knowledge. According to Munzner, “the importance of the attribute should match the salience of the channel,” meaning we should use channels at the top of the list to encode the variables that are the most important to communicating our data story.\nWhen looking at a plot, can you accurately detect differences is the sizes of the bubbles? Can you discriminate between all of the colors, compare the shades? Can you separate the dimensions of the data?\nTaking these principles together, when we want to compare magnitudes of ordinal data (numeric, continuous, or ordered qualitative data—like height, weight, number of children in a family, or a rating), we should use encodings at the top of Mackinlay’s list above.\nConversely, for nominal data (categorical or un-ordered qualitative data—like gender), use these identity channels:\n\nShape: glyphs are effective at grouping categorical attributes together. But be mindful that the more shapes you use, the harder it will be for a viewer to remember what corresponds to which specific data attribute.\nColor: while color can be very effective in data visualizations (see the Gestalt principles below) typically less is more. Apply contrasting colors only to differences in meanings in the data, or to emphasize the main elements. Start with grey, and add color only as necessary. And, be mindful when defining your color palette. Color brewer and Viz Palette provide palettes that optimize our perceptive abilities and design for accessibility. Do a color check—how will a person with colorblindness perceive your graphics?\nTexture: similar to shape and color, texture can be useful for differentiating between categories or separate areas. Textures can be particularly effective at replacing colors, such as in black and white figures, and for increasing accessibility by reinforcing a color encoding.\n\nCombining channels can result in integral or separable coding pairs, respectively allowing attributes to be perceived holistically or with separate judgments regarding their graphical dimension.\n\n\n\n\n\n\nFigure 8.17: (source: Colin Ware (2019) “Information Visualization”)\n\n\n\n\n\n8.1.5.5 Gestalt Principles\nIn addition to decoding specific elements, our brains have an amazing ability to create and perceive structure along visual objects. This is commonly referred to as the Gestalt principles of visual perception. This framework, combined with Steven’s Law, can help us think through how to use marks and channels together to create expressive and effective data visualizations:\n\nSimilarity: objects with the same visual properties are assumed to be similar and are grouped together.\n\nExample: use design elements such as shape, color, and organization to indicate groupings of the data. In design theory these are called “preattentive features” because we actually see and perceive them before we really think about them. In some experiments it was found to take less than 0.5 seconds for the eye and brain to process a preattentive property of an image.\n\nProximity: objects that are close together are perceived as a group.\n\nExample: since physical distance connotes similarity, grouping bars on a chart can indicate similarities among their data. Instead of listing it in a legend, directly label data groupings by adding informative text directly onto the graph.\n\nContinuity: elements that are aligned (on the same line, curve, or plane) are perceived to be more closely related to each other than to other elements.\n\nExample: it is often easier for us to perceive the groupings if the shapes are curves, rather than lines with sharp edges.\n\nEnclosure: objects that appear to have a boundary around them (i.e., are found within the same common or enclosed region) are perceived as being related.\n\nExample: Add line boundaries or shades to group objects.\n\nConnection: objects that are connected, such as by a line, are perceived as a group.\n\nExample: connect different data together to indicate a relationship. This connectedness is highly effective as it often over-rules the other principles for group perception. Every line plot is an example of connectedness.\n\nClosure: complex arrangements of visual elements are perceived as a single, recognizable pattern.\n\nExample: open structures are often perceived as closed, complete and regular.\n\nFigure and Ground: objects are perceived as either standing out prominently in the foreground (or front figure) of an image, or recede into the background.\n\nExample: shading or color blocking can be employed to to distinguish between the more important figure and less important ground features of an image. Place elements of the most importance in the foreground figure.\n\nFocal Point: whatever stands out visually is perceived as the most important. It will grabs our attention first, and holds it for the longest.\n\nExample: use design elements selectively to draw attention to the most important features of the data.\n\n\n\n\n\n\n\n\nFigure 8.18: Gestalt principles for perpetual grouping and figure-ground segregation. (source: Gestalt Principles for Attention and Segmentation in Natural and Artificial Vision Systems by G. Kootstra, N. Bergstrom, D. Kragic (2011).)\n\n\n\n\n\n\n8.1.6 Accessible Data Visualizations\n\n8.1.6.1 Color\nColor can be one of the most challenging—and important—attributes to apply to a plot. Special care must be taken when applying color to our data visualizations to ensure they are accessible to persons with color blindness. Color blindness prevents viewers from distinguishing between certain colors, their brightness, and/or shades of a color. Affecting approximately 1 in 12 men (8%) and 1 in 200 women (0.5%) around the world, it is likely that some viewers of your data visualization will perceive its colors differently.\nOverall we’re not doing a good job at using color mindfully in our science communication. If you want to use color, the following are some recommendations to keep in mind.\nRecommendation 1: Avoid problematic color combinations. The most common types of color blindness makes it hard to tell the difference between red and green (deuteranope and protanope color blindness). Blue-yellow color blindness (tritanope) is less common. Avoid using: red/green, green/brown, green/blue, blue/gray combinations. Many graphing software unfortunately use these combinations as a default and you will have to manually change this on your figures.\nTo demonstrate why these combinations are problematic, here is a color vision test:\n\n\n\n\n\n\nFigure 8.19: (source: Crameri, F., Shephard, G.E. & Heron, P.J. The misuse of colour in science communication. Nat Commun 11, 5444 (2020))\n\n\n\nRecommendation 2: Use an online tool to help you pick a colorblind friendly palette depending on your data and visualization needs. Examples include:\n\ncolorbrewer: palettes, color advice for mapping, and good general tips\ncoolors\n\n\n\n\n\n\n\nFigure 8.20\n\n\n\nRecommendation 3: Use a colorblindness simulator to check your visualization. Who won’t be able to see the differences you’re trying to display with color? Here are a few simulators:\n\nCoblis\nColor Oracle\n\nRecommendation 4: Add textures, symbols, or other channels to reinforce the grouping attributes on your plot.\n\n\n\n\n\n\nFigure 8.21: (source)\n\n\n\nRecommendation 5: Rethink your plot. You may not actually need color at all to effectively display your data.\n\n\n\n\n\n\nFigure 8.22: (source)\n\n\n\n\n\n\n\n\n\nSee also\n\n\n\n\n\nHere are some more resources to help you use color effectively and mindfully in your data visualizations.\nColor and design:\n\nVisualization-Aware Color Design: Aesthetic, Perceptual & Functional Constraints\nModeling Color Difference for Visualization Design (n experiment showing how mark type influences color perception in data viz)\nTextures and patterns for colorblindness\n\n\nColor accessibility in R:\n\nRColorBrewer package\nviridis package\nggpattern package\nR color cheatsheet\n\n\n\n\n\n\n8.1.6.2 Alternative Text\nSo far we’ve taken for granted that visualization is an accessible mode of communication, but researchers and audiences alike are not all sighted. RStudio is behind on vision impairment accessibility, but some packages can provide text descriptions and sonification/audification of plots to improve accessibility for non-visual data interaction.\nFor example, the BrailleR package, has a VI function that wraps around ggplot objects and provides a text-description output. This description is a starting point but it does not summarize the data itself, so it is important to consider also informative figure captions or embedded alternative text so that all viewers are able to interpret the visualization.\nOther packages like the sonification package’s sonify function can be used to represent data in audio form. With the function, the x-axis can span sound across time, so that the length of time a sound plays follows the data long the x-axis from left to right; the y-axis can be expressed as pitch, so that the pitch of the sound matches to the values of the data (lower value means lower pitch).\n\n\n\n8.1.7 Designing Statistical Graphics\nYou are now ready to make your plot! You can combine marks and channels to create nearly any plot type, and there are many established types of statistical graphics that you can choose from to showcase your data. Each type has its benefits, and drawbacks, based on how it encodes your data.\n\n\n\n\n\n\nTip\n\n\n\nMatch the chart type to your data—and what you want it to show—and not the other way around.\n\n\n\nStep 1: Identify Your Data Type\nData can be quantitative or qualitative:\n\nQuantitative data is either continuous (numerical data like height and weight), or discrete (constrained values, such as the number of children in a family).\nQualitative data can be ordered (categories that have a relationship but no meaningful distance between them, such as movie star ratings), or nominal (categories that have no meaningful order, such as gender).\n\n\n\nStep 2: Determine Your Functional Approach\nAsk ask yourself:\n\nWhat are the tasks you want the visual to support?\n\nShowing how values compare to each other? How the data are distributed? How they are composed? How values relate?\n\nWhat specific visual best supports those tasks?\nWhat do you expect people to naturally do in their “visual queries” as they explore the plot?\nHow can you modify the graphical marks and channels to support faster queries?\n\n\n\nStep 3: Select a Plot Type\nNow that you’ve identified your data types and what you need your visualization to show, explore your different chart type options! Start with this nifty From Data to Viz tool. Select your data type(s) and click through for the pros, cons, and alternate options for a bevy of charts.\n\n\n\n\n\n\nFigure 8.23\n\n\n\nFor example, if you want to enable accurate comparisons of individual quantitative values and their relationships, try a scatterplot or a chart with lines or bars sitting aligned on a single axis.\nThe following list contains an overview of some of the most common plot types you may encounter:\nSingle quantitative variables are plotted to show the frequency distribution of the data. While histograms are the most common density plots, a single quantitative variable can also be plotted using a rug plot/strip chart, boxplot, or violin plot (described below, where they’re most commonly employed).\nTwo quantitative variables can be plotted using a:\n\nScatterplot: each axis encodes the values of a different quantitative variable, and individual data are represented as points (or dots) on the chart.\nLine plot: data points are connected by straight lines. Line-scatter plots are are common for time series or trend data.\n\nOne quantitative and one qualitative variable are suitable for a:\n\nBar chart: bars represent the amount of data in different categories of a variable. One axis encodes the frequencies of the quantitative data, and the other axis the categories of the qualitative data.\nBoxplot: shows the median, quartiles, and bounds of your data.\nViolin plot: in essence, a boxplot that also shows the distribution of your quantitative variable.\nWord cloud: these eye-catching visualizations display a list of words with their font size corresponding to their importance. But, they require huge sample sizes and are not very useful as they often distort reality. For example, long words will look more prominent just because they have more letters and cover more area—our eyes don’t intuitively parse out word height from length.\nPie chart: uses relative frequencies to show how large each category is in relation to the whole.\n\n\n\n\n\n\n\nWarning\n\n\n\nPie charts are grudgingly listed here because you will see them in the wild, but resist the temptation to use them!\nBased on our visual perception, pie charts are inherently problematic because they encode values as visual attributes. Pie charts encode data as the area of each slice, as well as the angle that it forms in the center of the pie, making it difficult to easily perceive and compare differences.\nOver 492 posts on WTF Visualizations are tagged as pie charts! Almost any other chart type is better than a pie chart.\n\n\nOther complex plot types you may encounter that layer additional marks and channels on the above chart types are:\n\nLollipop chart: a dot chart where the dots are connected by lines to an axis.\nMosaic plot: also called a treemap, these plots display hierarchical data as sets of nested rectangles sized proportionately to their values.\nBubble plots: scatterplots where the size of a dot corresponds to a third numerical or ordered categorical value.\nRadar plots / star chart: line plots where each variable has its own axis and all axes are joined at the center of the figure.\nNetwork diagrams: also called graphs, these plots show connections (edges) between entities (nodes).\n\n\n\n\n\n\n\nSee also\n\n\n\nTo learn more about network diagrams, check out DataLab’s network toolkit and network analysis workshop.\n\n\n\n\n\n\n\n\nSee also\n\n\n\nGoogle also has an interactive plot gallery. And this Stack Exchange post has even more chart type resources.\nBut remember, some encodings are more difficult to accurately decode. When in doubt, stick to simple figures with points and lines.\n\n\n\n\n\n\n\n\nWhat About Maps?!\n\n\n\nGeospatial data visualization by nature is complex and encodes a lot of attributes. Interested in learning more? Check our DataLab’s Spatial Sciences research and learning cluster and workshops.\n\n\n\n\nStep 4: Iterate\nCreate your visual, and run through step 2 again keeping in mind the principles of visual perception, effectiveness and efficiency. Does it meet your needs? If not, try a different type. Graphing, like writing, requires continuous editing.\n\n\n\n8.1.8 Tips for Better Plots\nMaking effective data visualizations takes practice and experience. The more plots you look at, the more you will intuitively recognize what works—and what doesn’t—for data visual storytelling. One takeaway I hope you discover is the need to avoid unnecessary complexities.\n\n\n\n\n\n\nTip\n\n\n\nIf the “story” is simple, keep it simple. If the “story” is complex, make it look simple.\n\n\nBelow are some tips to help achieve those goals.\n\n8.1.8.1 Get Rid of Chartjunk\nAn easy way to instantly improve your plots is to eliminate superfluous material. Extra tick marks and grid lines; unnecessary text and arrows; decimal places beyond the measurement error of the level of difference; cute little butterfly clip art: this chartjunk has no meaning and it clutters up a chart, making it hard for your viewer to see what’s most important—your data. The amount of ink on your figure should directly correspond with the amount of data you present. If it doesn’t, you have a lot of chartjunk. (Evidence #10298 that pie charts are never a good choice.)\nTry these de-cluttering steps to improve your charts:\n\nShift from center to left-justified text\nRetain white space\nClear contrasts\nRemove chart borders\nRemove (or strongly mute) gridlines\nRemove data markers and point labels (unless they are important)\nRemove unnecessary polygon filling\nCleanup and rename axis labels to be intuitive\nReplace the title with something informative\nLabel the data directly using the principle of proximity\nLeverage consistent color and other aesthetics\n\nCreating visual order and reducing chartjunk will dramatically improve your graphic by helping your data stand out.\n\n\n8.1.8.2 Facilitate Comparisons\n\nAvoid having the graph elements interfere with the data\nJuxtapose or supepose plots (using the same scales)\nUse visually prominent symbols\nAvoid over-plotting; try jittering, or smoothing\nDon’t change a scale mid-axis\nUse only one scale on one axis\nUse color, judiciously\nAvoid jiggling the baseline\nDon’t distort the data; take care when selecting the encodings\n\nA common mistake is to use more encodings than there are dimensions of the data. If you data only has two dimensions (say number of students in STEM by gender identity), your figure could reasonably use points, rarely area, and never volume. (I’m looking at you, 3D pie chart.)\n\n\n8.1.8.3 Create Information-Rich Plots\nData visualizations cannot exist without text. They require context to infer meaning. Ask yourself:\n\nDoes the caption describe what has been graphed? Does it draw attention to the important features? Describe the conclusions drawn by the graph?\nAre the legends and labels clear and intuitive?\nAre important reference lines and points labeled?\n\n\n\n8.1.8.4 Don’t Distort the Data\nThere’s a bestselling book called [“How to Lie with Statistics”][]. Written by the journalist (and not a statistician) Darrell Huff in 1954, the book focuses on how decisions we make in selecting the data and analysis method, along with errors in interpretation, can generate incorrect conclusions. Similarly, visualization principles can be mis-applied when graphing such that the takeaway message from a graphic distorts reality. Review your plots to make sure they both tell, and show, the truth.\n\n\n8.1.8.5 Practice\nJust as an author edits before publishing the novel, and an artist sketches before making the masterpiece, plotting is an iterative process. Proofread for clarity and consistency. Check whether your plots pass the expressiveness and effectiveness tests. Does a viewer draw the same conclusions from the figure that you do?\nHere’s a cheat sheet and checklist to help you design and improve your data visualizations. Happy plotting!\n\n\n\n\n\n\nReferences and Additional Resources\n\n\n\n\n\nWebsites:\n\nMilestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization\nFrom Data to Viz\nInformation is Beautiful\nFlowing Data\nWTF Visualizations\nPerception in Visualization, a computer scientist’s viewpoint\n\nArticles:\n\nMickinlay, Jock. 1986. Automating the design of graphical presentations of relational information. ACM Transactions on Graphics. https://doi.org/10.1145/22949.22950\nCleveland, William S. & Kleiner, Beat. 1975. A Graphical Technique for Enhancing Scatterplots with Moving Statistics. In Proceedings of the Annual Meeting. Atlanta, GA.\nFisher, Ronald Alymer. (1915). Theory of Statistical Estimation. Proceedings of the Cambridge Philosophical Society. 22. 700-725.\n\nContemporary books and chapters:\n\nCleveland, William. 1994. The elements of graphing data, 2nd edition. Hobart Press.\nDrucker, J. 2014. Graphesis: Visual Forms of Knowledge Production. Harvard UP. Cambridge, MA.\nFriendly, M. 2007. A Brief History of Data Visualization. In Handbook of Computational Statistics: Data Visualization. III. Springer-Verlag. Heidelberg. 1-34.\nMunzner, Tamara. 2014. Visualization analysis and design.\nHuff, Darrell. 1954. How to Lie with statistics. W. W. Norton & Company. New York.\nTufte, Edward R. 1983. The Visual Display of Quantitative Information. Graphics Press. Cheshire, CT.\nWainer, Howard. 2007. Graphic discovery: a trout in the milk and other visual adventures.\nWilkinson, Leland. 2005. The Grammar of Graphics, 2nd ed.. Springer. New York. Yau, Visualize this: The flowing data guide to design, visualization, and statistics\n\nHistorical books:\n\nBertin, Jacques. 1983. Semiology of Graphics. University of Wisconsin Press. Madison, WI. (trans. W. Berg) 1967\nDescartes, Réne. 1637. La Géométrie. In Discours de la Méthode. Essellier. Paris.\nMinard, Charles Joseph. 1861. Des Tableaux Graphiques et des Cartes Figuratives. E. Thunot et Cie. Paris.\nPlayfair, William. 1786. Commercial and Political Atlas: Representing, by Copper-Plate Charts, the Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the Whole of the Eighteenth Century. Corry. London.\nSnow, John. 1855. On the Mode of Communication of Cholera. (n.p.). London.\nTukey, John Wilder. 1977. Exploratory Data Analysis. Addison-Wesley. Reading, MA.\nTukey, John Wilder. 1960. A survey of sampling from contaminated distributions. In Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling (I. Olkin et al., eds.) 448–485. Stanford Univ. Press.\n\nR graphics references:\n\nMurrell, Paul. 2019. R Graphics (3rd Edition). Chapman and Hall/CRC.\nSarkar, Deepayan. 2008. Lattice: Multivariate data visualization with R. Springer.\nggplot2: Elegant Graphics for Data Analysis (3e) by Wickham, Navarro, and Pedersen\nR Graphics Cookbook (2e) by Chang",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/08_data-visualization.html#data-viz-with-ggplot-in-r",
    "href": "chapters/08_data-visualization.html#data-viz-with-ggplot-in-r",
    "title": "8  Data Visualization",
    "section": "8.2 Data Viz with ggplot in R",
    "text": "8.2 Data Viz with ggplot in R\n\n8.2.1 R Graphics Overview\nThere are three popular systems for creating visualizations in R:\n\nThe base R functions (primarily the plot function)\nThe lattice package\nThe ggplot2 package\n\nThese three systems are not interoperable! Consequently, it’s best to choose one to use exclusively. Compared to base R, both lattice and ggplot2 are better at handling grouped data and generally require less code to create a nice-looking visualization.\nThe ggplot2 package is so popular that there are now knockoff packages for other data-science-oriented programming languages like Python and Julia. The package is also part of the Tidyverse. Because of these advantages, we’ll use ggplot2 for visualizations in this and all future lessons.\n\n\n8.2.2 The Grammar of Graphics\nggplot2 has detailed documentation and also a cheatsheet.\nThe “gg” in ggplot2 stands for grammar of graphics. The idea of a grammar of graphics is that visualizations can be built up in layers. In ggplot2, the three layers every plot must have are:\n\nData\nGeometry\nAesthetics\n\nThere are also several optional layers. Here are a few:\n\n\n\nLayer\nDescription\n\n\n\n\nscales\nTitle, label, and axis value settings\n\n\nfacets\nSide-by-side plots\n\n\nguides\nAxis and legend position settings\n\n\nannotations\nShapes that are not mapped to data\n\n\ncoordinates\nCoordinate systems (Cartesian, logarithmic, polar)\n\n\nthemes\nDisplay of non-data elements\n\n\n\n\n8.2.2.1 Making a Plot\nFor the plotting examples, let’s take the wine reviews data that we have been working with, and subset it to focus in on Cabernet Sauvignon from the Central Valley.\n\nwine_revs = read.csv(\"data/wine_enthusiast_rankings.csv\")\nwine_cv = subset(wine_revs, region_2 == \"Central Valley\" &\n                   variety == \"Cabernet Sauvignon\")\n\nNext we need to load ggplot2. As always, if this is your first time using the package, you’ll have to install it. Then you can load the package:\n\n# install.packages(\"ggplot2\")\nlibrary(\"ggplot2\")\n\nWhat kind of plot should we make? It depends on what data we want the plot to show. Let’s make a plot that shows the price of the wine against the points awarded to that wine by the reviewers. Both the price and the points are recorded as numbers. A scatter plot is a good choice for displaying two numeric features. Later we’ll learn about other options, but for now we’ll make a scatter plot.\n\nLayer 1: Data\nThe data layer determines the data set used to make the plot. ggplot and most other Tidyverse packages are designed for working with tidy data frames. Tidy means:\n\nEach observation has its own row.\nEach feature has its own column.\nEach value has its own cell.\n\nTidy data sets are convenient in general. A later lesson will cover how to make an untidy data set tidy. Until then, we’ll take it for granted that the data sets we work with are tidy.\nTo set up the data layer, call the ggplot function on a data frame:\n\nggplot(wine_cv)\n\n\n\n\n\n\n\n\nThis returns a blank plot. We still need to add a few more layers.\n\n\nLayer 2: Geometry\nThe geometry layer determines the shape or appearance of the visual elements of the plot. In other words, the geometry layer determines what kind of plot to make: one with points, lines, boxes, or something else.\nThere are many different geometries available in ggplot2. The package provides a function for each geometry, always prefixed with geom_.\nTo add a geometry layer to the plot, choose the geom_ function you want and add it to the plot with the + operator:\n\nggplot(wine_cv) + geom_point()\n\nError in `geom_point()`:\n! Problem while setting up geom.\nℹ Error occurred in the 1st layer.\nCaused by error in `compute_geom_1()`:\n! `geom_point()` requires the following missing aesthetics: x and y.\n\n\nThis returns an error message that we’re missing aesthetics x and y. We’ll learn more about aesthetics in the next section, but this error message is especially helpful: it tells us exactly what we’re missing. When you use a geometry you’re unfamiliar with, it can be helpful to run the code for just the data and geometry layer like this, to see exactly which aesthetics need to be set.\nAs we’ll see later, it’s possible to add multiple geometries to a plot.\n\n\nLayer 3: Aesthetic Mappings\nThe aesthetic mapping determines the relationship between the data and the geometry. Use this mapping to connect features in the data to aesthetics (visual elements) of the geometry.\nThe aes function creates an aesthetic mapping. The syntax is:\naes(AESTHETIC = FEATURE, ...)\nWhich aesthetics are relevant depends on the geometry, but some common ones are x, y, color, fill, shape, alpha, and size. There is more information about and examples of aesthetic names in the documentation.\nFor example, if we want to put the price feature on the x-axis, the aesthetic mapping should be:\naes(x = price)\nIn the aes function, column names are never quoted.\nThere are a few ways to attach the aesthetic mapping to your plot. The simplest method is to add the aesthetic mapping to the plot like any other layer. This embeds an assumption that there is only one mapping for this plot. When this is not the case, we will soon see that specifying the mapping as the mapping argument of the geometry is a more precise way to say what data features map to what aesthetics. For now, we use the simple method.\n\nggplot(wine_cv) +\n  aes(x = price, y = points) +\n  geom_point()\n\n\n\n\n\n\n\n\nAesthetics can be informed by data (e.g. the price column) or by constant values (e.g. the color “blue”). Whether the value is informed by the data or constant will determine where to place that piece of information.\n\n\n\n\n\n\nCaution\n\n\n\n\n\nGenerally, constant values should not be placed inside an aesthetic mapping (a call to the aes function) because a mapping connects data features to aethetics and a constant value is not a data feature.\nIf you set a constant value inside of the aesthetic mapping, the results you get might not be what you expect. For instance, suppose we want to make the points blue:\n\nggplot(wine_cv) +\n  aes(x = price, y = points, color = \"blue\") +\n  geom_point()\n\n\n\n\n\n\n\n\nInstead, if you want to set an aesthetic to a constant value, rather than one that’s data dependent, do so outside of the aesthetic mapping.\n\nggplot(wine_cv) +\n  aes(x = price, y = points) +\n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\n\nNotice that when we specify the color “blue” (outside of aesthetic mapping), R understands what we mean.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nR recognizes a long list of color names. We recommend that you use accessible colors and palettes, as described in Section 8.1.6.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nAnother useful constant aesthetic is the alpha argument, which adjusts the transparency of the points using a range from 0 to 1 (0 is fully transparent and 1 is fully opaque). This can be useful because geom_point plots points with identical coordinates on top of one another, and semi-transparent points make it visually clear where there are multiple points stacked up.\n\nggplot(wine_cv) +\n  aes(x = price, y = points) +\n  geom_point(color = \"blue\", alpha = .3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPer-geometry Aesthetics\nWhen you add an aesthetic mapping to the ggplot function, it applies to the entire plot. You can also set an aesthetic mapping individually for each geometry, by passing the mapping as the mapping argument in the geom_ function. Before we test this out, let’s make a smaller subset of our wines, what we’ll called underrated_wines, because they cost less than $20 and have scores higher than 85.\n\nunderrated_wines &lt;- subset(wine_cv, price &lt; 20 & points &gt; 85)\nnrow(underrated_wines)\n\n[1] 40\n\n\nNow, let’s first add the aesthetic mapping to the ggplot functions, and add color by region to take a look at where these wines are from within the Central Valley.\n\nggplot(underrated_wines) +\n  aes(x = price, y = points, color = region_1) +\n  geom_point()\n\n\n\n\n\n\n\n\nNow let’s add another geometry to better understand the effect of aesthetic placements. Let’s add a geom_text layer to add labels to the plot based on who ranked this wine (taster_name):\n\nggplot(underrated_wines) +\n  aes(x = price, y = points, color = region_1, label = taster_name) +\n  geom_point() +\n  geom_text(size = 3)\n\n\n\n\n\n\n\n\nIn the example above, both geometries (geom_point and geom_text), take on the same color aesthetic mapping. So, where we put the aesthetics matters. If we move the color aesthetic to the geom_text layer, how does the plot change?\n\nggplot(underrated_wines) +\n  aes(x = price, y = points, label = taster_name) +\n  geom_point() +\n  geom_text(mapping=aes(color = region_1), size = 3)\n\n\n\n\n\n\n\n\nWe can also move the color aesthetic to the geom_point layer to experiment:\n\nggplot(underrated_wines) +\n  aes(x = price, y = points, label = taster_name) +\n  geom_point(mapping = aes(color = region_1)) +\n  geom_text(size = 3)\n\n\n\n\n\n\n\n\nHow might we be able to better see all 40 of the observations? Let’s try the position argument within each geometry, where position = position_jitter() will adjust (or “jitter”) the points.\n\nggplot(underrated_wines) +\n  aes(x = price, y = points, label = taster_name) +\n  geom_point(aes(color = region_1), position = position_jitter(seed = 1)) +\n  geom_text(size = 3, position = position_jitter(seed = 1))\n\n\n\n\n\n\n\n\n\n\nOther Layers: Scales and Themes\nThe scales layer controls the title, axis labels, and axis scales of the plot. Most of the functions in the scales layer are prefixed with scale_, but not all of them.\nThe labs function is especially important, because it’s used to set the title and axis labels:\n\nggplot(wine_cv) +\n  aes(x = price, y = points, color = region_1) +\n  geom_point() +\n  labs(title = \"Central Valley Cabernet Sauvignon price by wine score points\",\n       x = \"Price ($)\", y = \"Points\", color = \"Region\")\n\n\n\n\n\n\n\n\nYou can add theme layers that change the non-data components of the figure.\n\n\n\n\n\n\nTip\n\n\n\nggplot2 comes with several themes which can be useful to quickly change the look of your visualization. Popular themes include theme_classic, theme_minimal, and theme_light.\n\n\n\nggplot(wine_cv) +\n  aes(x = price, y = points, color = region_1) +\n  geom_point() +\n  labs(title = \"Central Valley Cabernet Sauvignon price by wine score points\",\n       x = \"Price ($)\", y = \"Points\", color = \"Region\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nYou can assign plots to variables:\n\nwine_plot &lt;- ggplot(wine_cv) +\n  aes(x = price, y = points, color = region_1) +\n  geom_point() +\n  labs(title = \"Central Valley Cabernet Sauvignon price by wine score points\",\n       x = \"Price ($)\", y = \"Points\", color = \"Region\") +\n  theme_minimal()\n\nNote what kind of object this is:\n\ntypeof(wine_plot)\n\n[1] \"list\"\n\nclass(wine_plot)\n\n[1] \"gg\"     \"ggplot\"\n\n\n\n\n\n\n8.2.3 Saving Plots\n\nggsave\nIn ggplot2, use the ggsave function to save the most recent plot you created:\nggsave(plot = wine_plot, \"scatter_plot.png\")\nThe file format is selected automatically based on the extension. Common formats are PNG and PDF.\n\n\nThe Plot Device\nYou can also save a plot with one of R’s “plot device” functions. The steps are:\n\nCall a plot device function: png, jpeg, pdf, bmp, tiff, or svg.\nRun your code to make the plot.\nCall dev.off to indicate that you’re done plotting.\n\nThis strategy works with any of R’s graphics systems (not just ggplot2).\nHere’s an example:\n\n# Run these lines in the console, not the notebook!\njpeg(\"scatter_plot.jpeg\")\nwine_plot\ndev.off()\n\n\n\n\n8.2.4 Example: Bar Plot\nLet’s say we want to plot the number of wines for each region in the Central Valley. A bar plot is an appropriate way to represent this visually.\nThe geometry for a bar plot is geom_bar. Since bar plots are mainly used to display frequencies, the geom_bar function automatically computes frequencies when given mapped to a categorical feature. So we can write:\n\nggplot(wine_cv, aes(x = region_1)) + geom_bar()\n\n\n\n\n\n\n\n\nTo prevent geom_bar from computing frequencies automatically, set stat = \"identity\". This is mainly useful if you want to plot quantities you’ve computed manually on the y-axis.\n\n8.2.4.1 Position Adjustment\nJust as you added color to group the scatter plot data, you may want to add a color grouping to the bar plot. For bar plots, this will take the fill argument instead of the color argument. (The color argument will outline the bars in a color, whereas the fill argument will fill them in with a default color scheme.)\n\nggplot(wine_cv) +\n  aes(x = region_1) +\n  geom_bar(aes(fill = taster_name))\n\n\n\n\n\n\n\n\nThe geom_bar function automatically positions the grouped colors or fills on top of one another (default argument position = \"identity\"). If you want to change the position of the groupings, you can set position = \"dodge\" to display the groups side-by-side.\n\nggplot(wine_cv) +\n  aes(x = region_1) +\n  geom_bar(mapping = aes(fill = taster_name), position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n8.2.5 Remembering Factors\nA feature is categorical if it measures a qualitative category. For example, the genres rock, blues, alternative, folk, pop are categories.\nR uses the class factor to represent categorical data. Visualizations and statistical models sometimes treat factors differently than other data types, so it’s important to make sure you have the right data type. If you’re ever unsure, remember that you can check the class of an object with the class function.\nWhen you load a data set, R usually can’t tell which features are categorical. That means identifying and converting the categorical features is up to you. This can be especially helpful to know if you are plotting categories, but want them to have a particular order, other than the default (alphabetical).\nLet’s think about which features are categorical in the class wine reviews data.\n\nstr(wine_cv)\n\n'data.frame':   104 obs. of  14 variables:\n $ X                    : int  954 2765 3397 4549 4686 4944 5426 5975 6964 8633 ...\n $ country              : chr  \"US\" \"US\" \"US\" \"US\" ...\n $ description          : chr  \"Full-bodied and smooth in texture, this generous-tasting wine has lots of ripe plum flavors and sweet-seeming oak accents.\" \"This full-bodied wine has earthy, woodsy aromas, ripe and mature fruit flavors and a broad, almost soft texture\"| __truncated__ \"This is on the light side, with simple flavors and a juicy, soft texture that shows very little tannin. Aromas \"| __truncated__ \"A very basic Cabernet Sauvignon, very low in alcohol, with a harshness on the finish.\" ...\n $ designation          : chr  \"Reserve Bottling\" \"Judy's Vineyard\" \"\" \"\" ...\n $ points               : int  87 84 84 81 91 86 88 87 86 86 ...\n $ price                : num  15 29 13 11 20 11 12 10 13 14 ...\n $ province             : chr  \"California\" \"California\" \"California\" \"California\" ...\n $ region_1             : chr  \"Lodi\" \"Lodi\" \"Lodi\" \"Lodi\" ...\n $ region_2             : chr  \"Central Valley\" \"Central Valley\" \"Central Valley\" \"Central Valley\" ...\n $ taster_name          : chr  \"Jim Gordon\" \"Jim Gordon\" \"Jim Gordon\" \"Virginie Boone\" ...\n $ taster_twitter_handle: chr  \"@gordone_cellars\" \"@gordone_cellars\" \"@gordone_cellars\" \"@vboone\" ...\n $ title                : chr  \"Archgate Cellars 2014 Reserve Bottling Cabernet Sauvignon (Lodi)\" \"Housley's Century Oak 2013 Judy's Vineyard Cabernet Sauvignon (Lodi)\" \"Cable Car 2013 Cabernet Sauvignon (Lodi)\" \"Harlow Ridge 2011 Cabernet Sauvignon (Lodi)\" ...\n $ variety              : chr  \"Cabernet Sauvignon\" \"Cabernet Sauvignon\" \"Cabernet Sauvignon\" \"Cabernet Sauvignon\" ...\n $ winery               : chr  \"Archgate Cellars\" \"Housley's Century Oak\" \"Cable Car\" \"Harlow Ridge\" ...\n\n\nThe numeric columns in this data set (price, points) are all quantitative, so they’re not categorical. That leaves the character columns.\nBecause we have subsetted only the Cabernet Sauvignon varieties in the Central Valley, we know that features like province, region_2, and variety have no variation. So that leaves us with the other character variables. Some of these, like winery, have too many groups to really consider useful:\n\ntable(wine_cv$winery)\n\n\n         337 Wine Cellars          Archgate Cellars           Black's Station \n                        1                         1                         2 \n                Cable Car                Caricature          Christine Andrew \n                        2                         1                         1 \n                 Concrete            Cooper Station                 Cosentino \n                        2                         2                         1 \n              Criss Cross          Cycles Gladiator                Earthquake \n                        2                         1                         4 \n                Five Rows                 Freakshow                      Gen5 \n                        1                         2                         3 \n             Harlow Ridge            Herman Walters     Housley's Century Oak \n                        1                         1                         1 \n               Insatiable                 Ironstone            James Mitchell \n                        1                         3                         4 \n            Klinker Brick                LangeTwins                Lapis Luna \n                        1                         4                         1 \nLeonardo Family Vineyards              Lodi Estates                      Loft \n                        1                         2                         1 \n                Matchbook  Mettler Family Vineyards             Michael David \n                        1                         7                         6 \n                Moon Eyes               Noble Vines                  Oak Farm \n                        1                         3                         3 \n                Oak Ridge                  Old Soul         Pavilion Crossing \n                        1                         1                         1 \n       Pavillion Crossing                   Peirano                   Peltier \n                        1                         5                         3 \n              Plungerhead                Sand Point     Scotto Family Cellars \n                        1                         1                         2 \n         Sharabella Wines               Shenanigans               Table No. 7 \n                        1                         1                         1 \n              The Crusher           The Dancing Fox            The Federalist \n                        1                         1                         1 \n              Toad Hollow            Tortoise Creek             Twisted Cedar \n                        1                         7                         1 \n                  un4seen                Van Ruiten          Victor Vineyards \n                        1                         2                         1 \n              Vino Vargas \n                        1 \n\n\nOthers, such as region_1 and taster_name, have fewer groupings—which is why we have used them so far for simplifying our visualizations. To reorder our region_1 feature, lets’ convert to to a factor using the factor.\n\nfactor(wine_cv$region_1)\n\n  [1] Lodi           Lodi           Lodi           Lodi           Lodi          \n  [6] Lodi           Lodi           Lodi           Lodi           Lodi          \n [11] Lodi           Lodi           Lodi           Clarksburg     Lodi          \n [16] Lodi           Lodi           Lodi           Lodi           Lodi          \n [21] Lodi           Lodi           Lodi           Lodi           Yolo County   \n [26] Lodi           Lodi           Lodi           Lodi           Lodi          \n [31] Dunnigan Hills Lodi           Lodi           Lodi           Lodi          \n [36] Lodi           Lodi           Lodi           Clements Hills Lodi          \n [41] Yolo County    Lodi           Lodi           Lodi           Lodi          \n [46] Lodi           Lodi           Lodi           Lodi           Lodi          \n [51] Lodi           Lodi           Lodi           Lodi           Lodi          \n [56] Lodi           Lodi           Lodi           Lodi           Lodi          \n [61] Lodi           Lodi           Lodi           Lodi           Lodi          \n [66] Clarksburg     Lodi           Lodi           Lodi           Lodi          \n [71] Lodi           Lodi           Lodi           Lodi           Lodi          \n [76] Lodi           Lodi           Lodi           Lodi           Lodi          \n [81] Lodi           Lodi           Lodi           Lodi           Lodi          \n [86] Lodi           Lodi           Lodi           Clarksburg     Lodi          \n [91] Lodi           Lodi           Lodi           Lodi           Lodi          \n [96] Lodi           Lodi           Lodi           Clarksburg     Lodi          \n[101] Lodi           Lodi           Lodi           Lodi          \nLevels: Clarksburg Clements Hills Dunnigan Hills Lodi Yolo County\n\n\nThe categories of a factor are called levels. You can list the levels with the levels function:\n\nlevels(factor(wine_cv$region_1))\n\n[1] \"Clarksburg\"     \"Clements Hills\" \"Dunnigan Hills\" \"Lodi\"          \n[5] \"Yolo County\"   \n\n\nNotice that factors default the level order to be in alphabetical order. This is also true when we plot characters, which you can notice if we again call the bar plot we made that counted up the regions in our wine reviews data.\n\nggplot(wine_cv) +\n  aes(x = region_1) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n8.2.5.1 Assigning Factor Levels\nBut what if we wanted to change the order of the x axis to be in descending order? We can change the level assignments. The easier way to do this is to re-write the feature as a factor again, but specify the order of the levels as an argument in the factor function.\n\nregions = c(\n  \"Lodi\", \"Clarksburg\", \"Yolo County\", \"Clements Hills\", \"Dunnigan Hills\"\n)\nwine_cv$region_1_f &lt;- factor(wine_cv$region_1, levels = regions)\nlevels(wine_cv$region_1_f)\n\n[1] \"Lodi\"           \"Clarksburg\"     \"Yolo County\"    \"Clements Hills\"\n[5] \"Dunnigan Hills\"\n\n\nNow we can run the same plotting code, but see that the order of the x axis changed, based on the levels of the region_1 factor.\n\nggplot(wine_cv) +\n  aes(x = region_1_f) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n8.2.6 Designing a Visualization\nWhat plot is appropriate?\n\n\n\nFeature 1\nFeature 2\nPlot\n\n\n\n\ncategorical\n\nbar, dot\n\n\ncategorical\ncategorical\nbar, dot, mosaic\n\n\nnumerical\n\nbox, density, histogram\n\n\nnumerical\ncategorical\nbox, density, ridge\n\n\nnumerical\nnumerical\nline, scatter, smooth scatter\n\n\n\nIf you want to add a:\n\n3rd numerical feature, use it to change point/line sizes.\n3rd categorical feature, use it to change point/line styles.\n4th categorical feature, use side-by-side plots.\n\nAlso:\n\nAlways add a title and axis labels. These should be in plain English, not variable names!\nSpecify units after the axis label if the axis has units. For instance, “Height (ft)”.\nDon’t forget that many people are colorblind! Also, plots are often printed in black and white. Use point and line styles to distinguish groups; color is optional.\nAdd a legend whenever you’ve used more than one point or line style.\nAlways write a few sentences explaining what the plot reveals. Don’t describe the plot, because the reader can just look at it. Instead, explain what they can learn from the plot and point out important details that are easily overlooked.\nSometimes points get plotted on top of each other. This is called over plotting. Plots with a lot of over plotting can be hard to read and can even misrepresent the data by hiding how many points are present. Use a two-dimensional density plot or jitter the points to deal with over plotting.\nFor side-by-side plots, use the same axis scales for both plots so that comparing them is not deceptive.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/09_data-from-the-web.html",
    "href": "chapters/09_data-from-the-web.html",
    "title": "9  Getting Data from the Web",
    "section": "",
    "text": "9.1 How the Web Works\nThe discipline of Data Science was, in large part, ushered into being by the increasing availability of information available on the World Wide Web or through other internet sources. Prior to the popularization of the internet as a publishing and communications platform, the majority of scientific research involved controlled studies in which researchers would collect their own data through various direct means (surveys, medical testing, etc.) in order to test a stated hypothesis.\nThe vast amount of information available on the internet disrupted this centuries-long dominance. Today, the dominant form of scientific research involves using data collected or produced by others for reasons having little or nothing to do with the research question being investigated by scholar. Users who post items about their favorite political candidate are not, for example, doing this so that sociologists can better under how politics function in America. However, their Tweets are being used in that and many other unforeseen capacities.\nBecause the internet provides such a rich trove of information for study, understanding how to effectively get, process, and prepare information from the internet for scientific research is a crucial skill for any data scientist. And in order to understand these workflows, the data scientist must first understand how the internet itself functions.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Getting Data from the Web</span>"
    ]
  },
  {
    "objectID": "chapters/09_data-from-the-web.html#how-the-web-works",
    "href": "chapters/09_data-from-the-web.html#how-the-web-works",
    "title": "9  Getting Data from the Web",
    "section": "",
    "text": "9.1.1 Client-Server Architecture\nThe base architecture and functioning of the internet is quite simple:\n\n\n\n\n\n\nFigure 9.1\n\n\n\n\nA content producer puts information on a computer called the server for others to retrieve;\nA user uses their local computer, called the client, to request the information from the sever;\nThe server delivers the information to the client.\n\nEach of the above detailed steps is accomplished using a technically complex but conceptually simple set of computer protocols. The technical details are beyond the scope of this course. We are here concerned with their conceptual architecture.\n\n9.1.1.1 Communication Between Clients and Servers\nAnytime a computer connects to any network, that computer is assigned a unique identifier known as an internet protocol (IP) address that uniquely identifies that computer on the network. IP addresses have the form x.x.x.x, where each x can be any integer from 0 to 255. For example, 169.237.102.141 is the current IP address of the computer that hosts the DataLab website. IP addresses are sometimes pre-designated for particular computers. A pre-designated IP address is known as static IP address. In other cases IP addresses are dynamically assigned from a range of available IP Address using a system known as the Dynamic Host Configuration Protocol (DHCP). Servers are typically assigned static IP addresses and clients are typically assigned dynamic IP addresses.\n\n\n\n\n\n\nFigure 9.2\n\n\n\nAs humans, we are used to accessing websites via a domain name (which we’ll discuss shortly), but you can also contact any server on the internet by simply typing the IP address into your browser address bar where you would normally enter the URL. For example, you can simply click on https://169.237.102.144 to access the DataLab website.\n\n\n\n\n\n\nNote\n\n\n\nYour browser may give you a security warning if you try to access a server directly using an IP address. For the link above, it is safe to proceed to the site.\n\n\n\n\n9.1.1.2 Domain Name Resolution\nIP addresses are the unique identifiers that make the internet work, but they are not very human friendly. To solve this problem, a system of domain name resolution was created. Under this system, internet service providers access a universal domain registry database that associates human readable domain names with machine readable IP addresses, and a secondary set of of internet connected servers known as domain name servers (DNS) provide a lookup service that translates domain names into IP addresses in the background. As the end-user, you enter and see only domain names, but the actual request process is a multi-step process in which domain names are translated to IP address in the background:\n\n\n\n\n\n\nFigure 9.3\n\n\n\n\nA content producer puts information on a computer called the server for others to retrieve;\nA user uses their local computer, called the client, to request the information from the sever using a domain name using request software such as a web browser;\nThe user’s client software first sends a request to a DNS server to retrieve the IP address of the server on the network associated with the entered domain name;\nThe DNS server returns the associated IP address to the client;\nThe client then makes the information request to the server using its retrieved IP address;\nThe server delivers the information to the client.\n\n\n\n9.1.1.3 Request Routing\nOur simple diagram of the client server process shows only two computers. But when you connect to the internet you are not, of course, creating a direct connection to a single computer. Rather, you are connecting to vase network of literally millions of computers, what we have come to refer to as the cloud.\nIn order to solve this problem, the internet backbone also deploys a routing system that directs requests and responses across the network to the appropriate servers and clients.\nWhen you connect to the WiFi network in your home, office, or the local coffee house, you are connecting to a router. That router receives all of your requests and, provided you are not requesting something directly from another computer that is connected to the same router, passes that request on to a larger routing network at your internet service provider (ISP). When the ISP routers receive your request, they check to see if you’re requesting something from a computer that is connected to their network. If it is, they deliver the request. If it is not, they pass the request on to another, regional routing network. And this routing process is repeated until your request if finally routed to the correct server.\n\n\n\n\n\n\nFigure 9.4\n\n\n\n\n\n9.1.1.4 The Server Response\nWhen a request is sent to a server across the internet, the request includes both the specific URL of the resource being request and also an hidden request header. The request header provides information to the server such as the IP address and the operating system of the client, the transfer protocol being used, and the software on the client that is making the request. The server uses this information to properly format its response and to route it back to the requesting client using the same IP routing process as described above.\n\n\n9.1.1.5 Internet Transfer Protocols\nAll of the information transferred between computers over the network is transferred as streams of binary data. In order to ensure data integrity, these streams are usually broken up into smaller packets of data which are transmitted independent of each other and then reassembled by the receiving computer once it has received all of the packets in the stream. The first packet returned (a header packet) typically delivers information about how many packets the client should expect to receive and about how they should be reassembled to recreate the original data stream.\nThere are many different standards for how data streams are divided into packets. One standard might, for example, break the stream into a collection of 50-byte packets, while another might use 100-byte packages. These standards are called protocols. The two protocols that are familiar to most users are HTTP and HTTPS, which define the hypertext transfer protocol and its sibling the hypertext transfer secure protocol. When you type a URL like https://datalab.ucdavis.edu into your browser, you are instructing the browser to use the HTTPS protocol to exchange information. Because HTTP and HTTPS are so common, most modern browsers do not require you to type the protocol name. They will simply insert the protocol for you in the background.\n\n\n\n9.1.2 Understanding URLs\nURL is an acronym for uniform resource locator. “Uniform” is a key term in this context. URLs are not arbitrary pointers to information. They are machine parsable, human readable, and can contain a lot of information.\nAll URLs are constructed using a standardized format. Consider the following URL:\nhttps://sfbaywildlife.info/species/common_birds.htm\nThere are actually several distinct components to the above URL:\n\n\n\n\n\n\nprotocol\nserver\npath to file\n\n\n\n\nhttps://\nsfbaywildlife.info\n/species/common_birds.htm\n\n\n\n\n\n\nWe’ve already discussed internet protocols and domain names. The file path portion of the URL can also provide valuable information about the server. It reads exactly like a Unix file path on the command line. The path /species/common_birds.htm indicates that the file common_birds.htm is in the species directory on the server.\n\n9.1.2.1 Dynamic Files\nIn the above example, when you enter the URL https://sfbaywildlife.info/species/common_birds.htm, your browser requests the file at /species/common_birds.html on the server. The server simply finds the file and delivers it to your web browser. We call this a static web server because the server itself does not do any processing of files prior to delivery. It simply receives requests for files living on the server and then sends them to the client, whose browser renders the file for viewing.\nMany websites, however, use dynamic processing. Pages with file extensions such as .php or .jsp, for example, include computer code in them. When these pages are requested by the server, the server executes the code in the designated file and sends the output of that execution to the requesting client rather than the actual file. Many sites, such as online stores and blogs, use this functionality to connect their web pages to active databases that track inventory and orders, for example.\n\n\n9.1.2.2 Query Strings\nDynamic websites, such as e-commerce sites that are connected to databases, require a mechanism for users to submit information to the server for processing. This is accomplished through one of two HTTP requests: GET or POST.\nPOST requests send submitted information to the server via a hidden HTTP header that is invisible to the end user. Scraping sites that require POST transactions is possible but can require significant sleuthing to determine the correct parameters and is beyond the scope of this course.\nGET requests, which are, happily for web scrapers more ubiquitous than POST requests, are much easier to understand. They are submitted via a query string that is simply appended to the request URL as in the following example:\nhttps://ebba.english.ucsb.edu/search_combined/?ft=dragon&numkw=52\nHere we see a query string appended to the end of the actual URL:\n\n\n\n\n\n\n\n\n\n\n\n\nprotocol\nserver\npath to file\nquery string\n\n\n\n\nhttps://\nebba.english.ucsb.edu\n/search_combined/index.php\n?ft=dragon&numkw=52\n\n\n\n\n\n\nQuery strings always appear at the end of the URL and begin with the ? character followed by a series of key/value pairs separated by the & character. In the above example we see that two parameters are submitted to the server via the query string as follows:\n\nft=dragon\nnumkw=52\n\nThe server will use these parameter values as input to perform a dynamic operation, in this case searching a database.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Getting Data from the Web</span>"
    ]
  },
  {
    "objectID": "chapters/09_data-from-the-web.html#accessing-data-online",
    "href": "chapters/09_data-from-the-web.html#accessing-data-online",
    "title": "9  Getting Data from the Web",
    "section": "9.2 Accessing Data Online",
    "text": "9.2 Accessing Data Online\nWhile there are many methods (and R packages) for acquiring data from the web, all fall into one of three general categories of data acquisition:\n\nDirect download describes the case where a data provider has provided a specific URL or web link from which you can download the data. For example, when you download data from the “Files” section of Canvas, you are using the direct download method of data acquisition.\nWeb application programming interfaces (web APIs) are web-accessible endpoints that you access via a URL, just as you would any website, but that are designed specifically to interact with computers (as opposed to humans). APIs receive requests and return data to the requester in machine, as opposed to human, readable formats, such as JSON or XML. We will learn more about working with APIs in this unit.\nScraping a web page means extracting information from human readable internet sources so that it can be used programmatically (for instance, in R). We will also learn more about Scraping in this unit.\n\nEach of the above general methods can be accomplished by applying any number of sub-methods and packages. And each brings with it its own degree of complexity and difficulty. As a general rule, the various ways you can get data from the web can be ranked according to difficulty from most to least convenient as follows:\n\nDirect download or “data dump”\nR or Python package (there are packages for many popular web APIs)\nDocumented web API\nUndocumented web API\nScraping",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Getting Data from the Web</span>"
    ]
  },
  {
    "objectID": "chapters/09_data-from-the-web.html#web-apis",
    "href": "chapters/09_data-from-the-web.html#web-apis",
    "title": "9  Getting Data from the Web",
    "section": "9.3 Web APIs",
    "text": "9.3 Web APIs\nAs noted earlier, a web application programming interface (API) provides a machine readable gateway for accessing data from the web. Most APIs provide programmatic access to the data that lives behind a human readable website. For example, most social media platforms such as Twitter, Facebook, and Instagram provide web APIs that allow computers to programmatically access the same data that you, as a human, see when you interact with these platforms via a web browser of mobile app. Some web APIs, however, are stand-alone, in that they provide machine access to data sources that have no human readable interface.\nOne of the challenges with working with web APIs is that, while there are some conventions for behavior, you need to know what and how to query a specific API in order to interact with it. Some APIs are well documented, while others are not. And some, for example the Twitter API, have extensive documentation that is frequently erroneous, incomplete, or out of date. As a result, working with web APIs can sometimes be challenging.\nFor this unit, we will work with the RESTCountries API which stores data on countries all over the world: their currencies, flags, population, etc. There are a large number of public web APIs out there, such as those listed by the public-api project.\n\n9.3.1 Querying a Web API\nThe R community has developed packages to facilitate interaction with many popular web APIs (Twitter, Facebook, etc.). Because web APIs are web-accessible, however, all can be accessed programmatically using basic internet request protocols, just as if you were going to a human readable webpage, provided you know how to formulate your request as a URL. The RESTcountries webpage publishes guidelines for accessing its API.\nWe can see from the documentation that the API will allow us to query a list of country features that appear in the database using a URL with the following construction:\n\"https://restcountries.com/v3.1/all?fields=name\"\nYou can actually go to this URL in your web browser and see the response, a portion of which is reproduced here:\n[{\"name\":{\"common\":\"American Samoa\",\"official\":\"American Samoa\",\"nativeName\":{\"eng\":{\"official\":\"American Samoa\",\"common\":\"American Samoa\"},\"smo\":{\"official\":\"Sāmoa Amelika\",\"common\":\"Sāmoa Amelika\"}}}},{\"name\":{\"common\":\"Peru\",\"official\":\"Republic of Peru\",\"nativeName\":{\"aym\":{\"official\":\"Piruw Suyu\",\"common\":\"Piruw\"},\"que\":{\"official\":\"Piruw Ripuwlika\",\"common\":\"Piruw\"},\"spa\":{\"official\":\"República del Perú\",\"common\":\"Perú\"}}}},{\"name\":{\"common\":\"Tonga\",\"official\":\"Kingdom of Tonga\",\"nativeName\":{\"eng\":{\"official\":\"Kingdom of Tonga\",\"common\":\"Tonga\"},\"ton\":{\"official\":\"Kingdom of Tonga\",\"common\":\"Tonga\"}}}}\nIf you look closely at this extract form the response, you will see that it contains HTML but is not HTML. Remember that APIs exist to deliver machine readable information. In this case, the API is delivering data in the JSON format, and some of the fields in the JSON object contain information provided as HTML.\nBecause the response is machine readable, we can make better use of the query if we run it in R rather than our web browser. Before we can do so, we need to setup our R environment to execute HTTP queries against the API and to process JSON. We’ll use the httr package to process our http transactions and the jsonlite package to process the JSON that we receive\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\nWith our packages installed, we execute our query in R with one simple command:\n\nlibrary(\"httr\")\nlibrary(\"jsonlite\")\n\nresponse &lt;- GET(\"https://restcountries.com/v3.1/all?fields=name\")\n\nThe above executes an HTTP GET request (just like your web browser) to the identified query URL and loads it into an httr “response” object. If you take some time to examine the response object, you will see that it is a container object that contains a lot of useful information in addition to the actual JSON response that you see when you load the URL in your browser. For example, we can check the status of the response to see if it was successful by look at the response “status_code” which should be 200 if the query executed successfully.\n\nmessage(response$status_code)\n\n200\n\n\nThe actual content of the response can be found in the response object’s “content” element. Note, however, that we have to do some formatting on the object in order to access it. Go ahead and look at the actual response$content object:\n\nresponse$content\n\n    [1] 5b 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74\n   [25] 68 20 47 65 6f 72 67 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53\n   [49] 6f 75 74 68 20 47 65 6f 72 67 69 61 20 61 6e 64 20 74 68 65 20 53 6f 75\n   [73] 74 68 20 53 61 6e 64 77 69 63 68 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61\n   [97] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n  [121] 69 61 6c 22 3a 22 53 6f 75 74 68 20 47 65 6f 72 67 69 61 20 61 6e 64 20\n  [145] 74 68 65 20 53 6f 75 74 68 20 53 61 6e 64 77 69 63 68 20 49 73 6c 61 6e\n  [169] 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 47 65 6f 72\n  [193] 67 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n  [217] 6e 22 3a 22 47 72 65 6e 61 64 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n  [241] 22 47 72 65 6e 61 64 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n  [265] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 72 65 6e 61\n  [289] 64 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 72 65 6e 61 64 61 22 7d 7d\n  [313] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 77\n  [337] 69 74 7a 65 72 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53\n  [361] 77 69 73 73 20 43 6f 6e 66 65 64 65 72 61 74 69 6f 6e 22 2c 22 6e 61 74\n  [385] 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69\n  [409] 61 6c 22 3a 22 43 6f 6e 66 c3 a9 64 c3 a9 72 61 74 69 6f 6e 20 73 75 69\n  [433] 73 73 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 75 69 73 73 65 22 7d 2c\n  [457] 22 67 73 77 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 63 68 77 65\n  [481] 69 7a 65 72 69 73 63 68 65 20 45 69 64 67 65 6e 6f 73 73 65 6e 73 63 68\n  [505] 61 66 74 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 63 68 77 65 69 7a 22 7d\n  [529] 2c 22 69 74 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6e 66\n  [553] 65 64 65 72 61 7a 69 6f 6e 65 20 53 76 69 7a 7a 65 72 61 22 2c 22 63 6f\n  [577] 6d 6d 6f 6e 22 3a 22 53 76 69 7a 7a 65 72 61 22 7d 2c 22 72 6f 68 22 3a\n  [601] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6e 66 65 64 65 72 61 7a 69\n  [625] 75 6e 20 73 76 69 7a 72 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 76 69\n  [649] 7a 72 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n  [673] 6e 22 3a 22 53 69 65 72 72 61 20 4c 65 6f 6e 65 22 2c 22 6f 66 66 69 63\n  [697] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 53 69 65 72 72 61\n  [721] 20 4c 65 6f 6e 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65\n  [745] 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n  [769] 63 20 6f 66 20 53 69 65 72 72 61 20 4c 65 6f 6e 65 22 2c 22 63 6f 6d 6d\n  [793] 6f 6e 22 3a 22 53 69 65 72 72 61 20 4c 65 6f 6e 65 22 7d 7d 7d 7d 2c 7b\n  [817] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 48 75 6e 67 61 72\n  [841] 79 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 48 75 6e 67 61 72 79 22 2c\n  [865] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 68 75 6e 22 3a 7b 22 6f 66\n  [889] 66 69 63 69 61 6c 22 3a 22 4d 61 67 79 61 72 6f 72 73 7a c3 a1 67 22 2c\n  [913] 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 67 79 61 72 6f 72 73 7a c3 a1 67 22\n  [937] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n  [961] 54 61 69 77 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n  [985] 62 6c 69 63 20 6f 66 20 43 68 69 6e 61 20 28 54 61 69 77 61 6e 29 22 2c\n [1009] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 7a 68 6f 22 3a 7b 22 6f 66\n [1033] 66 69 63 69 61 6c 22 3a 22 e4 b8 ad e8 8f af e6 b0 91 e5 9c 8b 22 2c 22\n [1057] 63 6f 6d 6d 6f 6e 22 3a 22 e5 8f b0 e7 81 a3 22 7d 7d 7d 7d 2c 7b 22 6e\n [1081] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 57 61 6c 6c 69 73 20 61\n [1105] 6e 64 20 46 75 74 75 6e 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54\n [1129] 65 72 72 69 74 6f 72 79 20 6f 66 20 74 68 65 20 57 61 6c 6c 69 73 20 61\n [1153] 6e 64 20 46 75 74 75 6e 61 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69\n [1177] 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61\n [1201] 6c 22 3a 22 54 65 72 72 69 74 6f 69 72 65 20 64 65 73 20 c3 ae 6c 65 73\n [1225] 20 57 61 6c 6c 69 73 20 65 74 20 46 75 74 75 6e 61 22 2c 22 63 6f 6d 6d\n [1249] 6f 6e 22 3a 22 57 61 6c 6c 69 73 20 65 74 20 46 75 74 75 6e 61 22 7d 7d\n [1273] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 61\n [1297] 72 62 61 64 6f 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 61 72 62\n [1321] 61 64 6f 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67\n [1345] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 61 72 62 61 64 6f 73 22\n [1369] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 61 72 62 61 64 6f 73 22 7d 7d 7d 7d\n [1393] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 69 74 63\n [1417] 61 69 72 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22\n [1441] 3a 22 50 69 74 63 61 69 72 6e 20 47 72 6f 75 70 20 6f 66 20 49 73 6c 61\n [1465] 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22\n [1489] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 69 74 63 61 69 72 6e 20 47\n [1513] 72 6f 75 70 20 6f 66 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e\n [1537] 22 3a 22 50 69 74 63 61 69 72 6e 20 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d\n [1561] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 49 76 6f 72\n [1585] 79 20 43 6f 61 73 74 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70\n [1609] 75 62 6c 69 63 20 6f 66 20 43 c3 b4 74 65 20 64 27 49 76 6f 69 72 65 22\n [1633] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f\n [1657] 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65\n [1681] 20 43 c3 b4 74 65 20 64 27 49 76 6f 69 72 65 22 2c 22 63 6f 6d 6d 6f 6e\n [1705] 22 3a 22 43 c3 b4 74 65 20 64 27 49 76 6f 69 72 65 22 7d 7d 7d 7d 2c 7b\n [1729] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 54 75 6e 69 73 69\n [1753] 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 75 6e 69 73 69 61 6e 20\n [1777] 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n [1801] 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8\n [1825] ac d9 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 aa d9 88 d9 86\n [1849] d8 b3 d9 8a d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 aa d9 88 d9 86\n [1873] d8 b3 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n [1897] 22 3a 22 49 74 61 6c 79 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 74\n [1921] 61 6c 69 61 6e 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e\n [1945] 61 6d 65 22 3a 7b 22 69 74 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n [1969] 22 52 65 70 75 62 62 6c 69 63 61 20 69 74 61 6c 69 61 6e 61 22 2c 22 63\n [1993] 6f 6d 6d 6f 6e 22 3a 22 49 74 61 6c 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61\n [2017] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6e 69 6e 22 2c 22 6f\n [2041] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 42 65\n [2065] 6e 69 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22\n [2089] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75\n [2113] 65 20 64 75 20 42 c3 a9 6e 69 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42\n [2137] c3 a9 6e 69 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n [2161] 6d 6f 6e 22 3a 22 49 6e 64 6f 6e 65 73 69 61 22 2c 22 6f 66 66 69 63 69\n [2185] 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 49 6e 64 6f 6e 65 73\n [2209] 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 69 6e 64 22 3a\n [2233] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 20 49 6e\n [2257] 64 6f 6e 65 73 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 49 6e 64 6f 6e\n [2281] 65 73 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n [2305] 6f 6e 22 3a 22 43 61 70 65 20 56 65 72 64 65 22 2c 22 6f 66 66 69 63 69\n [2329] 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 43 61 62 6f 20 56 65\n [2353] 72 64 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22\n [2377] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61\n [2401] 20 64 65 20 43 61 62 6f 20 56 65 72 64 65 22 2c 22 63 6f 6d 6d 6f 6e 22\n [2425] 3a 22 43 61 62 6f 20 56 65 72 64 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n [2449] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69 6e 74 20 4b 69 74 74 73\n [2473] 20 61 6e 64 20 4e 65 76 69 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n [2497] 46 65 64 65 72 61 74 69 6f 6e 20 6f 66 20 53 61 69 6e 74 20 43 68 72 69\n [2521] 73 74 6f 70 68 65 72 20 61 6e 64 20 4e 65 76 69 73 22 2c 22 6e 61 74 69\n [2545] 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61\n [2569] 6c 22 3a 22 46 65 64 65 72 61 74 69 6f 6e 20 6f 66 20 53 61 69 6e 74 20\n [2593] 43 68 72 69 73 74 6f 70 68 65 72 20 61 6e 64 20 4e 65 76 69 73 22 2c 22\n [2617] 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69 6e 74 20 4b 69 74 74 73 20 61 6e 64\n [2641] 20 4e 65 76 69 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n [2665] 6d 6d 6f 6e 22 3a 22 4c 61 6f 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n [2689] 22 4c 61 6f 20 50 65 6f 70 6c 65 27 73 20 44 65 6d 6f 63 72 61 74 69 63\n [2713] 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n [2737] 7b 22 6c 61 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0 ba aa e0\n [2761] ba b2 e0 ba 97 e0 ba b2 e0 ba a5 e0 ba b0 e0 ba 99 e0 ba b0 20 e0 ba 8a\n [2785] e0 ba b2 e0 ba 97 e0 ba b4 e0 ba 9b e0 ba b0 e0 bb 84 e0 ba 95 20 e0 ba\n [2809] 84 e0 ba bb e0 ba 99 e0 ba a5 e0 ba b2 e0 ba a7 20 e0 ba 82 e0 ba ad e0\n [2833] ba 87 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 ba aa e0 ba 9b e0 ba 9b e0\n [2857] ba a5 e0 ba b2 e0 ba a7 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n [2881] 63 6f 6d 6d 6f 6e 22 3a 22 43 61 72 69 62 62 65 61 6e 20 4e 65 74 68 65\n [2905] 72 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 6f 6e 61\n [2929] 69 72 65 2c 20 53 69 6e 74 20 45 75 73 74 61 74 69 75 73 20 61 6e 64 20\n [2953] 53 61 62 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6e 6c 64\n [2977] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 6f 6e 61 69 72 65 2c 20\n [3001] 53 69 6e 74 20 45 75 73 74 61 74 69 75 73 20 65 6e 20 53 61 62 61 22 2c\n [3025] 22 63 6f 6d 6d 6f 6e 22 3a 22 43 61 72 69 62 69 73 63 68 20 4e 65 64 65\n [3049] 72 6c 61 6e 64 22 7d 2c 22 70 61 70 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [3073] 22 3a 22 42 6f 6e 65 69 72 75 2c 20 53 69 6e 74 20 45 75 73 74 61 74 69\n [3097] 75 73 20 79 20 53 61 62 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 6e\n [3121] 65 69 72 75 2c 20 53 69 6e 74 20 45 75 73 74 61 74 69 75 73 20 79 20 53\n [3145] 61 62 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n [3169] 6e 22 3a 22 55 67 61 6e 64 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n [3193] 52 65 70 75 62 6c 69 63 20 6f 66 20 55 67 61 6e 64 61 22 2c 22 6e 61 74\n [3217] 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69\n [3241] 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 55 67 61 6e 64 61 22\n [3265] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 55 67 61 6e 64 61 22 7d 2c 22 73 77 61\n [3289] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20\n [3313] 6f 66 20 55 67 61 6e 64 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 55 67 61\n [3337] 6e 64 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n [3361] 6e 22 3a 22 41 6e 64 6f 72 72 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n [3385] 22 50 72 69 6e 63 69 70 61 6c 69 74 79 20 6f 66 20 41 6e 64 6f 72 72 61\n [3409] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 63 61 74 22 3a 7b 22\n [3433] 6f 66 66 69 63 69 61 6c 22 3a 22 50 72 69 6e 63 69 70 61 74 20 64 27 41\n [3457] 6e 64 6f 72 72 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 64 6f 72 72\n [3481] 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n [3505] 3a 22 42 75 72 75 6e 64 69 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n [3529] 65 70 75 62 6c 69 63 20 6f 66 20 42 75 72 75 6e 64 69 22 2c 22 6e 61 74\n [3553] 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69\n [3577] 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 75 20 42 75 72 75\n [3601] 6e 64 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 75 72 75 6e 64 69 22 7d\n [3625] 2c 22 72 75 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n [3649] 62 6c 69 6b 61 20 79 27 55 62 75 72 75 6e 64 69 20 22 2c 22 63 6f 6d 6d\n [3673] 6f 6e 22 3a 22 55 62 75 72 75 6e 64 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n [3697] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 41 66 72 69\n [3721] 63 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63\n [3745] 20 6f 66 20 53 6f 75 74 68 20 41 66 72 69 63 61 22 2c 22 6e 61 74 69 76\n [3769] 65 4e 61 6d 65 22 3a 7b 22 61 66 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [3793] 22 3a 22 52 65 70 75 62 6c 69 65 6b 20 76 61 6e 20 53 75 69 64 2d 41 66\n [3817] 72 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 41 66\n [3841] 72 69 63 61 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n [3865] 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 53 6f 75 74 68 20 41 66 72 69\n [3889] 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 41 66 72 69\n [3913] 63 61 22 7d 2c 22 6e 62 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n [3937] 49 52 69 70 68 61 62 6c 69 6b 69 20 79 65 53 65 77 75 6c 61 20 41 66 72\n [3961] 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 65 77 75 6c 61 20 41 66\n [3985] 72 69 6b 61 22 7d 2c 22 6e 73 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n [4009] 3a 22 52 65 70 68 61 62 6f 6c 69 6b 69 20 79 61 20 41 66 72 69 6b 61 2d\n [4033] 42 6f 72 77 61 20 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 66 72 69 6b 61\n [4057] 2d 42 6f 72 77 61 22 7d 2c 22 73 6f 74 22 3a 7b 22 6f 66 66 69 63 69 61\n [4081] 6c 22 3a 22 52 65 70 68 61 62 6f 6c 69 6b 69 20 79 61 20 41 66 72 69 6b\n [4105] 61 20 42 6f 72 77 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 66 72 69 6b\n [4129] 61 20 42 6f 72 77 61 22 7d 2c 22 73 73 77 22 3a 7b 22 6f 66 66 69 63 69\n [4153] 61 6c 22 3a 22 49 52 69 70 68 61 62 68 75 6c 69 6b 68 69 20 79 65 4e 69\n [4177] 6e 67 69 7a 69 6d 75 20 41 66 72 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22\n [4201] 3a 22 4e 69 6e 67 69 7a 69 6d 75 20 41 66 72 69 6b 61 22 7d 2c 22 74 73\n [4225] 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 68 61 62 6f 6c\n [4249] 69 6b 69 20 79 61 20 41 66 6f 72 69 6b 61 20 42 6f 72 77 61 22 2c 22 63\n [4273] 6f 6d 6d 6f 6e 22 3a 22 41 66 6f 72 69 6b 61 20 42 6f 72 77 61 22 7d 2c\n [4297] 22 74 73 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 69 70 68 61\n [4321] 62 6c 69 6b 69 20 72 61 20 41 66 72 69 6b 61 20 44 7a 6f 6e 67 61 22 2c\n [4345] 22 63 6f 6d 6d 6f 6e 22 3a 22 41 66 72 69 6b 61 20 44 7a 6f 6e 67 61 22\n [4369] 7d 2c 22 76 65 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 69 70\n [4393] 68 61 62 75 e1 b8 bd 69 6b 69 20 79 61 20 41 66 75 72 69 6b 61 20 54 73\n [4417] 68 69 70 65 6d 62 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 66 75 72 69\n [4441] 6b 61 20 54 73 68 69 70 65 6d 62 65 22 7d 2c 22 78 68 6f 22 3a 7b 22 6f\n [4465] 66 66 69 63 69 61 6c 22 3a 22 49 52 69 70 68 61 62 6c 69 6b 69 20 79 61\n [4489] 73 65 4d 7a 61 6e 74 73 69 20 41 66 72 69 6b 61 22 2c 22 63 6f 6d 6d 6f\n [4513] 6e 22 3a 22 4d 7a 61 6e 74 73 69 20 41 66 72 69 6b 61 22 7d 2c 22 7a 75\n [4537] 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 52 69 70 68 61 62 6c\n [4561] 69 6b 69 20 79 61 73 65 4e 69 6e 67 69 7a 69 6d 75 20 41 66 72 69 6b 61\n [4585] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 6e 67 69 7a 69 6d 75 20 41 66\n [4609] 72 69 6b 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n [4633] 6f 6e 22 3a 22 46 72 61 6e 63 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n [4657] 22 46 72 65 6e 63 68 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76\n [4681] 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [4705] 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 66 72 61 6e c3 a7 61 69 73\n [4729] 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46 72 61 6e 63 65 22 7d 7d 7d 7d\n [4753] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 69 62 79\n [4777] 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 65 20 6f 66 20\n [4801] 4c 69 62 79 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72\n [4825] 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 af d9 88\n [4849] d9 84 d8 a9 20 d9 84 d9 8a d8 a8 d9 8a d8 a7 22 2c 22 63 6f 6d 6d 6f 6e\n [4873] 22 3a 22 e2 80 8f d9 84 d9 8a d8 a8 d9 8a d8 a7 22 7d 7d 7d 7d 2c 7b 22\n [4897] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 65 78 69 63 6f 22\n [4921] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 55 6e 69 74 65 64 20 4d 65 78 69\n [4945] 63 61 6e 20 53 74 61 74 65 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n [4969] 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 45 73 74\n [4993] 61 64 6f 73 20 55 6e 69 64 6f 73 20 4d 65 78 69 63 61 6e 6f 73 22 2c 22\n [5017] 63 6f 6d 6d 6f 6e 22 3a 22 4d c3 a9 78 69 63 6f 22 7d 7d 7d 7d 2c 7b 22\n [5041] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 61 62 6f 6e 22 2c\n [5065] 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 61 62 6f 6e 65 73 65 20 52 65 70\n [5089] 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72\n [5113] 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69\n [5137] 71 75 65 20 67 61 62 6f 6e 61 69 73 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n [5161] 22 47 61 62 6f 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n [5185] 6d 6d 6f 6e 22 3a 22 4e 6f 72 74 68 65 72 6e 20 4d 61 72 69 61 6e 61 20\n [5209] 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6d\n [5233] 6d 6f 6e 77 65 61 6c 74 68 20 6f 66 20 74 68 65 20 4e 6f 72 74 68 65 72\n [5257] 6e 20 4d 61 72 69 61 6e 61 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69\n [5281] 76 65 4e 61 6d 65 22 3a 7b 22 63 61 6c 22 3a 7b 22 6f 66 66 69 63 69 61\n [5305] 6c 22 3a 22 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66 20 74 68 65 20\n [5329] 4e 6f 72 74 68 65 72 6e 20 4d 61 72 69 61 6e 61 20 49 73 6c 61 6e 64 73\n [5353] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 74 68 65 72 6e 20 4d 61 72\n [5377] 69 61 6e 61 20 49 73 6c 61 6e 64 73 22 7d 2c 22 63 68 61 22 3a 7b 22 6f\n [5401] 66 66 69 63 69 61 6c 22 3a 22 53 61 6e 6b 61 74 74 61 6e 20 53 69 68 61\n [5425] 20 4e 61 20 49 73 6c 61 73 20 4d 61 72 69 c3 a5 6e 61 73 22 2c 22 63 6f\n [5449] 6d 6d 6f 6e 22 3a 22 4e 61 20 49 73 6c 61 73 20 4d 61 72 69 c3 a5 6e 61\n [5473] 73 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43\n [5497] 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66 20 74 68 65 20 4e 6f 72 74 68\n [5521] 65 72 6e 20 4d 61 72 69 61 6e 61 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f\n [5545] 6d 6d 6f 6e 22 3a 22 4e 6f 72 74 68 65 72 6e 20 4d 61 72 69 61 6e 61 20\n [5569] 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n [5593] 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 74 68 20 4d 61 63 65 64 6f 6e 69 61 22\n [5617] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n [5641] 20 4e 6f 72 74 68 20 4d 61 63 65 64 6f 6e 69 61 22 2c 22 6e 61 74 69 76\n [5665] 65 4e 61 6d 65 22 3a 7b 22 6d 6b 64 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [5689] 22 3a 22 d0 a0 d0 b5 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 20 d0 a1\n [5713] d0 b5 d0 b2 d0 b5 d1 80 d0 bd d0 b0 20 d0 9c d0 b0 d0 ba d0 b5 d0 b4 d0\n [5737] be d0 bd d0 b8 d1 98 d0 b0 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 9c d0\n [5761] b0 d0 ba d0 b5 d0 b4 d0 be d0 bd d0 b8 d1 98 d0 b0 22 7d 7d 7d 7d 2c 7b\n [5785] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 68 69 6e 61 22\n [5809] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 65 6f 70 6c 65 27 73 20 52 65\n [5833] 70 75 62 6c 69 63 20 6f 66 20 43 68 69 6e 61 22 2c 22 6e 61 74 69 76 65\n [5857] 4e 61 6d 65 22 3a 7b 22 7a 68 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n [5881] 3a 22 e4 b8 ad e5 8d 8e e4 ba ba e6 b0 91 e5 85 b1 e5 92 8c e5 9b bd 22\n [5905] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e4 b8 ad e5 9b bd 22 7d 7d 7d 7d 2c 7b\n [5929] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 59 65 6d 65 6e 22\n [5953] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n [5977] 20 59 65 6d 65 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61\n [6001] 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 ac d9\n [6025] 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d9 8a d9 85 d9 86 d9 8a\n [6049] d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d9 8a d9 8e d9 85\n [6073] d9 8e d9 86 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n [6097] 6f 6e 22 3a 22 53 61 69 6e 74 20 42 61 72 74 68 c3 a9 6c 65 6d 79 22 2c\n [6121] 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6c 6c 65 63 74 69 76 69 74 79\n [6145] 20 6f 66 20 53 61 69 6e 74 20 42 61 72 74 68 c3 a9 6c 65 6d 79 22 2c 22\n [6169] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66\n [6193] 69 63 69 61 6c 22 3a 22 43 6f 6c 6c 65 63 74 69 76 69 74 c3 a9 20 64 65\n [6217] 20 53 61 69 6e 74 2d 42 61 72 74 68 c3 a9 6c 65 6d 79 22 2c 22 63 6f 6d\n [6241] 6d 6f 6e 22 3a 22 53 61 69 6e 74 2d 42 61 72 74 68 c3 a9 6c 65 6d 79 22\n [6265] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n [6289] 47 75 65 72 6e 73 65 79 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 61\n [6313] 69 6c 69 77 69 63 6b 20 6f 66 20 47 75 65 72 6e 73 65 79 22 2c 22 6e 61\n [6337] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n [6361] 69 61 6c 22 3a 22 42 61 69 6c 69 77 69 63 6b 20 6f 66 20 47 75 65 72 6e\n [6385] 73 65 79 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 65 72 6e 73 65 79 22\n [6409] 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 61 69\n [6433] 6c 6c 69 61 67 65 20 64 65 20 47 75 65 72 6e 65 73 65 79 22 2c 22 63 6f\n [6457] 6d 6d 6f 6e 22 3a 22 47 75 65 72 6e 65 73 65 79 22 7d 2c 22 6e 66 72 22\n [6481] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 67 c3 a8 72 6e c3 a9 73 69\n [6505] 61 69 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 44 67 c3 a8 72 6e c3 a9 73\n [6529] 69 61 69 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n [6553] 6f 6e 22 3a 22 53 6f 6c 6f 6d 6f 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6f\n [6577] 66 66 69 63 69 61 6c 22 3a 22 53 6f 6c 6f 6d 6f 6e 20 49 73 6c 61 6e 64\n [6601] 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b\n [6625] 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 6f 6c 6f 6d 6f 6e 20 49 73 6c 61\n [6649] 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 6c 6f 6d 6f 6e 20 49\n [6673] 73 6c 61 6e 64 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n [6697] 6d 6d 6f 6e 22 3a 22 53 76 61 6c 62 61 72 64 20 61 6e 64 20 4a 61 6e 20\n [6721] 4d 61 79 65 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 76 61 6c 62\n [6745] 61 72 64 20 6f 67 20 4a 61 6e 20 4d 61 79 65 6e 22 2c 22 6e 61 74 69 76\n [6769] 65 4e 61 6d 65 22 3a 7b 22 6e 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [6793] 22 3a 22 53 76 61 6c 62 61 72 64 20 6f 67 20 4a 61 6e 20 4d 61 79 65 6e\n [6817] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 76 61 6c 62 61 72 64 20 6f 67 20\n [6841] 4a 61 6e 20 4d 61 79 65 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n [6865] 22 63 6f 6d 6d 6f 6e 22 3a 22 46 61 72 6f 65 20 49 73 6c 61 6e 64 73 22\n [6889] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 61 72 6f 65 20 49 73 6c 61 6e\n [6913] 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 64 61 6e 22 3a\n [6937] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 c3 a6 72 c3 b8 65 72 6e 65 22\n [6961] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46 c3 a6 72 c3 b8 65 72 6e 65 22 7d 2c\n [6985] 22 66 61 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 c3 b8 72 6f\n [7009] 79 61 72 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46 c3 b8 72 6f 79 61 72 22\n [7033] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n [7057] 55 7a 62 65 6b 69 73 74 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n [7081] 52 65 70 75 62 6c 69 63 20 6f 66 20 55 7a 62 65 6b 69 73 74 61 6e 22 2c\n [7105] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 72 75 73 22 3a 7b 22 6f 66\n [7129] 66 69 63 69 61 6c 22 3a 22 d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0 bb d0\n [7153] b8 d0 ba d0 b0 20 d0 a3 d0 b7 d0 b1 d0 b5 d0 ba d0 b8 d1 81 d1 82 d0 b0\n [7177] d0 bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a3 d0 b7 d0 b1 d0 b5 d0 ba\n [7201] d0 b8 d1 81 d1 82 d0 b0 d0 bd 22 7d 2c 22 75 7a 62 22 3a 7b 22 6f 66 66\n [7225] 69 63 69 61 6c 22 3a 22 4f 27 7a 62 65 6b 69 73 74 6f 6e 20 52 65 73 70\n [7249] 75 62 6c 69 6b 61 73 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4f e2 80 98\n [7273] 7a 62 65 6b 69 73 74 6f 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n [7297] 22 63 6f 6d 6d 6f 6e 22 3a 22 45 67 79 70 74 22 2c 22 6f 66 66 69 63 69\n [7321] 61 6c 22 3a 22 41 72 61 62 20 52 65 70 75 62 6c 69 63 20 6f 66 20 45 67\n [7345] 79 70 74 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22\n [7369] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 ac d9 85 d9 87 d9 88 d8 b1\n [7393] d9 8a d8 a9 20 d9 85 d8 b5 d8 b1 20 d8 a7 d9 84 d8 b9 d8 b1 d8 a8 d9 8a\n [7417] d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d9 85 d8 b5 d8 b1 22 7d 7d 7d\n [7441] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 65 6e\n [7465] 65 67 61 6c 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n [7489] 69 63 20 6f 66 20 53 65 6e 65 67 61 6c 22 2c 22 6e 61 74 69 76 65 4e 61\n [7513] 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n [7537] 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 75 20 53 c3 a9 6e c3 a9 67 61 6c\n [7561] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 c3 a9 6e c3 a9 67 61 6c 22 7d 7d\n [7585] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 72\n [7609] 69 20 4c 61 6e 6b 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 65 6d\n [7633] 6f 63 72 61 74 69 63 20 53 6f 63 69 61 6c 69 73 74 20 52 65 70 75 62 6c\n [7657] 69 63 20 6f 66 20 53 72 69 20 4c 61 6e 6b 61 22 2c 22 6e 61 74 69 76 65\n [7681] 4e 61 6d 65 22 3a 7b 22 73 69 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n [7705] 3a 22 e0 b7 81 e0 b7 8a e2 80 8d e0 b6 bb e0 b7 93 20 e0 b6 bd e0 b6 82\n [7729] e0 b6 9a e0 b7 8f 20 e0 b6 b4 e0 b7 8a e2 80 8d e0 b6 bb e0 b6 a2 e0 b7\n [7753] 8f e0 b6 ad e0 b7 8f e0 b6 b1 e0 b7 8a e0 b6 ad e0 b7 8a e2 80 8d e0 b6\n [7777] bb e0 b7 92 e0 b6 9a 20 e0 b7 83 e0 b6 b8 e0 b7 8f e0 b6 a2 e0 b7 80 e0\n [7801] b7 8f e0 b6 af e0 b7 93 20 e0 b6 a2 e0 b6 b1 e0 b6 bb e0 b6 a2 e0 b6 ba\n [7825] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 b7 81 e0 b7 8a e2 80 8d e0 b6 bb\n [7849] e0 b7 93 20 e0 b6 bd e0 b6 82 e0 b6 9a e0 b7 8f e0 b7 80 22 7d 2c 22 74\n [7873] 61 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0 ae 87 e0 ae b2 e0\n [7897] ae 99 e0 af 8d e0 ae 95 e0 af 88 20 e0 ae 9a e0 ae a9 e0 ae a8 e0 ae be\n [7921] e0 ae af e0 ae 95 20 e0 ae 9a e0 af 8b e0 ae 9a e0 ae b2 e0 ae bf e0 ae\n [7945] 9a e0 ae 95 e0 af 8d 20 e0 ae 95 e0 af 81 e0 ae 9f e0 ae bf e0 ae af e0\n [7969] ae b0 e0 ae 9a e0 af 81 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 ae 87 e0\n [7993] ae b2 e0 ae 99 e0 af 8d e0 ae 95 e0 af 88 22 7d 7d 7d 7d 2c 7b 22 6e 61\n [8017] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6c 65 73 74 69 6e 65\n [8041] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 65 20 6f 66 20 50\n [8065] 61 6c 65 73 74 69 6e 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n [8089] 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 af d9 88 d9\n [8113] 84 d8 a9 20 d9 81 d9 84 d8 b3 d8 b7 d9 8a d9 86 22 2c 22 63 6f 6d 6d 6f\n [8137] 6e 22 3a 22 d9 81 d9 84 d8 b3 d8 b7 d9 8a d9 86 22 7d 7d 7d 7d 2c 7b 22\n [8161] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 61 6e 67 6c 61 64\n [8185] 65 73 68 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 65 6f 70 6c 65 27\n [8209] 73 20 52 65 70 75 62 6c 69 63 20 6f 66 20 42 61 6e 67 6c 61 64 65 73 68\n [8233] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 65 6e 22 3a 7b 22\n [8257] 6f 66 66 69 63 69 61 6c 22 3a 22 e0 a6 ac e0 a6 be e0 a6 82 e0 a6 b2 e0\n [8281] a6 be e0 a6 a6 e0 a7 87 e0 a6 b6 20 e0 a6 97 e0 a6 a3 e0 a6 aa e0 a7 8d\n [8305] e0 a6 b0 e0 a6 9c e0 a6 be e0 a6 a4 e0 a6 a8 e0 a7 8d e0 a6 a4 e0 a7 8d\n [8329] e0 a6 b0 e0 a7 80 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 a6 ac e0 a6 be\n [8353] e0 a6 82 e0 a6 b2 e0 a6 be e0 a6 a6 e0 a7 87 e0 a6 b6 22 7d 7d 7d 7d 2c\n [8377] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 65 72 75 22\n [8401] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n [8425] 20 50 65 72 75 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 79\n [8449] 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 69 72 75 77 20 53 75\n [8473] 79 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 69 72 75 77 22 7d 2c 22 71\n [8497] 75 65 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 69 72 75 77 20 52\n [8521] 69 70 75 77 6c 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 69 72 75\n [8545] 77 22 7d 2c 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n [8569] 65 70 c3 ba 62 6c 69 63 61 20 64 65 6c 20 50 65 72 c3 ba 22 2c 22 63 6f\n [8593] 6d 6d 6f 6e 22 3a 22 50 65 72 c3 ba 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n [8617] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 69 6e 67 61 70 6f 72 65 22 2c\n [8641] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20\n [8665] 53 69 6e 67 61 70 6f 72 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n [8689] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n [8713] 62 6c 69 63 20 6f 66 20 53 69 6e 67 61 70 6f 72 65 22 2c 22 63 6f 6d 6d\n [8737] 6f 6e 22 3a 22 53 69 6e 67 61 70 6f 72 65 22 7d 2c 22 7a 68 6f 22 3a 7b\n [8761] 22 6f 66 66 69 63 69 61 6c 22 3a 22 e6 96 b0 e5 8a a0 e5 9d a1 e5 85 b1\n [8785] e5 92 8c e5 9b bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e6 96 b0 e5 8a a0\n [8809] e5 9d a1 22 7d 2c 22 6d 73 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n [8833] 22 52 65 70 75 62 6c 69 6b 20 53 69 6e 67 61 70 75 72 61 22 2c 22 63 6f\n [8857] 6d 6d 6f 6e 22 3a 22 53 69 6e 67 61 70 75 72 61 22 7d 2c 22 74 61 6d 22\n [8881] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0 ae 9a e0 ae bf e0 ae 99 e0\n [8905] af 8d e0 ae 95 e0 ae aa e0 af 8d e0 ae aa e0 af 82 e0 ae b0 e0 af 8d 20\n [8929] e0 ae 95 e0 af 81 e0 ae 9f e0 ae bf e0 ae af e0 ae b0 e0 ae 9a e0 af 81\n [8953] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 ae 9a e0 ae bf e0 ae 99 e0 af 8d\n [8977] e0 ae 95 e0 ae aa e0 af 8d e0 ae aa e0 af 82 e0 ae b0 e0 af 8d 22 7d 7d\n [9001] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 54 75\n [9025] 72 6b 65 79 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n [9049] 69 63 20 6f 66 20 54 75 72 6b 65 79 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n [9073] 65 22 3a 7b 22 74 75 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 54\n [9097] c3 bc 72 6b 69 79 65 20 43 75 6d 68 75 72 69 79 65 74 69 22 2c 22 63 6f\n [9121] 6d 6d 6f 6e 22 3a 22 54 c3 bc 72 6b 69 79 65 22 7d 7d 7d 7d 2c 7b 22 6e\n [9145] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 66 67 68 61 6e 69 73\n [9169] 74 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 61 6d 69 63\n [9193] 20 52 65 70 75 62 6c 69 63 20 6f 66 20 41 66 67 68 61 6e 69 73 74 61 6e\n [9217] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 72 73 22 3a 7b 22\n [9241] 6f 66 66 69 63 69 61 6c 22 3a 22 d8 ac d9 85 d9 87 d9 88 d8 b1 db 8c 20\n [9265] d8 a7 d8 b3 d9 84 d8 a7 d9 85 db 8c 20 d8 a7 d9 81 d8 ba d8 a7 d9 86 d8\n [9289] b3 d8 aa d8 a7 d9 86 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 81 d8\n [9313] ba d8 a7 d9 86 d8 b3 d8 aa d8 a7 d9 86 22 7d 2c 22 70 75 73 22 3a 7b 22\n [9337] 6f 66 66 69 63 69 61 6c 22 3a 22 d8 af 20 d8 a7 d9 81 d8 ba d8 a7 d9 86\n [9361] d8 b3 d8 aa d8 a7 d9 86 20 d8 a7 d8 b3 d9 84 d8 a7 d9 85 d9 8a 20 d8 ac\n [9385] d9 85 d9 87 d9 88 d8 b1 db 8c d8 aa 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n [9409] d8 a7 d9 81 d8 ba d8 a7 d9 86 d8 b3 d8 aa d8 a7 d9 86 22 7d 2c 22 74 75\n [9433] 6b 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4f 77 67 61 6e 79 73 74\n [9457] 61 6e 20 59 73 6c 61 6d 20 52 65 73 70 75 62 6c 69 6b 61 73 79 22 2c 22\n [9481] 63 6f 6d 6d 6f 6e 22 3a 22 4f 77 67 61 6e 79 73 74 61 6e 22 7d 7d 7d 7d\n [9505] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 72 75 62\n [9529] 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 72 75 62 61 22 2c 22 6e\n [9553] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6e 6c 64 22 3a 7b 22 6f 66 66 69\n [9577] 63 69 61 6c 22 3a 22 41 72 75 62 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n [9601] 41 72 75 62 61 22 7d 2c 22 70 61 70 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [9625] 22 3a 22 41 72 75 62 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 72 75 62\n [9649] 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n [9673] 3a 22 43 6f 6f 6b 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61\n [9697] 6c 22 3a 22 43 6f 6f 6b 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76\n [9721] 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n [9745] 22 3a 22 43 6f 6f 6b 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e\n [9769] 22 3a 22 43 6f 6f 6b 20 49 73 6c 61 6e 64 73 22 7d 2c 22 72 61 72 22 3a\n [9793] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b c5 ab 6b 69 20 27 c4 80 69 72\n [9817] 61 6e 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b c5 ab 6b 69 20 27 c4 80\n [9841] 69 72 61 6e 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n [9865] 6d 6f 6e 22 3a 22 55 6e 69 74 65 64 20 4b 69 6e 67 64 6f 6d 22 2c 22 6f\n [9889] 66 66 69 63 69 61 6c 22 3a 22 55 6e 69 74 65 64 20 4b 69 6e 67 64 6f 6d\n [9913] 20 6f 66 20 47 72 65 61 74 20 42 72 69 74 61 69 6e 20 61 6e 64 20 4e 6f\n [9937] 72 74 68 65 72 6e 20 49 72 65 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e\n [9961] 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n [9985] 22 55 6e 69 74 65 64 20 4b 69 6e 67 64 6f 6d 20 6f 66 20 47 72 65 61 74\n[10009] 20 42 72 69 74 61 69 6e 20 61 6e 64 20 4e 6f 72 74 68 65 72 6e 20 49 72\n[10033] 65 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6e 69 74 65 64 20\n[10057] 4b 69 6e 67 64 6f 6d 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[10081] 6f 6d 6d 6f 6e 22 3a 22 5a 61 6d 62 69 61 22 2c 22 6f 66 66 69 63 69 61\n[10105] 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 61 6d 62 69 61 22 2c\n[10129] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[10153] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 61 6d\n[10177] 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 61 6d 62 69 61 22 7d 7d\n[10201] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 46 69\n[10225] 6e 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[10249] 6c 69 63 20 6f 66 20 46 69 6e 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e\n[10273] 61 6d 65 22 3a 7b 22 66 69 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[10297] 22 53 75 6f 6d 65 6e 20 74 61 73 61 76 61 6c 74 61 22 2c 22 63 6f 6d 6d\n[10321] 6f 6e 22 3a 22 53 75 6f 6d 69 22 7d 2c 22 73 77 65 22 3a 7b 22 6f 66 66\n[10345] 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 65 6e 20 46 69 6e 6c 61\n[10369] 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46 69 6e 6c 61 6e 64 22 7d 7d\n[10393] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69\n[10417] 67 65 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n[10441] 63 20 6f 66 20 4e 69 67 65 72 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[10465] 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9\n[10489] 70 75 62 6c 69 71 75 65 20 64 75 20 4e 69 67 65 72 22 2c 22 63 6f 6d 6d\n[10513] 6f 6e 22 3a 22 4e 69 67 65 72 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[10537] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 68 72 69 73 74 6d 61 73 20 49 73 6c\n[10561] 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 65 72 72 69 74 6f\n[10585] 72 79 20 6f 66 20 43 68 72 69 73 74 6d 61 73 20 49 73 6c 61 6e 64 22 2c\n[10609] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[10633] 66 69 63 69 61 6c 22 3a 22 54 65 72 72 69 74 6f 72 79 20 6f 66 20 43 68\n[10657] 72 69 73 74 6d 61 73 20 49 73 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22\n[10681] 3a 22 43 68 72 69 73 74 6d 61 73 20 49 73 6c 61 6e 64 22 7d 7d 7d 7d 2c\n[10705] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 54 6f 6b 65 6c\n[10729] 61 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 6f 6b 65 6c 61 75 22\n[10753] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f\n[10777] 66 66 69 63 69 61 6c 22 3a 22 54 6f 6b 65 6c 61 75 22 2c 22 63 6f 6d 6d\n[10801] 6f 6e 22 3a 22 54 6f 6b 65 6c 61 75 22 7d 2c 22 73 6d 6f 22 3a 7b 22 6f\n[10825] 66 66 69 63 69 61 6c 22 3a 22 54 6f 6b 65 6c 61 75 22 2c 22 63 6f 6d 6d\n[10849] 6f 6e 22 3a 22 54 6f 6b 65 6c 61 75 22 7d 2c 22 74 6b 6c 22 3a 7b 22 6f\n[10873] 66 66 69 63 69 61 6c 22 3a 22 54 6f 6b 65 6c 61 75 22 2c 22 63 6f 6d 6d\n[10897] 6f 6e 22 3a 22 54 6f 6b 65 6c 61 75 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[10921] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69 6e 65 61 2d 42 69 73 73\n[10945] 61 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63\n[10969] 20 6f 66 20 47 75 69 6e 65 61 2d 42 69 73 73 61 75 22 2c 22 6e 61 74 69\n[10993] 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61\n[11017] 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 61 20 47 75 69 6e c3 a9\n[11041] 2d 42 69 73 73 61 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69 6e c3\n[11065] a9 2d 42 69 73 73 61 75 22 7d 2c 22 70 6f 76 22 3a 7b 22 6f 66 66 69 63\n[11089] 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 61 20 47 75 69 6e\n[11113] c3 a9 2d 42 69 73 73 61 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69\n[11137] 6e c3 a9 2d 42 69 73 73 61 75 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[11161] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 7a 65 72 62 61 69 6a 61 6e 22 2c 22\n[11185] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 41\n[11209] 7a 65 72 62 61 69 6a 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[11233] 7b 22 61 7a 65 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 7a c9 99\n[11257] 72 62 61 79 63 61 6e 20 52 65 73 70 75 62 6c 69 6b 61 73 c4 b1 22 2c 22\n[11281] 63 6f 6d 6d 6f 6e 22 3a 22 41 7a c9 99 72 62 61 79 63 61 6e 22 7d 7d 7d\n[11305] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 52 c3 a9\n[11329] 75 6e 69 6f 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 75 6e\n[11353] 69 6f 6e 20 49 73 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[11377] 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 6c 65\n[11401] 20 64 65 20 6c 61 20 52 c3 a9 75 6e 69 6f 6e 22 2c 22 63 6f 6d 6d 6f 6e\n[11425] 22 3a 22 4c 61 20 52 c3 a9 75 6e 69 6f 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[11449] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 44 6a 69 62 6f 75 74 69 22\n[11473] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n[11497] 20 44 6a 69 62 6f 75 74 69 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[11521] 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 ac d9 85\n[11545] d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 ac d9 8a d8 a8 d9 88 d8 aa d9 8a 22\n[11569] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 ac d9 8a d8 a8 d9 88 d8 aa d9 8a e2\n[11593] 80 8e 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[11617] 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 20 44 6a 69 62 6f 75 74 69 22\n[11641] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 44 6a 69 62 6f 75 74 69 22 7d 7d 7d 7d\n[11665] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 74\n[11689] 68 20 4b 6f 72 65 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 65 6d\n[11713] 6f 63 72 61 74 69 63 20 50 65 6f 70 6c 65 27 73 20 52 65 70 75 62 6c 69\n[11737] 63 20 6f 66 20 4b 6f 72 65 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[11761] 3a 7b 22 6b 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 ec a1 b0\n[11785] ec 84 a0 eb af bc ec a3 bc ec a3 bc ec 9d 98 ec 9d b8 eb af bc ea b3 b5\n[11809] ed 99 94 ea b5 ad 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 ec a1 b0 ec 84 a0\n[11833] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[11857] 22 4d 61 75 72 69 74 69 75 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[11881] 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 61 75 72 69 74 69 75 73 22 2c 22\n[11905] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66\n[11929] 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 61 75 72\n[11953] 69 74 69 75 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 75 72 69 74 69\n[11977] 75 73 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[12001] 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 20 4d 61 75 72 69 63 65 22 2c\n[12025] 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 75 72 69 63 65 22 7d 2c 22 6d 66 65\n[12049] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 20\n[12073] 4d 6f 72 69 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 72 69 73 22 7d\n[12097] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d\n[12121] 6f 6e 74 73 65 72 72 61 74 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d\n[12145] 6f 6e 74 73 65 72 72 61 74 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[12169] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 6f 6e 74\n[12193] 73 65 72 72 61 74 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 6e 74 73 65\n[12217] 72 72 61 74 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[12241] 6f 6e 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 56 69 72 67 69\n[12265] 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 56\n[12289] 69 72 67 69 6e 20 49 73 6c 61 6e 64 73 20 6f 66 20 74 68 65 20 55 6e 69\n[12313] 74 65 64 20 53 74 61 74 65 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[12337] 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 56 69 72\n[12361] 67 69 6e 20 49 73 6c 61 6e 64 73 20 6f 66 20 74 68 65 20 55 6e 69 74 65\n[12385] 64 20 53 74 61 74 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6e 69 74\n[12409] 65 64 20 53 74 61 74 65 73 20 56 69 72 67 69 6e 20 49 73 6c 61 6e 64 73\n[12433] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[12457] 22 43 6f 6c 6f 6d 62 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[12481] 65 70 75 62 6c 69 63 20 6f 66 20 43 6f 6c 6f 6d 62 69 61 22 2c 22 6e 61\n[12505] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63\n[12529] 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 43 6f 6c 6f\n[12553] 6d 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 6c 6f 6d 62 69 61\n[12577] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[12601] 22 47 72 65 65 63 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 48 65 6c\n[12625] 6c 65 6e 69 63 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e\n[12649] 61 6d 65 22 3a 7b 22 65 6c 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[12673] 22 ce 95 ce bb ce bb ce b7 ce bd ce b9 ce ba ce ae 20 ce 94 ce b7 ce bc\n[12697] ce bf ce ba cf 81 ce b1 cf 84 ce af ce b1 22 2c 22 63 6f 6d 6d 6f 6e 22\n[12721] 3a 22 ce 95 ce bb ce bb ce ac ce b4 ce b1 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[12745] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 72 6f 61 74 69 61 22 2c\n[12769] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20\n[12793] 43 72 6f 61 74 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[12817] 68 72 76 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[12841] 69 6b 61 20 48 72 76 61 74 73 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[12865] 48 72 76 61 74 73 6b 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[12889] 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 72 6f 63 63 6f 22 2c 22 6f 66 66 69 63\n[12913] 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 4d 6f 72 6f 63 63 6f\n[12937] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22\n[12961] 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d9 85 d9 85 d9 84 d9 83 d8\n[12985] a9 20 d8 a7 d9 84 d9 85 d8 ba d8 b1 d8 a8 d9 8a d8 a9 22 2c 22 63 6f 6d\n[13009] 6d 6f 6e 22 3a 22 d8 a7 d9 84 d9 85 d8 ba d8 b1 d8 a8 22 7d 2c 22 62 65\n[13033] 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e2 b5 9c e2 b4 b0 e2 b4\n[13057] b3 e2 b5 8d e2 b4 b7 e2 b5 89 e2 b5 9c 20 e2 b5 8f 20 e2 b5 8d e2 b5 8e\n[13081] e2 b5 96 e2 b5 94 e2 b5 89 e2 b4 b1 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[13105] e2 b5 8d e2 b5 8e e2 b4 b0 e2 b5 96 e2 b5 94 e2 b5 89 e2 b4 b1 22 7d 7d\n[13129] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6c\n[13153] 67 65 72 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 65 6f 70 6c\n[13177] 65 27 73 20 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62 6c 69 63 20\n[13201] 6f 66 20 41 6c 67 65 72 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[13225] 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9\n[13249] 84 d8 ac d9 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 af d9 8a\n[13273] d9 85 d9 82 d8 b1 d8 a7 d8 b7 d9 8a d8 a9 20 d8 a7 d9 84 d8 b4 d8 b9 d8\n[13297] a8 d9 8a d8 a9 20 d8 a7 d9 84 d8 ac d8 b2 d8 a7 d8 a6 d8 b1 d9 8a d8 a9\n[13321] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d8 ac d8 b2 d8 a7 d8 a6\n[13345] d8 b1 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[13369] 22 3a 22 41 6e 74 61 72 63 74 69 63 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[13393] 22 3a 22 41 6e 74 61 72 63 74 69 63 61 22 2c 22 6e 61 74 69 76 65 4e 61\n[13417] 6d 65 22 3a 7b 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[13441] 6e 22 3a 22 4e 65 74 68 65 72 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69\n[13465] 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 74 68 65 20 4e 65 74 68\n[13489] 65 72 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[13513] 6e 6c 64 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 6f 6e 69 6e 6b\n[13537] 72 69 6a 6b 20 64 65 72 20 4e 65 64 65 72 6c 61 6e 64 65 6e 22 2c 22 63\n[13561] 6f 6d 6d 6f 6e 22 3a 22 4e 65 64 65 72 6c 61 6e 64 22 7d 7d 7d 7d 2c 7b\n[13585] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 75 64 61 6e 22\n[13609] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n[13633] 20 74 68 65 20 53 75 64 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[13657] 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 ac d9\n[13681] 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 b3 d9 88 d8 af d8 a7\n[13705] d9 86 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d8 b3 d9 88 d8 af\n[13729] d8 a7 d9 86 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[13753] 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 53 75 64 61 6e 22\n[13777] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 75 64 61 6e 22 7d 7d 7d 7d 2c 7b 22\n[13801] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 46 69 6a 69 22 2c 22\n[13825] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 46\n[13849] 69 6a 69 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22\n[13873] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[13897] 66 20 46 69 6a 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46 69 6a 69 22 7d\n[13921] 2c 22 66 69 6a 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 61 74 61\n[13945] 6e 69 74 75 20 54 75 67 61 6c 61 6c 61 20 6f 20 56 69 74 69 22 2c 22 63\n[13969] 6f 6d 6d 6f 6e 22 3a 22 56 69 74 69 22 7d 2c 22 68 69 66 22 3a 7b 22 6f\n[13993] 66 66 69 63 69 61 6c 22 3a 22 e0 a4 b0 e0 a4 bf e0 a4 aa e0 a4 ac e0 a5\n[14017] 8d e0 a4 b2 e0 a4 bf e0 a4 95 20 e0 a4 91 e0 a4 ab 20 e0 a4 ab e0 a5 80\n[14041] e0 a4 9c e0 a5 80 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 a4 ab e0 a4 bf\n[14065] e0 a4 9c e0 a5 80 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n[14089] 6d 6d 6f 6e 22 3a 22 4c 69 65 63 68 74 65 6e 73 74 65 69 6e 22 2c 22 6f\n[14113] 66 66 69 63 69 61 6c 22 3a 22 50 72 69 6e 63 69 70 61 6c 69 74 79 20 6f\n[14137] 66 20 4c 69 65 63 68 74 65 6e 73 74 65 69 6e 22 2c 22 6e 61 74 69 76 65\n[14161] 4e 61 6d 65 22 3a 7b 22 64 65 75 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[14185] 3a 22 46 c3 bc 72 73 74 65 6e 74 75 6d 20 4c 69 65 63 68 74 65 6e 73 74\n[14209] 65 69 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 69 65 63 68 74 65 6e 73\n[14233] 74 65 69 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[14257] 6f 6e 22 3a 22 4e 65 70 61 6c 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[14281] 46 65 64 65 72 61 6c 20 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62\n[14305] 6c 69 63 20 6f 66 20 4e 65 70 61 6c 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[14329] 65 22 3a 7b 22 6e 65 70 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0\n[14353] a4 a8 e0 a5 87 e0 a4 aa e0 a4 be e0 a4 b2 20 e0 a4 b8 e0 a4 82 e0 a4 98\n[14377] e0 a5 80 e0 a4 af 20 e0 a4 b2 e0 a5 8b e0 a4 95 e0 a4 a4 e0 a4 be e0 a4\n[14401] a8 e0 a5 8d e0 a4 a4 e0 a5 8d e0 a4 b0 e0 a4 bf e0 a4 95 20 e0 a4 97 e0\n[14425] a4 a3 e0 a4 a4 e0 a4 a8 e0 a5 8d e0 a4 a4 e0 a5 8d e0 a4 b0 22 2c 22 63\n[14449] 6f 6d 6d 6f 6e 22 3a 22 e0 a4 a8 e0 a5 87 e0 a4 aa e0 a4 be e0 a4 b2 22\n[14473] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[14497] 50 75 65 72 74 6f 20 52 69 63 6f 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[14521] 22 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66 20 50 75 65 72 74 6f 20\n[14545] 52 69 63 6f 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67\n[14569] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d 6f 6e 77 65 61\n[14593] 6c 74 68 20 6f 66 20 50 75 65 72 74 6f 20 52 69 63 6f 22 2c 22 63 6f 6d\n[14617] 6d 6f 6e 22 3a 22 50 75 65 72 74 6f 20 52 69 63 6f 22 7d 2c 22 73 70 61\n[14641] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 45 73 74 61 64 6f 20 4c 69\n[14665] 62 72 65 20 41 73 6f 63 69 61 64 6f 20 64 65 20 50 75 65 72 74 6f 20 52\n[14689] 69 63 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 75 65 72 74 6f 20 52 69\n[14713] 63 6f 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[14737] 22 3a 22 47 65 6f 72 67 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[14761] 47 65 6f 72 67 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[14785] 6b 61 74 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e1 83 a1 e1 83 90\n[14809] e1 83 a5 e1 83 90 e1 83 a0 e1 83 97 e1 83 95 e1 83 94 e1 83 9a e1 83 9d\n[14833] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e1 83 a1 e1 83 90 e1 83 a5 e1 83 90\n[14857] e1 83 a0 e1 83 97 e1 83 95 e1 83 94 e1 83 9a e1 83 9d 22 7d 7d 7d 7d 2c\n[14881] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6b 69 73\n[14905] 74 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 61 6d 69 63\n[14929] 20 52 65 70 75 62 6c 69 63 20 6f 66 20 50 61 6b 69 73 74 61 6e 22 2c 22\n[14953] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66\n[14977] 69 63 69 61 6c 22 3a 22 49 73 6c 61 6d 69 63 20 52 65 70 75 62 6c 69 63\n[15001] 20 6f 66 20 50 61 6b 69 73 74 61 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[15025] 50 61 6b 69 73 74 61 6e 22 7d 2c 22 75 72 64 22 3a 7b 22 6f 66 66 69 63\n[15049] 69 61 6c 22 3a 22 d8 a7 d8 b3 d9 84 d8 a7 d9 85 db 8c 20 d8 ac d9 85 db\n[15073] 81 d9 88 d8 b1 db 8c db 82 20 d9 be d8 a7 d9 83 d8 b3 d8 aa d8 a7 d9 86\n[15097] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d9 be d8 a7 d9 83 d8 b3 d8 aa d8 a7\n[15121] d9 86 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[15145] 22 3a 22 4d 6f 6e 61 63 6f 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 50\n[15169] 72 69 6e 63 69 70 61 6c 69 74 79 20 6f 66 20 4d 6f 6e 61 63 6f 22 2c 22\n[15193] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66\n[15217] 69 63 69 61 6c 22 3a 22 50 72 69 6e 63 69 70 61 75 74 c3 a9 20 64 65 20\n[15241] 4d 6f 6e 61 63 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 6e 61 63 6f\n[15265] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[15289] 22 42 6f 74 73 77 61 6e 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[15313] 65 70 75 62 6c 69 63 20 6f 66 20 42 6f 74 73 77 61 6e 61 22 2c 22 6e 61\n[15337] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n[15361] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 42 6f 74 73 77 61\n[15385] 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 74 73 77 61 6e 61 22 7d\n[15409] 2c 22 74 73 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4c 65 66 61\n[15433] 74 73 68 65 20 6c 61 20 42 6f 74 73 77 61 6e 61 22 2c 22 63 6f 6d 6d 6f\n[15457] 6e 22 3a 22 42 6f 74 73 77 61 6e 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[15481] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 65 62 61 6e 6f 6e 22 2c 22 6f\n[15505] 66 66 69 63 69 61 6c 22 3a 22 4c 65 62 61 6e 65 73 65 20 52 65 70 75 62\n[15529] 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22\n[15553] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 ac d9 85 d9 87\n[15577] d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d9 84 d8 a8 d9 86 d8 a7 d9 86 d9\n[15601] 8a d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d9 84 d8 a8 d9 86 d8 a7 d9\n[15625] 86 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[15649] c3 a9 70 75 62 6c 69 71 75 65 20 6c 69 62 61 6e 61 69 73 65 22 2c 22 63\n[15673] 6f 6d 6d 6f 6e 22 3a 22 4c 69 62 61 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[15697] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 70 75 61 20 4e 65 77 20\n[15721] 47 75 69 6e 65 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 6e 64 65\n[15745] 70 65 6e 64 65 6e 74 20 53 74 61 74 65 20 6f 66 20 50 61 70 75 61 20 4e\n[15769] 65 77 20 47 75 69 6e 65 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[15793] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 6e 64 65\n[15817] 70 65 6e 64 65 6e 74 20 53 74 61 74 65 20 6f 66 20 50 61 70 75 61 20 4e\n[15841] 65 77 20 47 75 69 6e 65 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 70\n[15865] 75 61 20 4e 65 77 20 47 75 69 6e 65 61 22 7d 2c 22 68 6d 6f 22 3a 7b 22\n[15889] 6f 66 66 69 63 69 61 6c 22 3a 22 49 6e 64 65 70 65 6e 64 65 6e 20 53 74\n[15913] 65 74 20 62 69 6c 6f 6e 67 20 50 61 70 75 61 20 4e 69 75 67 69 6e 69 22\n[15937] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 70 75 61 20 4e 69 75 20 47 69 6e\n[15961] 69 22 7d 2c 22 74 70 69 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 49\n[15985] 6e 64 65 70 65 6e 64 65 6e 20 53 74 65 74 20 62 69 6c 6f 6e 67 20 50 61\n[16009] 70 75 61 20 4e 69 75 67 69 6e 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50\n[16033] 61 70 75 61 20 4e 69 75 67 69 6e 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[16057] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 79 6f 74 74 65 22 2c 22 6f\n[16081] 66 66 69 63 69 61 6c 22 3a 22 44 65 70 61 72 74 6d 65 6e 74 20 6f 66 20\n[16105] 4d 61 79 6f 74 74 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[16129] 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 c3 a9 70 61 72\n[16153] 74 65 6d 65 6e 74 20 64 65 20 4d 61 79 6f 74 74 65 22 2c 22 63 6f 6d 6d\n[16177] 6f 6e 22 3a 22 4d 61 79 6f 74 74 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[16201] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 44 6f 6d 69 6e 69 63 61 6e 20 52\n[16225] 65 70 75 62 6c 69 63 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 6f 6d\n[16249] 69 6e 69 63 61 6e 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65\n[16273] 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[16297] 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 44 6f 6d 69 6e 69 63 61 6e 61 22\n[16321] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 44 6f\n[16345] 6d 69 6e 69 63 61 6e 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[16369] 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 66 6f 6c 6b 20 49 73 6c 61 6e 64 22\n[16393] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 65 72 72 69 74 6f 72 79 20 6f\n[16417] 66 20 4e 6f 72 66 6f 6c 6b 20 49 73 6c 61 6e 64 22 2c 22 6e 61 74 69 76\n[16441] 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[16465] 22 3a 22 54 65 72 72 69 74 6f 72 79 20 6f 66 20 4e 6f 72 66 6f 6c 6b 20\n[16489] 49 73 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 66 6f 6c\n[16513] 6b 20 49 73 6c 61 6e 64 22 7d 2c 22 70 69 68 22 3a 7b 22 6f 66 66 69 63\n[16537] 69 61 6c 22 3a 22 54 65 72 61 74 72 69 20 6f 66 20 4e 6f 72 66 27 6b 20\n[16561] 41 69 6c 65 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 66 27 6b 20\n[16585] 41 69 6c 65 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n[16609] 6d 6f 6e 22 3a 22 42 6f 75 76 65 74 20 49 73 6c 61 6e 64 22 2c 22 6f 66\n[16633] 66 69 63 69 61 6c 22 3a 22 42 6f 75 76 65 74 20 49 73 6c 61 6e 64 22 2c\n[16657] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6e 6f 72 22 3a 7b 22 6f 66\n[16681] 66 69 63 69 61 6c 22 3a 22 42 6f 75 76 65 74 c3 b8 79 61 22 2c 22 63 6f\n[16705] 6d 6d 6f 6e 22 3a 22 42 6f 75 76 65 74 c3 b8 79 61 22 7d 7d 7d 7d 2c 7b\n[16729] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 51 61 74 61 72 22\n[16753] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 65 20 6f 66 20 51 61\n[16777] 74 61 72 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22\n[16801] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 af d9 88 d9 84 d8 a9 20 d9\n[16825] 82 d8 b7 d8 b1 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d9 82 d8 b7 d8 b1 22\n[16849] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[16873] 4d 61 64 61 67 61 73 63 61 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[16897] 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 61 64 61 67 61 73 63 61 72 22 2c\n[16921] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66\n[16945] 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 20\n[16969] 4d 61 64 61 67 61 73 63 61 72 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61\n[16993] 64 61 67 61 73 63 61 72 22 7d 2c 22 6d 6c 67 22 3a 7b 22 6f 66 66 69 63\n[17017] 69 61 6c 22 3a 22 52 65 70 6f 62 6c 69 6b 61 6e 27 69 20 4d 61 64 61 67\n[17041] 61 73 69 6b 61 72 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 64 61 67\n[17065] 61 73 69 6b 61 72 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[17089] 6f 6d 6d 6f 6e 22 3a 22 49 6e 64 69 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[17113] 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 49 6e 64 69 61 22 2c 22 6e\n[17137] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69\n[17161] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 49 6e 64 69 61\n[17185] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 49 6e 64 69 61 22 7d 2c 22 68 69 6e\n[17209] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0 a4 ad e0 a4 be e0 a4 b0\n[17233] e0 a4 a4 20 e0 a4 97 e0 a4 a3 e0 a4 b0 e0 a4 be e0 a4 9c e0 a5 8d e0 a4\n[17257] af 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 a4 ad e0 a4 be e0 a4 b0 e0 a4\n[17281] a4 22 7d 2c 22 74 61 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0\n[17305] ae 87 e0 ae a8 e0 af 8d e0 ae a4 e0 ae bf e0 ae af e0 ae 95 e0 af 8d 20\n[17329] e0 ae 95 e0 af 81 e0 ae 9f e0 ae bf e0 ae af e0 ae b0 e0 ae 9a e0 af 81\n[17353] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 ae 87 e0 ae a8 e0 af 8d e0 ae a4\n[17377] e0 ae bf e0 ae af e0 ae be 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[17401] 22 63 6f 6d 6d 6f 6e 22 3a 22 53 79 72 69 61 22 2c 22 6f 66 66 69 63 69\n[17425] 61 6c 22 3a 22 53 79 72 69 61 6e 20 41 72 61 62 20 52 65 70 75 62 6c 69\n[17449] 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b\n[17473] 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 ac d9 85 d9 87 d9 88\n[17497] d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 b9 d8 b1 d8 a8 d9 8a d8 a9 20 d8 a7\n[17521] d9 84 d8 b3 d9 88 d8 b1 d9 8a d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[17545] d8 b3 d9 88 d8 b1 d9 8a d8 a7 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[17569] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 6e 74 65 6e 65 67 72 6f 22 2c 22\n[17593] 6f 66 66 69 63 69 61 6c 22 3a 22 4d 6f 6e 74 65 6e 65 67 72 6f 22 2c 22\n[17617] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 63 6e 72 22 3a 7b 22 6f 66 66\n[17641] 69 63 69 61 6c 22 3a 22 d0 a6 d1 80 d0 bd d0 b0 20 d0 93 d0 be d1 80 d0\n[17665] b0 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a6 d1 80 d0 bd d0 b0 20 d0 93\n[17689] d0 be d1 80 d0 b0 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n[17713] 6d 6d 6f 6e 22 3a 22 45 73 77 61 74 69 6e 69 22 2c 22 6f 66 66 69 63 69\n[17737] 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 45 73 77 61 74 69 6e 69\n[17761] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22\n[17785] 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 45 73\n[17809] 77 61 74 69 6e 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 45 73 77 61 74 69\n[17833] 6e 69 22 7d 2c 22 73 73 77 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[17857] 55 6d 62 75 73 6f 20 77 65 53 77 61 74 69 6e 69 22 2c 22 63 6f 6d 6d 6f\n[17881] 6e 22 3a 22 65 53 77 61 74 69 6e 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[17905] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 72 61 67 75 61 79 22 2c 22\n[17929] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 50\n[17953] 61 72 61 67 75 61 79 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[17977] 67 72 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 65 74 c3 a3 20\n[18001] 50 61 72 61 67 75 c3 a1 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 72\n[18025] 61 67 75 c3 a1 69 22 7d 2c 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61\n[18049] 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 50 61 72 61 67 75\n[18073] 61 79 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 72 61 67 75 61 79 22 7d\n[18097] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 45\n[18121] 6c 20 53 61 6c 76 61 64 6f 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[18145] 52 65 70 75 62 6c 69 63 20 6f 66 20 45 6c 20 53 61 6c 76 61 64 6f 72 22\n[18169] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f\n[18193] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20\n[18217] 45 6c 20 53 61 6c 76 61 64 6f 72 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 45\n[18241] 6c 20 53 61 6c 76 61 64 6f 72 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[18265] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6b 72 61 69 6e 65 22 2c 22 6f 66 66\n[18289] 69 63 69 61 6c 22 3a 22 55 6b 72 61 69 6e 65 22 2c 22 6e 61 74 69 76 65\n[18313] 4e 61 6d 65 22 3a 7b 22 75 6b 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[18337] 3a 22 d0 a3 d0 ba d1 80 d0 b0 d1 97 d0 bd d0 b0 22 2c 22 63 6f 6d 6d 6f\n[18361] 6e 22 3a 22 d0 a3 d0 ba d1 80 d0 b0 d1 97 d0 bd d0 b0 22 7d 7d 7d 7d 2c\n[18385] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 49 73 6c 65 20\n[18409] 6f 66 20 4d 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 65\n[18433] 20 6f 66 20 4d 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[18457] 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 65 20 6f\n[18481] 66 20 4d 61 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 49 73 6c 65 20 6f 66\n[18505] 20 4d 61 6e 22 7d 2c 22 67 6c 76 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[18529] 3a 22 45 6c 6c 61 6e 20 56 61 6e 6e 69 6e 20 6f 72 20 4d 61 6e 6e 69 6e\n[18553] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 6e 6e 69 6e 22 7d 7d 7d 7d 2c\n[18577] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62\n[18601] 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63\n[18625] 20 6f 66 20 4e 61 6d 69 62 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[18649] 22 3a 7b 22 61 66 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[18673] 70 75 62 6c 69 65 6b 20 76 61 6e 20 4e 61 6d 69 62 69 c3 ab 22 2c 22 63\n[18697] 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69 c3 ab 22 7d 2c 22 64 65 75 22\n[18721] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 20 4e\n[18745] 61 6d 69 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69\n[18769] 61 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[18793] 65 70 75 62 6c 69 63 20 6f 66 20 4e 61 6d 69 62 69 61 22 2c 22 63 6f 6d\n[18817] 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69 61 22 7d 2c 22 68 65 72 22 3a 7b 22\n[18841] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4e\n[18865] 61 6d 69 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69\n[18889] 61 22 7d 2c 22 68 67 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[18913] 65 70 75 62 6c 69 63 20 6f 66 20 4e 61 6d 69 62 69 61 22 2c 22 63 6f 6d\n[18937] 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69 61 22 7d 2c 22 6b 77 6e 22 3a 7b 22\n[18961] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4e\n[18985] 61 6d 69 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69\n[19009] 61 22 7d 2c 22 6c 6f 7a 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[19033] 65 70 75 62 6c 69 63 20 6f 66 20 4e 61 6d 69 62 69 61 22 2c 22 63 6f 6d\n[19057] 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69 61 22 7d 2c 22 6e 64 6f 22 3a 7b 22\n[19081] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4e\n[19105] 61 6d 69 62 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69\n[19129] 61 22 7d 2c 22 74 73 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4c\n[19153] 65 66 61 74 73 68 65 20 6c 61 20 4e 61 6d 69 62 69 61 22 2c 22 63 6f 6d\n[19177] 6d 6f 6e 22 3a 22 4e 61 6d 69 62 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[19201] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6e 69 74 65 64 20 41 72 61\n[19225] 62 20 45 6d 69 72 61 74 65 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[19249] 55 6e 69 74 65 64 20 41 72 61 62 20 45 6d 69 72 61 74 65 73 22 2c 22 6e\n[19273] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69\n[19297] 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 a5 d9 85 d8 a7 d8 b1 d8 a7 d8 aa 20\n[19321] d8 a7 d9 84 d8 b9 d8 b1 d8 a8 d9 8a d8 a9 20 d8 a7 d9 84 d9 85 d8 aa d8\n[19345] ad d8 af d8 a9 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 af d9 88 d9 84 d8\n[19369] a9 20 d8 a7 d9 84 d8 a5 d9 85 d8 a7 d8 b1 d8 a7 d8 aa 20 d8 a7 d9 84 d8\n[19393] b9 d8 b1 d8 a8 d9 8a d8 a9 20 d8 a7 d9 84 d9 85 d8 aa d8 ad d8 af d8 a9\n[19417] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[19441] 22 42 75 6c 67 61 72 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[19465] 65 70 75 62 6c 69 63 20 6f 66 20 42 75 6c 67 61 72 69 61 22 2c 22 6e 61\n[19489] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 75 6c 22 3a 7b 22 6f 66 66 69 63\n[19513] 69 61 6c 22 3a 22 d0 a0 d0 b5 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0\n[19537] 20 d0 91 d1 8a d0 bb d0 b3 d0 b0 d1 80 d0 b8 d1 8f 22 2c 22 63 6f 6d 6d\n[19561] 6f 6e 22 3a 22 d0 91 d1 8a d0 bb d0 b3 d0 b0 d1 80 d0 b8 d1 8f 22 7d 7d\n[19585] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 72\n[19609] 65 65 6e 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 72 65\n[19633] 65 6e 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6b\n[19657] 61 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 61 6c 61 61 6c 6c\n[19681] 69 74 20 4e 75 6e 61 61 74 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b 61 6c\n[19705] 61 61 6c 6c 69 74 20 4e 75 6e 61 61 74 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[19729] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 65 72 6d 61 6e 79 22 2c 22\n[19753] 6f 66 66 69 63 69 61 6c 22 3a 22 46 65 64 65 72 61 6c 20 52 65 70 75 62\n[19777] 6c 69 63 20 6f 66 20 47 65 72 6d 61 6e 79 22 2c 22 6e 61 74 69 76 65 4e\n[19801] 61 6d 65 22 3a 7b 22 64 65 75 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[19825] 22 42 75 6e 64 65 73 72 65 70 75 62 6c 69 6b 20 44 65 75 74 73 63 68 6c\n[19849] 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 44 65 75 74 73 63 68 6c 61\n[19873] 6e 64 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[19897] 22 3a 22 43 61 6d 62 6f 64 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[19921] 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 43 61 6d 62 6f 64 69 61 22 2c 22 6e\n[19945] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6b 68 6d 22 3a 7b 22 6f 66 66 69\n[19969] 63 69 61 6c 22 3a 22 e1 9e 96 e1 9f 92 e1 9e 9a e1 9f 87 e1 9e 9a e1 9e\n[19993] b6 e1 9e 87 e1 9e b6 e1 9e 8e e1 9e b6 e1 9e 85 e1 9e 80 e1 9f 92 e1 9e\n[20017] 9a e1 9e 80 e1 9e 98 e1 9f 92 e1 9e 96 e1 9e bb e1 9e 87 e1 9e b6 22 2c\n[20041] 22 63 6f 6d 6d 6f 6e 22 3a 22 4b c3 a2 6d 70 c5 ad 63 68 c3 a9 61 22 7d\n[20065] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 49\n[20089] 72 61 71 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n[20113] 63 20 6f 66 20 49 72 61 71 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[20137] 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 ac d9 85\n[20161] d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 b9 d8 b1 d8 a7 d9 82 22\n[20185] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d8 b9 d8 b1 d8 a7 d9 82 22\n[20209] 7d 2c 22 61 72 63 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 dc a9 dc\n[20233] 98 dc bc dc 9b dc a2 dc b5 dc 90 20 dc 90 dc 9d dc bc dc aa dc b2 dc a9\n[20257] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 dc a9 dc 98 dc bc dc 9b dc a2 dc b5\n[20281] dc 90 22 7d 2c 22 63 6b 62 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[20305] da a9 db 86 d9 85 d8 a7 d8 b1 db 8c 20 d8 b9 db 8e d8 b1 d8 a7 d9 82 22\n[20329] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 da a9 db 86 d9 85 d8 a7 d8 b1 db 8c 22\n[20353] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[20377] 46 72 65 6e 63 68 20 53 6f 75 74 68 65 72 6e 20 61 6e 64 20 41 6e 74 61\n[20401] 72 63 74 69 63 20 4c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[20425] 22 54 65 72 72 69 74 6f 72 79 20 6f 66 20 74 68 65 20 46 72 65 6e 63 68\n[20449] 20 53 6f 75 74 68 65 72 6e 20 61 6e 64 20 41 6e 74 61 72 63 74 69 63 20\n[20473] 4c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72\n[20497] 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 65 72 72 69 74 6f 69\n[20521] 72 65 20 64 65 73 20 54 65 72 72 65 73 20 61 75 73 74 72 61 6c 65 73 20\n[20545] 65 74 20 61 6e 74 61 72 63 74 69 71 75 65 73 20 66 72 61 6e c3 a7 61 69\n[20569] 73 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 65 72 72 65 73 20 61 75\n[20593] 73 74 72 61 6c 65 73 20 65 74 20 61 6e 74 61 72 63 74 69 71 75 65 73 20\n[20617] 66 72 61 6e c3 a7 61 69 73 65 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[20641] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 77 65 64 65 6e 22 2c 22 6f 66 66\n[20665] 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 53 77 65 64 65\n[20689] 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 77 65 22 3a 7b\n[20713] 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 6f 6e 75 6e 67 61 72 69 6b 65 74\n[20737] 20 53 76 65 72 69 67 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 76 65 72\n[20761] 69 67 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[20785] 6e 22 3a 22 43 75 62 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[20809] 70 75 62 6c 69 63 20 6f 66 20 43 75 62 61 22 2c 22 6e 61 74 69 76 65 4e\n[20833] 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[20857] 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 43 75 62 61 22 2c 22 63 6f\n[20881] 6d 6d 6f 6e 22 3a 22 43 75 62 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[20905] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4b 79 72 67 79 7a 73 74 61 6e 22 2c\n[20929] 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 79 72 67 79 7a 20 52 65 70 75 62\n[20953] 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6b 69 72 22\n[20977] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d0 9a d1 8b d1 80 d0 b3 d1 8b\n[21001] d0 b7 20 d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 d1\n[21025] 81 d1 8b 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 9a d1 8b d1 80 d0 b3 d1\n[21049] 8b d0 b7 d1 81 d1 82 d0 b0 d0 bd 22 7d 2c 22 72 75 73 22 3a 7b 22 6f 66\n[21073] 66 69 63 69 61 6c 22 3a 22 d0 9a d1 8b d1 80 d0 b3 d1 8b d0 b7 d1 81 d0\n[21097] ba d0 b0 d1 8f 20 d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba\n[21121] d0 b0 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 9a d0 b8 d1 80 d0 b3 d0 b8\n[21145] d0 b7 d0 b8 d1 8f 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n[21169] 6d 6d 6f 6e 22 3a 22 52 75 73 73 69 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[21193] 22 3a 22 52 75 73 73 69 61 6e 20 46 65 64 65 72 61 74 69 6f 6e 22 2c 22\n[21217] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 72 75 73 22 3a 7b 22 6f 66 66\n[21241] 69 63 69 61 6c 22 3a 22 d0 a0 d0 be d1 81 d1 81 d0 b8 d0 b9 d1 81 d0 ba\n[21265] d0 b0 d1 8f 20 d0 a4 d0 b5 d0 b4 d0 b5 d1 80 d0 b0 d1 86 d0 b8 d1 8f 22\n[21289] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a0 d0 be d1 81 d1 81 d0 b8 d1 8f 22\n[21313] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[21337] 4d 61 6c 61 79 73 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 61\n[21361] 6c 61 79 73 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65\n[21385] 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 61 6c 61 79 73 69\n[21409] 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 6c 61 79 73 69 61 22 7d 2c\n[21433] 22 6d 73 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d9 85 d9 84 d9\n[21457] 8a d8 b3 d9 8a d8 a7 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d9 85 d9 84 d9\n[21481] 8a d8 b3 d9 8a d8 a7 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[21505] 6f 6d 6d 6f 6e 22 3a 22 53 c3 a3 6f 20 54 6f 6d c3 a9 20 61 6e 64 20 50\n[21529] 72 c3 ad 6e 63 69 70 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 44 65\n[21553] 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62 6c 69 63 20 6f 66 20 53 c3 a3\n[21577] 6f 20 54 6f 6d c3 a9 20 61 6e 64 20 50 72 c3 ad 6e 63 69 70 65 22 2c 22\n[21601] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66\n[21625] 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 44 65 6d 6f 63\n[21649] 72 c3 a1 74 69 63 61 20 64 6f 20 53 c3 a3 6f 20 54 6f 6d c3 a9 20 65 20\n[21673] 50 72 c3 ad 6e 63 69 70 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 c3 a3\n[21697] 6f 20 54 6f 6d c3 a9 20 65 20 50 72 c3 ad 6e 63 69 70 65 22 7d 7d 7d 7d\n[21721] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 79 70 72\n[21745] 75 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63\n[21769] 20 6f 66 20 43 79 70 72 75 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[21793] 3a 7b 22 65 6c 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 ce 94 ce\n[21817] b7 ce bc ce bf ce ba cf 81 ce b1 cf 84 ce af ce b1 20 cf 84 ce b7 cf 82\n[21841] 20 ce 9a cf 8d cf 80 cf 81 ce bf cf 82 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[21865] 22 ce 9a cf 8d cf 80 cf 81 ce bf cf 82 22 7d 2c 22 74 75 72 22 3a 7b 22\n[21889] 6f 66 66 69 63 69 61 6c 22 3a 22 4b c4 b1 62 72 c4 b1 73 20 43 75 6d 68\n[21913] 75 72 69 79 65 74 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b c4 b1 62 72\n[21937] c4 b1 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[21961] 6e 22 3a 22 43 61 6e 61 64 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[21985] 43 61 6e 61 64 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65\n[22009] 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 61 6e 61 64 61 22\n[22033] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 61 6e 61 64 61 22 7d 2c 22 66 72 61\n[22057] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 61 6e 61 64 61 22 2c 22\n[22081] 63 6f 6d 6d 6f 6e 22 3a 22 43 61 6e 61 64 61 22 7d 7d 7d 7d 2c 7b 22 6e\n[22105] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 6c 61 77 69 22 2c\n[22129] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20\n[22153] 4d 61 6c 61 77 69 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65\n[22177] 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n[22201] 63 20 6f 66 20 4d 61 6c 61 77 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d\n[22225] 61 6c 61 77 69 22 7d 2c 22 6e 79 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[22249] 22 3a 22 43 68 61 6c 6f 20 63 68 61 20 4d 61 6c 61 77 69 2c 20 44 7a 69\n[22273] 6b 6f 20 6c 61 20 4d 61 6c 61 c5 b5 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[22297] 22 4d 61 6c 61 c5 b5 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[22321] 63 6f 6d 6d 6f 6e 22 3a 22 53 61 75 64 69 20 41 72 61 62 69 61 22 2c 22\n[22345] 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 53 61\n[22369] 75 64 69 20 41 72 61 62 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[22393] 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9\n[22417] 84 d9 85 d9 85 d9 84 d9 83 d8 a9 20 d8 a7 d9 84 d8 b9 d8 b1 d8 a8 d9 8a\n[22441] d8 a9 20 d8 a7 d9 84 d8 b3 d8 b9 d9 88 d8 af d9 8a d8 a9 22 2c 22 63 6f\n[22465] 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d8 b9 d8 b1 d8 a8 d9 8a d8 a9 20 d8 a7\n[22489] d9 84 d8 b3 d8 b9 d9 88 d8 af d9 8a d8 a9 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[22513] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 73 6e 69 61 20 61 6e\n[22537] 64 20 48 65 72 7a 65 67 6f 76 69 6e 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[22561] 22 3a 22 42 6f 73 6e 69 61 20 61 6e 64 20 48 65 72 7a 65 67 6f 76 69 6e\n[22585] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 6f 73 22 3a 7b\n[22609] 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 6f 73 6e 61 20 69 20 48 65 72 63\n[22633] 65 67 6f 76 69 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 73 6e 61\n[22657] 20 69 20 48 65 72 63 65 67 6f 76 69 6e 61 22 7d 2c 22 68 72 76 22 3a 7b\n[22681] 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 6f 73 6e 61 20 69 20 48 65 72 63\n[22705] 65 67 6f 76 69 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 73 6e 61\n[22729] 20 69 20 48 65 72 63 65 67 6f 76 69 6e 61 22 7d 2c 22 73 72 70 22 3a 7b\n[22753] 22 6f 66 66 69 63 69 61 6c 22 3a 22 d0 91 d0 be d1 81 d0 bd d0 b0 20 d0\n[22777] b8 20 d0 a5 d0 b5 d1 80 d1 86 d0 b5 d0 b3 d0 be d0 b2 d0 b8 d0 bd d0 b0\n[22801] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 91 d0 be d1 81 d0 bd d0 b0 20 d0\n[22825] b8 20 d0 a5 d0 b5 d1 80 d1 86 d0 b5 d0 b3 d0 be d0 b2 d0 b8 d0 bd d0 b0\n[22849] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[22873] 22 45 74 68 69 6f 70 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 46\n[22897] 65 64 65 72 61 6c 20 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62 6c\n[22921] 69 63 20 6f 66 20 45 74 68 69 6f 70 69 61 22 2c 22 6e 61 74 69 76 65 4e\n[22945] 61 6d 65 22 3a 7b 22 61 6d 68 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[22969] 22 e1 8b a8 e1 8a a2 e1 89 b5 e1 8b ae e1 8c b5 e1 8b ab 20 e1 8d 8c e1\n[22993] 8b b4 e1 88 ab e1 88 8b e1 8b 8a 20 e1 8b b2 e1 88 9e e1 8a ad e1 88 ab\n[23017] e1 88 b2 e1 8b ab e1 8b 8a 20 e1 88 aa e1 8d 90 e1 89 a5 e1 88 8a e1 8a\n[23041] ad 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e1 8a a2 e1 89 b5 e1 8b ae e1 8c\n[23065] b5 e1 8b ab 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[23089] 6f 6e 22 3a 22 53 70 61 69 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[23113] 4b 69 6e 67 64 6f 6d 20 6f 66 20 53 70 61 69 6e 22 2c 22 6e 61 74 69 76\n[23137] 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[23161] 22 3a 22 52 65 69 6e 6f 20 64 65 20 45 73 70 61 c3 b1 61 22 2c 22 63 6f\n[23185] 6d 6d 6f 6e 22 3a 22 45 73 70 61 c3 b1 61 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[23209] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6c 6f 76 65 6e 69 61 22\n[23233] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n[23257] 20 53 6c 6f 76 65 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[23281] 7b 22 73 6c 76 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n[23305] 62 6c 69 6b 61 20 53 6c 6f 76 65 6e 69 6a 61 22 2c 22 63 6f 6d 6d 6f 6e\n[23329] 22 3a 22 53 6c 6f 76 65 6e 69 6a 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[23353] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4f 6d 61 6e 22 2c 22 6f 66 66 69\n[23377] 63 69 61 6c 22 3a 22 53 75 6c 74 61 6e 61 74 65 20 6f 66 20 4f 6d 61 6e\n[23401] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22\n[23425] 6f 66 66 69 63 69 61 6c 22 3a 22 d8 b3 d9 84 d8 b7 d9 86 d8 a9 20 d8 b9\n[23449] d9 85 d8 a7 d9 86 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 b9 d9 85 d8 a7\n[23473] d9 86 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[23497] 22 3a 22 53 61 69 6e 74 20 50 69 65 72 72 65 20 61 6e 64 20 4d 69 71 75\n[23521] 65 6c 6f 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69 6e 74 20\n[23545] 50 69 65 72 72 65 20 61 6e 64 20 4d 69 71 75 65 6c 6f 6e 22 2c 22 6e 61\n[23569] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63\n[23593] 69 61 6c 22 3a 22 43 6f 6c 6c 65 63 74 69 76 69 74 c3 a9 20 74 65 72 72\n[23617] 69 74 6f 72 69 61 6c 65 20 64 65 20 53 61 69 6e 74 2d 50 69 65 72 72 65\n[23641] 2d 65 74 2d 4d 69 71 75 65 6c 6f 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[23665] 53 61 69 6e 74 2d 50 69 65 72 72 65 2d 65 74 2d 4d 69 71 75 65 6c 6f 6e\n[23689] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[23713] 22 4d 61 63 61 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 61 63 61\n[23737] 6f 20 53 70 65 63 69 61 6c 20 41 64 6d 69 6e 69 73 74 72 61 74 69 76 65\n[23761] 20 52 65 67 69 6f 6e 20 6f 66 20 74 68 65 20 50 65 6f 70 6c 65 27 73 20\n[23785] 52 65 70 75 62 6c 69 63 20 6f 66 20 43 68 69 6e 61 22 2c 22 6e 61 74 69\n[23809] 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61\n[23833] 6c 22 3a 22 52 65 67 69 c3 a3 6f 20 41 64 6d 69 6e 69 73 74 72 61 74 69\n[23857] 76 61 20 45 73 70 65 63 69 61 6c 20 64 65 20 4d 61 63 61 75 20 64 61 20\n[23881] 52 65 70 c3 ba 62 6c 69 63 61 20 50 6f 70 75 6c 61 72 20 64 61 20 43 68\n[23905] 69 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 63 61 75 22 7d 2c 22\n[23929] 7a 68 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e4 b8 ad e5 8d 8e\n[23953] e4 ba ba e6 b0 91 e5 85 b1 e5 92 8c e5 9b bd e6 be b3 e9 97 a8 e7 89 b9\n[23977] e5 88 ab e8 a1 8c e6 94 bf e5 8c ba 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[24001] e6 be b3 e9 97 a8 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n[24025] 6d 6d 6f 6e 22 3a 22 53 61 6e 20 4d 61 72 69 6e 6f 22 2c 22 6f 66 66 69\n[24049] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 53 61 6e 20 4d\n[24073] 61 72 69 6e 6f 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 69 74\n[24097] 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 62 6c 69\n[24121] 63 61 20 64 69 20 53 61 6e 20 4d 61 72 69 6e 6f 22 2c 22 63 6f 6d 6d 6f\n[24145] 6e 22 3a 22 53 61 6e 20 4d 61 72 69 6e 6f 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[24169] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 65 73 6f 74 68 6f 22 2c\n[24193] 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 4c\n[24217] 65 73 6f 74 68 6f 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65\n[24241] 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d\n[24265] 20 6f 66 20 4c 65 73 6f 74 68 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4c\n[24289] 65 73 6f 74 68 6f 22 7d 2c 22 73 6f 74 22 3a 7b 22 6f 66 66 69 63 69 61\n[24313] 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 4c 65 73 6f 74 68 6f 22 2c\n[24337] 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 65 73 6f 74 68 6f 22 7d 7d 7d 7d 2c 7b\n[24361] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 72 73 68 61\n[24385] 6c 6c 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[24409] 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 4d 61 72 73 68 61 6c 6c\n[24433] 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[24457] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[24481] 6c 69 63 20 6f 66 20 74 68 65 20 4d 61 72 73 68 61 6c 6c 20 49 73 6c 61\n[24505] 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 72 73 68 61 6c 6c 20\n[24529] 49 73 6c 61 6e 64 73 22 7d 2c 22 6d 61 68 22 3a 7b 22 6f 66 66 69 63 69\n[24553] 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 4d 61 72\n[24577] 73 68 61 6c 6c 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[24601] 22 4d cc a7 61 6a 65 c4 bc 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[24625] 22 63 6f 6d 6d 6f 6e 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e 22 2c\n[24649] 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e\n[24673] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22\n[24697] 6f 66 66 69 63 69 61 6c 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e 22\n[24721] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e 22\n[24745] 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69\n[24769] 6e 74 2d 4d 61 72 74 69 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69\n[24793] 6e 74 2d 4d 61 72 74 69 6e 22 7d 2c 22 6e 6c 64 22 3a 7b 22 6f 66 66 69\n[24817] 63 69 61 6c 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e 22 2c 22 63 6f\n[24841] 6d 6d 6f 6e 22 3a 22 53 69 6e 74 20 4d 61 61 72 74 65 6e 22 7d 7d 7d 7d\n[24865] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 49 63 65 6c\n[24889] 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 63 65 6c 61 6e 64\n[24913] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 69 73 6c 22 3a 7b 22\n[24937] 6f 66 66 69 63 69 61 6c 22 3a 22 c3 8d 73 6c 61 6e 64 22 2c 22 63 6f 6d\n[24961] 6d 6f 6e 22 3a 22 c3 8d 73 6c 61 6e 64 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[24985] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 75 78 65 6d 62 6f 75 72 67\n[25009] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 72 61 6e 64 20 44 75 63 68\n[25033] 79 20 6f 66 20 4c 75 78 65 6d 62 6f 75 72 67 22 2c 22 6e 61 74 69 76 65\n[25057] 4e 61 6d 65 22 3a 7b 22 64 65 75 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[25081] 3a 22 47 72 6f c3 9f 68 65 72 7a 6f 67 74 75 6d 20 4c 75 78 65 6d 62 75\n[25105] 72 67 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 75 78 65 6d 62 75 72 67 22\n[25129] 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 72 61\n[25153] 6e 64 2d 44 75 63 68 c3 a9 20 64 65 20 4c 75 78 65 6d 62 6f 75 72 67 22\n[25177] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 75 78 65 6d 62 6f 75 72 67 22 7d 2c\n[25201] 22 6c 74 7a 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 72 6f 75 73\n[25225] 73 68 65 72 7a 6f 67 74 75 6d 20 4c c3 ab 74 7a 65 62 75 65 72 67 22 2c\n[25249] 22 63 6f 6d 6d 6f 6e 22 3a 22 4c c3 ab 74 7a 65 62 75 65 72 67 22 7d 7d\n[25273] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 72\n[25297] 67 65 6e 74 69 6e 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 72 67\n[25321] 65 6e 74 69 6e 65 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65\n[25345] 4e 61 6d 65 22 3a 7b 22 67 72 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[25369] 3a 22 41 72 67 65 6e 74 69 6e 65 20 52 65 70 75 62 6c 69 63 22 2c 22 63\n[25393] 6f 6d 6d 6f 6e 22 3a 22 41 72 67 65 6e 74 69 6e 61 22 7d 2c 22 73 70 61\n[25417] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63\n[25441] 61 20 41 72 67 65 6e 74 69 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41\n[25465] 72 67 65 6e 74 69 6e 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[25489] 63 6f 6d 6d 6f 6e 22 3a 22 54 75 72 6b 73 20 61 6e 64 20 43 61 69 63 6f\n[25513] 73 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54\n[25537] 75 72 6b 73 20 61 6e 64 20 43 61 69 63 6f 73 20 49 73 6c 61 6e 64 73 22\n[25561] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f\n[25585] 66 66 69 63 69 61 6c 22 3a 22 54 75 72 6b 73 20 61 6e 64 20 43 61 69 63\n[25609] 6f 73 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 75\n[25633] 72 6b 73 20 61 6e 64 20 43 61 69 63 6f 73 20 49 73 6c 61 6e 64 73 22 7d\n[25657] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e\n[25681] 61 75 72 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[25705] 69 63 20 6f 66 20 4e 61 75 72 75 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[25729] 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[25753] 70 75 62 6c 69 63 20 6f 66 20 4e 61 75 72 75 22 2c 22 63 6f 6d 6d 6f 6e\n[25777] 22 3a 22 4e 61 75 72 75 22 7d 2c 22 6e 61 75 22 3a 7b 22 6f 66 66 69 63\n[25801] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4e 61 75 72 75 22\n[25825] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 61 75 72 75 22 7d 7d 7d 7d 2c 7b 22\n[25849] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 63 6f 73 20 28\n[25873] 4b 65 65 6c 69 6e 67 29 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63\n[25897] 69 61 6c 22 3a 22 54 65 72 72 69 74 6f 72 79 20 6f 66 20 74 68 65 20 43\n[25921] 6f 63 6f 73 20 28 4b 65 65 6c 69 6e 67 29 20 49 73 6c 61 6e 64 73 22 2c\n[25945] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[25969] 66 69 63 69 61 6c 22 3a 22 54 65 72 72 69 74 6f 72 79 20 6f 66 20 74 68\n[25993] 65 20 43 6f 63 6f 73 20 28 4b 65 65 6c 69 6e 67 29 20 49 73 6c 61 6e 64\n[26017] 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 63 6f 73 20 28 4b 65 65 6c\n[26041] 69 6e 67 29 20 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[26065] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 57 65 73 74 65 72 6e 20 53 61 68\n[26089] 61 72 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 68 72 61 77 69\n[26113] 20 41 72 61 62 20 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62 6c 69\n[26137] 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 65 72 22 3a 7b\n[26161] 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 68 72 61 77 69 20 41 72 61 62\n[26185] 20 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62 6c 69 63 22 2c 22 63\n[26209] 6f 6d 6d 6f 6e 22 3a 22 57 65 73 74 65 72 6e 20 53 61 68 61 72 61 22 7d\n[26233] 2c 22 6d 65 79 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84\n[26257] d8 ac d9 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 b9 d8 b1 d8\n[26281] a8 d9 8a d8 a9 20 d8 a7 d9 84 d8 b5 d8 ad d8 b1 d8 a7 d9 88 d9 8a d8 a9\n[26305] 20 d8 a7 d9 84 d8 af d9 8a d9 85 d9 82 d8 b1 d8 a7 d8 b7 d9 8a d8 a9 22\n[26329] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d8 b5 d8 ad d8 b1 d8 a7 d8\n[26353] a1 20 d8 a7 d9 84 d8 ba d8 b1 d8 a8 d9 8a d8 a9 22 7d 2c 22 73 70 61 22\n[26377] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61\n[26401] 20 c3 81 72 61 62 65 20 53 61 68 61 72 61 75 69 20 44 65 6d 6f 63 72 c3\n[26425] a1 74 69 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 68 61 72 61 20\n[26449] 4f 63 63 69 64 65 6e 74 61 6c 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[26473] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 44 6f 6d 69 6e 69 63 61 22 2c 22 6f 66\n[26497] 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66\n[26521] 20 44 6f 6d 69 6e 69 63 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[26545] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d\n[26569] 6f 6e 77 65 61 6c 74 68 20 6f 66 20 44 6f 6d 69 6e 69 63 61 22 2c 22 63\n[26593] 6f 6d 6d 6f 6e 22 3a 22 44 6f 6d 69 6e 69 63 61 22 7d 7d 7d 7d 2c 7b 22\n[26617] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 73 74 61 20 52\n[26641] 69 63 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n[26665] 63 20 6f 66 20 43 6f 73 74 61 20 52 69 63 61 22 2c 22 6e 61 74 69 76 65\n[26689] 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[26713] 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 43 6f 73 74 61 20 52 69\n[26737] 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 73 74 61 20 52 69 63 61\n[26761] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[26785] 22 41 75 73 74 72 61 6c 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[26809] 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66 20 41 75 73 74 72 61 6c 69\n[26833] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b\n[26857] 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68\n[26881] 20 6f 66 20 41 75 73 74 72 61 6c 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[26905] 22 41 75 73 74 72 61 6c 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[26929] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 54 68 61 69 6c 61 6e 64 22 2c 22 6f 66\n[26953] 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 54 68 61 69\n[26977] 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 74 68 61\n[27001] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e0 b8 a3 e0 b8 b2 e0 b8 8a\n[27025] e0 b8 ad e0 b8 b2 e0 b8 93 e0 b8 b2 e0 b8 88 e0 b8 b1 e0 b8 81 e0 b8 a3\n[27049] e0 b9 84 e0 b8 97 e0 b8 a2 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e0 b8 9b\n[27073] e0 b8 a3 e0 b8 b0 e0 b9 80 e0 b8 97 e0 b8 a8 e0 b9 84 e0 b8 97 e0 b8 a2\n[27097] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[27121] 22 48 61 69 74 69 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n[27145] 62 6c 69 63 20 6f 66 20 48 61 69 74 69 22 2c 22 6e 61 74 69 76 65 4e 61\n[27169] 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[27193] 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 27 48 61 c3 af 74 69 22 2c 22 63\n[27217] 6f 6d 6d 6f 6e 22 3a 22 48 61 c3 af 74 69 22 7d 2c 22 68 61 74 22 3a 7b\n[27241] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 69 62 6c 69 6b 20 41 79 69\n[27265] 74 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 79 69 74 69 22 7d 7d 7d 7d\n[27289] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 54 75 76 61\n[27313] 6c 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 75 76 61 6c 75 22 2c\n[27337] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[27361] 66 69 63 69 61 6c 22 3a 22 54 75 76 61 6c 75 22 2c 22 63 6f 6d 6d 6f 6e\n[27385] 22 3a 22 54 75 76 61 6c 75 22 7d 2c 22 74 76 6c 22 3a 7b 22 6f 66 66 69\n[27409] 63 69 61 6c 22 3a 22 54 75 76 61 6c 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[27433] 22 54 75 76 61 6c 75 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[27457] 6f 6d 6d 6f 6e 22 3a 22 48 6f 6e 64 75 72 61 73 22 2c 22 6f 66 66 69 63\n[27481] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 48 6f 6e 64 75 72\n[27505] 61 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a\n[27529] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20\n[27553] 64 65 20 48 6f 6e 64 75 72 61 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 48\n[27577] 6f 6e 64 75 72 61 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[27601] 6f 6d 6d 6f 6e 22 3a 22 45 71 75 61 74 6f 72 69 61 6c 20 47 75 69 6e 65\n[27625] 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20\n[27649] 6f 66 20 45 71 75 61 74 6f 72 69 61 6c 20 47 75 69 6e 65 61 22 2c 22 6e\n[27673] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69\n[27697] 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 20 6c 61\n[27721] 20 47 75 69 6e c3 a9 65 20 c3 89 71 75 61 74 6f 72 69 61 6c 65 22 2c 22\n[27745] 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69 6e c3 a9 65 20 c3 a9 71 75 61 74 6f\n[27769] 72 69 61 6c 65 22 7d 2c 22 70 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[27793] 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 61 20 47 75 69 6e c3 a9 20\n[27817] 45 71 75 61 74 6f 72 69 61 6c 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75\n[27841] 69 6e c3 a9 20 45 71 75 61 74 6f 72 69 61 6c 22 7d 2c 22 73 70 61 22 3a\n[27865] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20\n[27889] 64 65 20 47 75 69 6e 65 61 20 45 63 75 61 74 6f 72 69 61 6c 22 2c 22 63\n[27913] 6f 6d 6d 6f 6e 22 3a 22 47 75 69 6e 65 61 20 45 63 75 61 74 6f 72 69 61\n[27937] 6c 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n[27961] 3a 22 53 61 69 6e 74 20 4c 75 63 69 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[27985] 22 3a 22 53 61 69 6e 74 20 4c 75 63 69 61 22 2c 22 6e 61 74 69 76 65 4e\n[28009] 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[28033] 22 53 61 69 6e 74 20 4c 75 63 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[28057] 53 61 69 6e 74 20 4c 75 63 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[28081] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 46 72 65 6e 63 68 20 50 6f 6c 79 6e\n[28105] 65 73 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 72 65 6e 63 68\n[28129] 20 50 6f 6c 79 6e 65 73 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[28153] 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 6f 6c\n[28177] 79 6e c3 a9 73 69 65 20 66 72 61 6e c3 a7 61 69 73 65 22 2c 22 63 6f 6d\n[28201] 6d 6f 6e 22 3a 22 50 6f 6c 79 6e c3 a9 73 69 65 20 66 72 61 6e c3 a7 61\n[28225] 69 73 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[28249] 6e 22 3a 22 42 65 6c 61 72 75 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[28273] 22 52 65 70 75 62 6c 69 63 20 6f 66 20 42 65 6c 61 72 75 73 22 2c 22 6e\n[28297] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 65 6c 22 3a 7b 22 6f 66 66 69\n[28321] 63 69 61 6c 22 3a 22 d0 a0 d1 8d d1 81 d0 bf d1 83 d0 b1 d0 bb d1 96 d0\n[28345] ba d0 b0 20 d0 91 d0 b5 d0 bb d0 b0 d1 80 d1 83 d1 81 d1 8c 22 2c 22 63\n[28369] 6f 6d 6d 6f 6e 22 3a 22 d0 91 d0 b5 d0 bb d0 b0 d1 80 d1 83 cc 81 d1 81\n[28393] d1 8c 22 7d 2c 22 72 75 73 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[28417] d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 20 d0 91 d0\n[28441] b5 d0 bb d0 b0 d1 80 d1 83 d1 81 d1 8c 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[28465] 22 d0 91 d0 b5 d0 bb d0 b0 d1 80 d1 83 d1 81 d1 8c 22 7d 7d 7d 7d 2c 7b\n[28489] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 61 74 76 69 61\n[28513] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[28537] 66 20 4c 61 74 76 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[28561] 22 6c 61 76 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4c 61 74 76 69\n[28585] 6a 61 73 20 52 65 70 75 62 6c 69 6b 61 73 22 2c 22 63 6f 6d 6d 6f 6e 22\n[28609] 3a 22 4c 61 74 76 69 6a 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[28633] 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6c 61 75 22 2c 22 6f 66 66 69 63 69\n[28657] 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 50 61 6c 61 75 22 2c\n[28681] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[28705] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 50 61 6c\n[28729] 61 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6c 61 75 22 7d 2c 22 70\n[28753] 61 75 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 65 6c 75 75 20 65\n[28777] 72 20 61 20 42 65 6c 61 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c\n[28801] 61 75 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[28825] 22 3a 22 47 75 61 64 65 6c 6f 75 70 65 22 2c 22 6f 66 66 69 63 69 61 6c\n[28849] 22 3a 22 47 75 61 64 65 6c 6f 75 70 65 22 2c 22 6e 61 74 69 76 65 4e 61\n[28873] 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[28897] 47 75 61 64 65 6c 6f 75 70 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75\n[28921] 61 64 65 6c 6f 75 70 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[28945] 63 6f 6d 6d 6f 6e 22 3a 22 50 68 69 6c 69 70 70 69 6e 65 73 22 2c 22 6f\n[28969] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68\n[28993] 65 20 50 68 69 6c 69 70 70 69 6e 65 73 22 2c 22 6e 61 74 69 76 65 4e 61\n[29017] 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[29041] 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 50 68 69 6c 69 70 70 69\n[29065] 6e 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 68 69 6c 69 70 70 69 6e\n[29089] 65 73 22 7d 2c 22 66 69 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[29113] 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 50 68 69 6c 69 70 70 69\n[29137] 6e 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 69 6c 69 70 69 6e 61 73\n[29161] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[29185] 22 47 69 62 72 61 6c 74 61 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[29209] 47 69 62 72 61 6c 74 61 72 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[29233] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 69 62 72\n[29257] 61 6c 74 61 72 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 69 62 72 61 6c 74\n[29281] 61 72 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[29305] 22 3a 22 44 65 6e 6d 61 72 6b 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[29329] 4b 69 6e 67 64 6f 6d 20 6f 66 20 44 65 6e 6d 61 72 6b 22 2c 22 6e 61 74\n[29353] 69 76 65 4e 61 6d 65 22 3a 7b 22 64 61 6e 22 3a 7b 22 6f 66 66 69 63 69\n[29377] 61 6c 22 3a 22 4b 6f 6e 67 65 72 69 67 65 74 20 44 61 6e 6d 61 72 6b 22\n[29401] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 44 61 6e 6d 61 72 6b 22 7d 7d 7d 7d 2c\n[29425] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 61 6d 65 72\n[29449] 6f 6f 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69\n[29473] 63 20 6f 66 20 43 61 6d 65 72 6f 6f 6e 22 2c 22 6e 61 74 69 76 65 4e 61\n[29497] 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[29521] 52 65 70 75 62 6c 69 63 20 6f 66 20 43 61 6d 65 72 6f 6f 6e 22 2c 22 63\n[29545] 6f 6d 6d 6f 6e 22 3a 22 43 61 6d 65 72 6f 6f 6e 22 7d 2c 22 66 72 61 22\n[29569] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75\n[29593] 65 20 64 75 20 43 61 6d 65 72 6f 75 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[29617] 22 43 61 6d 65 72 6f 75 6e 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[29641] 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69 6e 65 61 22 2c 22 6f 66 66 69 63\n[29665] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 47 75 69 6e 65 61\n[29689] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22\n[29713] 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64\n[29737] 65 20 47 75 69 6e c3 a9 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 69\n[29761] 6e c3 a9 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[29785] 6f 6e 22 3a 22 42 61 68 72 61 69 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[29809] 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 42 61 68 72 61 69 6e 22 2c 22 6e\n[29833] 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69\n[29857] 63 69 61 6c 22 3a 22 d9 85 d9 85 d9 84 d9 83 d8 a9 20 d8 a7 d9 84 d8 a8\n[29881] d8 ad d8 b1 d9 8a d9 86 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e2 80 8f d8\n[29905] a7 d9 84 d8 a8 d8 ad d8 b1 d9 8a d9 86 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[29929] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 75 72 69 6e 61 6d 65 22 2c\n[29953] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20\n[29977] 53 75 72 69 6e 61 6d 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[30001] 22 6e 6c 64 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[30025] 6c 69 65 6b 20 53 75 72 69 6e 61 6d 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[30049] 22 53 75 72 69 6e 61 6d 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[30073] 22 63 6f 6d 6d 6f 6e 22 3a 22 44 52 20 43 6f 6e 67 6f 22 2c 22 6f 66 66\n[30097] 69 63 69 61 6c 22 3a 22 44 65 6d 6f 63 72 61 74 69 63 20 52 65 70 75 62\n[30121] 6c 69 63 20 6f 66 20 74 68 65 20 43 6f 6e 67 6f 22 2c 22 6e 61 74 69 76\n[30145] 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[30169] 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 c3 a9 6d 6f 63 72 61 74\n[30193] 69 71 75 65 20 64 75 20 43 6f 6e 67 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[30217] 22 52 44 20 43 6f 6e 67 6f 22 7d 2c 22 6b 6f 6e 22 3a 7b 22 6f 66 66 69\n[30241] 63 69 61 6c 22 3a 22 52 65 70 75 62 69 6c 69 6b 61 20 79 61 20 4b 6f 6e\n[30265] 67 6f 20 44 65 6d 6f 6b 72 61 74 69 6b 69 22 2c 22 63 6f 6d 6d 6f 6e 22\n[30289] 3a 22 52 65 70 75 62 69 6c 69 6b 61 20 79 61 20 4b 6f 6e 67 6f 20 44 65\n[30313] 6d 6f 6b 72 61 74 69 6b 69 22 7d 2c 22 6c 69 6e 22 3a 7b 22 6f 66 66 69\n[30337] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 69 20 79 61 20 4b 6f 6e 67\n[30361] c3 b3 20 44 65 6d 6f 6b 72 61 74 69 6b 69 22 2c 22 63 6f 6d 6d 6f 6e 22\n[30385] 3a 22 52 65 70 75 62 6c 69 6b 69 20 79 61 20 4b 6f 6e 67 c3 b3 20 44 65\n[30409] 6d 6f 6b 72 61 74 69 6b 69 22 7d 2c 22 6c 75 61 22 3a 7b 22 6f 66 66 69\n[30433] 63 69 61 6c 22 3a 22 44 69 74 75 6e 67 61 20 64 69 61 20 4b 6f 6e 67 75\n[30457] 20 77 61 20 4d 75 6e 67 61 6c 61 61 74 61 22 2c 22 63 6f 6d 6d 6f 6e 22\n[30481] 3a 22 44 69 74 75 6e 67 61 20 64 69 61 20 4b 6f 6e 67 75 20 77 61 20 4d\n[30505] 75 6e 67 61 6c 61 61 74 61 22 7d 2c 22 73 77 61 22 3a 7b 22 6f 66 66 69\n[30529] 63 69 61 6c 22 3a 22 4a 61 6d 68 75 72 69 20 79 61 20 4b 69 64 65 6d 6f\n[30553] 6b 72 61 73 69 61 20 79 61 20 4b 6f 6e 67 6f 22 2c 22 63 6f 6d 6d 6f 6e\n[30577] 22 3a 22 4a 61 6d 68 75 72 69 20 79 61 20 4b 69 64 65 6d 6f 6b 72 61 73\n[30601] 69 61 20 79 61 20 4b 6f 6e 67 6f 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[30625] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 6d 61 6c 69 61 22 2c 22 6f 66\n[30649] 66 69 63 69 61 6c 22 3a 22 46 65 64 65 72 61 6c 20 52 65 70 75 62 6c 69\n[30673] 63 20 6f 66 20 53 6f 6d 61 6c 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[30697] 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8\n[30721] ac d9 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 a7 d9 84 d8 b5 d9 88 d9 85\n[30745] d8 a7 d9 84 e2 80 8e e2 80 8e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7\n[30769] d9 84 d8 b5 d9 88 d9 85 d8 a7 d9 84 e2 80 8e e2 80 8e 22 7d 2c 22 73 6f\n[30793] 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4a 61 6d 68 75 75 72 69\n[30817] 79 61 64 64 61 20 46 65 64 65 72 61 61 6c 6b 61 20 53 6f 6f 6d 61 61 6c\n[30841] 69 79 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 6f 6d 61 61 6c 69 79\n[30865] 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n[30889] 3a 22 43 7a 65 63 68 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 43\n[30913] 7a 65 63 68 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61\n[30937] 6d 65 22 3a 7b 22 63 65 73 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[30961] c4 8c 65 73 6b c3 a1 20 72 65 70 75 62 6c 69 6b 61 22 2c 22 63 6f 6d 6d\n[30985] 6f 6e 22 3a 22 c4 8c 65 73 6b 6f 22 7d 2c 22 73 6c 6b 22 3a 7b 22 6f 66\n[31009] 66 69 63 69 61 6c 22 3a 22 c4 8c 65 73 6b c3 a1 20 72 65 70 75 62 6c 69\n[31033] 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 c4 8c 65 73 6b 6f 22 7d 7d 7d\n[31057] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 65 77\n[31081] 20 43 61 6c 65 64 6f 6e 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[31105] 4e 65 77 20 43 61 6c 65 64 6f 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61\n[31129] 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[31153] 4e 6f 75 76 65 6c 6c 65 2d 43 61 6c c3 a9 64 6f 6e 69 65 22 2c 22 63 6f\n[31177] 6d 6d 6f 6e 22 3a 22 4e 6f 75 76 65 6c 6c 65 2d 43 61 6c c3 a9 64 6f 6e\n[31201] 69 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[31225] 22 3a 22 56 61 6e 75 61 74 75 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[31249] 52 65 70 75 62 6c 69 63 20 6f 66 20 56 61 6e 75 61 74 75 22 2c 22 6e 61\n[31273] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 69 73 22 3a 7b 22 6f 66 66 69 63\n[31297] 69 61 6c 22 3a 22 52 69 70 61 62 6c 69 6b 20 62 6c 6f 6e 67 20 56 61 6e\n[31321] 75 61 74 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 56 61 6e 75 61 74 75 22\n[31345] 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70\n[31369] 75 62 6c 69 63 20 6f 66 20 56 61 6e 75 61 74 75 22 2c 22 63 6f 6d 6d 6f\n[31393] 6e 22 3a 22 56 61 6e 75 61 74 75 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66\n[31417] 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 20\n[31441] 56 61 6e 75 61 74 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 56 61 6e 75 61\n[31465] 74 75 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[31489] 22 3a 22 53 61 69 6e 74 20 48 65 6c 65 6e 61 2c 20 41 73 63 65 6e 73 69\n[31513] 6f 6e 20 61 6e 64 20 54 72 69 73 74 61 6e 20 64 61 20 43 75 6e 68 61 22\n[31537] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69 6e 74 20 48 65 6c 65 6e\n[31561] 61 2c 20 41 73 63 65 6e 73 69 6f 6e 20 61 6e 64 20 54 72 69 73 74 61 6e\n[31585] 20 64 61 20 43 75 6e 68 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[31609] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69 6e\n[31633] 74 20 48 65 6c 65 6e 61 2c 20 41 73 63 65 6e 73 69 6f 6e 20 61 6e 64 20\n[31657] 54 72 69 73 74 61 6e 20 64 61 20 43 75 6e 68 61 22 2c 22 63 6f 6d 6d 6f\n[31681] 6e 22 3a 22 53 61 69 6e 74 20 48 65 6c 65 6e 61 2c 20 41 73 63 65 6e 73\n[31705] 69 6f 6e 20 61 6e 64 20 54 72 69 73 74 61 6e 20 64 61 20 43 75 6e 68 61\n[31729] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[31753] 22 54 6f 67 6f 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 54 6f 67 6f 6c\n[31777] 65 73 65 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[31801] 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[31825] c3 a9 70 75 62 6c 69 71 75 65 20 74 6f 67 6f 6c 61 69 73 65 22 2c 22 63\n[31849] 6f 6d 6d 6f 6e 22 3a 22 54 6f 67 6f 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65\n[31873] 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 72 69 74 69 73 68 20 56 69 72\n[31897] 67 69 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[31921] 22 56 69 72 67 69 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65\n[31945] 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[31969] 3a 22 56 69 72 67 69 6e 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f\n[31993] 6e 22 3a 22 42 72 69 74 69 73 68 20 56 69 72 67 69 6e 20 49 73 6c 61 6e\n[32017] 64 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[32041] 22 3a 22 4b 65 6e 79 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[32065] 70 75 62 6c 69 63 20 6f 66 20 4b 65 6e 79 61 22 2c 22 6e 61 74 69 76 65\n[32089] 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[32113] 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 65 6e 79 61 22 2c 22 63 6f\n[32137] 6d 6d 6f 6e 22 3a 22 4b 65 6e 79 61 22 7d 2c 22 73 77 61 22 3a 7b 22 6f\n[32161] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 65\n[32185] 6e 79 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b 65 6e 79 61 22 7d 7d 7d\n[32209] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 75\n[32233] 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4e 69 75 65 22 2c 22 6e 61\n[32257] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n[32281] 69 61 6c 22 3a 22 4e 69 75 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69\n[32305] 75 65 22 7d 2c 22 6e 69 75 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[32329] 4e 69 75 c4 93 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 75 c4 93 22 7d\n[32353] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 48\n[32377] 65 61 72 64 20 49 73 6c 61 6e 64 20 61 6e 64 20 4d 63 44 6f 6e 61 6c 64\n[32401] 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 48 65\n[32425] 61 72 64 20 49 73 6c 61 6e 64 20 61 6e 64 20 4d 63 44 6f 6e 61 6c 64 20\n[32449] 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[32473] 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 48 65 61 72 64 20\n[32497] 49 73 6c 61 6e 64 20 61 6e 64 20 4d 63 44 6f 6e 61 6c 64 20 49 73 6c 61\n[32521] 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 48 65 61 72 64 20 49 73 6c\n[32545] 61 6e 64 20 61 6e 64 20 4d 63 44 6f 6e 61 6c 64 20 49 73 6c 61 6e 64 73\n[32569] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[32593] 22 52 77 61 6e 64 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70\n[32617] 75 62 6c 69 63 20 6f 66 20 52 77 61 6e 64 61 22 2c 22 6e 61 74 69 76 65\n[32641] 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[32665] 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 52 77 61 6e 64 61 22 2c 22 63\n[32689] 6f 6d 6d 6f 6e 22 3a 22 52 77 61 6e 64 61 22 7d 2c 22 66 72 61 22 3a 7b\n[32713] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20\n[32737] 72 77 61 6e 64 61 69 73 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 77 61\n[32761] 6e 64 61 22 7d 2c 22 6b 69 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[32785] 22 52 65 70 75 62 75 6c 69 6b 61 20 79 27 75 20 52 77 61 6e 64 61 22 2c\n[32809] 22 63 6f 6d 6d 6f 6e 22 3a 22 52 77 61 6e 64 61 22 7d 7d 7d 7d 2c 7b 22\n[32833] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 45 73 74 6f 6e 69 61\n[32857] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[32881] 66 20 45 73 74 6f 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[32905] 7b 22 65 73 74 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 45 65 73 74\n[32929] 69 20 56 61 62 61 72 69 69 6b 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 45 65\n[32953] 73 74 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[32977] 6e 22 3a 22 52 6f 6d 61 6e 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[33001] 22 52 6f 6d 61 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[33025] 22 72 6f 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 6f 6d c3 a2\n[33049] 6e 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 6f 6d c3 a2 6e 69 61 22\n[33073] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[33097] 54 72 69 6e 69 64 61 64 20 61 6e 64 20 54 6f 62 61 67 6f 22 2c 22 6f 66\n[33121] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 54 72 69\n[33145] 6e 69 64 61 64 20 61 6e 64 20 54 6f 62 61 67 6f 22 2c 22 6e 61 74 69 76\n[33169] 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[33193] 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 54 72 69 6e 69 64 61 64 20\n[33217] 61 6e 64 20 54 6f 62 61 67 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 72\n[33241] 69 6e 69 64 61 64 20 61 6e 64 20 54 6f 62 61 67 6f 22 7d 7d 7d 7d 2c 7b\n[33265] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 79 61 6e 61\n[33289] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 2d 6f 70 65 72 61 74 69\n[33313] 76 65 20 52 65 70 75 62 6c 69 63 20 6f 66 20 47 75 79 61 6e 61 22 2c 22\n[33337] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66\n[33361] 69 63 69 61 6c 22 3a 22 43 6f 2d 6f 70 65 72 61 74 69 76 65 20 52 65 70\n[33385] 75 62 6c 69 63 20 6f 66 20 47 75 79 61 6e 61 22 2c 22 63 6f 6d 6d 6f 6e\n[33409] 22 3a 22 47 75 79 61 6e 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[33433] 22 63 6f 6d 6d 6f 6e 22 3a 22 54 69 6d 6f 72 2d 4c 65 73 74 65 22 2c 22\n[33457] 6f 66 66 69 63 69 61 6c 22 3a 22 44 65 6d 6f 63 72 61 74 69 63 20 52 65\n[33481] 70 75 62 6c 69 63 20 6f 66 20 54 69 6d 6f 72 2d 4c 65 73 74 65 22 2c 22\n[33505] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66\n[33529] 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 44 65 6d 6f 63\n[33553] 72 c3 a1 74 69 63 61 20 64 65 20 54 69 6d 6f 72 2d 4c 65 73 74 65 22 2c\n[33577] 22 63 6f 6d 6d 6f 6e 22 3a 22 54 69 6d 6f 72 2d 4c 65 73 74 65 22 7d 2c\n[33601] 22 74 65 74 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba\n[33625] 62 6c 69 6b 61 20 44 65 6d 6f 6b 72 c3 a1 74 69 6b 61 20 54 69 6d c3 b3\n[33649] 72 2d 4c 65 73 74 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 69 6d c3 b3\n[33673] 72 2d 4c 65 73 74 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[33697] 6f 6d 6d 6f 6e 22 3a 22 56 69 65 74 6e 61 6d 22 2c 22 6f 66 66 69 63 69\n[33721] 61 6c 22 3a 22 53 6f 63 69 61 6c 69 73 74 20 52 65 70 75 62 6c 69 63 20\n[33745] 6f 66 20 56 69 65 74 6e 61 6d 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[33769] 3a 7b 22 76 69 65 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 e1 bb\n[33793] 99 6e 67 20 68 c3 b2 61 20 78 c3 a3 20 68 e1 bb 99 69 20 63 68 e1 bb a7\n[33817] 20 6e 67 68 c4 a9 61 20 56 69 e1 bb 87 74 20 4e 61 6d 22 2c 22 63 6f 6d\n[33841] 6d 6f 6e 22 3a 22 56 69 e1 bb 87 74 20 4e 61 6d 22 7d 7d 7d 7d 2c 7b 22\n[33865] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 55 72 75 67 75 61 79\n[33889] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4f 72 69 65 6e 74 61 6c 20 52\n[33913] 65 70 75 62 6c 69 63 20 6f 66 20 55 72 75 67 75 61 79 22 2c 22 6e 61 74\n[33937] 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69\n[33961] 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 4f 72 69 65 6e 74 61 6c\n[33985] 20 64 65 6c 20 55 72 75 67 75 61 79 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[34009] 55 72 75 67 75 61 79 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[34033] 6f 6d 6d 6f 6e 22 3a 22 56 61 74 69 63 61 6e 20 43 69 74 79 22 2c 22 6f\n[34057] 66 66 69 63 69 61 6c 22 3a 22 56 61 74 69 63 61 6e 20 43 69 74 79 20 53\n[34081] 74 61 74 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 69 74 61\n[34105] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 6f 20 64 65 6c\n[34129] 6c 61 20 43 69 74 74 c3 a0 20 64 65 6c 20 56 61 74 69 63 61 6e 6f 22 2c\n[34153] 22 63 6f 6d 6d 6f 6e 22 3a 22 56 61 74 69 63 61 6e 6f 22 7d 2c 22 6c 61\n[34177] 74 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 75 73 20 43\n[34201] 69 76 69 74 61 74 69 73 20 56 61 74 69 63 61 6e c3 a6 22 2c 22 63 6f 6d\n[34225] 6d 6f 6e 22 3a 22 56 61 74 69 63 61 6e c3 a6 22 7d 7d 7d 7d 2c 7b 22 6e\n[34249] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 48 6f 6e 67 20 4b 6f 6e\n[34273] 67 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 48 6f 6e 67 20 4b 6f 6e 67\n[34297] 20 53 70 65 63 69 61 6c 20 41 64 6d 69 6e 69 73 74 72 61 74 69 76 65 20\n[34321] 52 65 67 69 6f 6e 20 6f 66 20 74 68 65 20 50 65 6f 70 6c 65 27 73 20 52\n[34345] 65 70 75 62 6c 69 63 20 6f 66 20 43 68 69 6e 61 22 2c 22 6e 61 74 69 76\n[34369] 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[34393] 22 3a 22 48 6f 6e 67 20 4b 6f 6e 67 20 53 70 65 63 69 61 6c 20 41 64 6d\n[34417] 69 6e 69 73 74 72 61 74 69 76 65 20 52 65 67 69 6f 6e 20 6f 66 20 74 68\n[34441] 65 20 50 65 6f 70 6c 65 27 73 20 52 65 70 75 62 6c 69 63 20 6f 66 20 43\n[34465] 68 69 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 48 6f 6e 67 20 4b 6f 6e\n[34489] 67 22 7d 2c 22 7a 68 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e4\n[34513] b8 ad e5 8d 8e e4 ba ba e6 b0 91 e5 85 b1 e5 92 8c e5 9b bd e9 a6 99 e6\n[34537] b8 af e7 89 b9 e5 88 ab e8 a1 8c e6 94 bf e5 8c ba 22 2c 22 63 6f 6d 6d\n[34561] 6f 6e 22 3a 22 e9 a6 99 e6 b8 af 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[34585] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 75 73 74 72 69 61 22 2c 22 6f 66\n[34609] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 41 75 73\n[34633] 74 72 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 61 72\n[34657] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 20\n[34681] c3 96 73 74 65 72 72 65 69 63 68 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 c3\n[34705] 96 73 74 65 72 72 65 69 63 68 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[34729] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 74 69 67 75 61 20 61 6e 64 20 42\n[34753] 61 72 62 75 64 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 6e 74 69\n[34777] 67 75 61 20 61 6e 64 20 42 61 72 62 75 64 61 22 2c 22 6e 61 74 69 76 65\n[34801] 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[34825] 3a 22 41 6e 74 69 67 75 61 20 61 6e 64 20 42 61 72 62 75 64 61 22 2c 22\n[34849] 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 74 69 67 75 61 20 61 6e 64 20 42 61 72\n[34873] 62 75 64 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[34897] 6f 6e 22 3a 22 54 75 72 6b 6d 65 6e 69 73 74 61 6e 22 2c 22 6f 66 66 69\n[34921] 63 69 61 6c 22 3a 22 54 75 72 6b 6d 65 6e 69 73 74 61 6e 22 2c 22 6e 61\n[34945] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 72 75 73 22 3a 7b 22 6f 66 66 69 63\n[34969] 69 61 6c 22 3a 22 d0 a2 d1 83 d1 80 d0 ba d0 bc d0 b5 d0 bd d0 b8 d1 81\n[34993] d1 82 d0 b0 d0 bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a2 d1 83 d1 80\n[35017] d0 ba d0 bc d0 b5 d0 bd d0 b8 d1 8f 22 7d 2c 22 74 75 6b 22 3a 7b 22 6f\n[35041] 66 66 69 63 69 61 6c 22 3a 22 54 c3 bc 72 6b 6d 65 6e 69 73 74 61 6e 22\n[35065] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 c3 bc 72 6b 6d 65 6e 69 73 74 61 6e\n[35089] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[35113] 22 4d 6f 7a 61 6d 62 69 71 75 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[35137] 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 6f 7a 61 6d 62 69 71 75 65 22\n[35161] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f\n[35185] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20\n[35209] 4d 6f c3 a7 61 6d 62 69 71 75 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d\n[35233] 6f c3 a7 61 6d 62 69 71 75 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[35257] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6e 61 6d 61 22 2c 22 6f 66 66 69\n[35281] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 50 61 6e 61 6d\n[35305] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b\n[35329] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64\n[35353] 65 20 50 61 6e 61 6d c3 a1 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 61 6e\n[35377] 61 6d c3 a1 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[35401] 6f 6e 22 3a 22 4d 69 63 72 6f 6e 65 73 69 61 22 2c 22 6f 66 66 69 63 69\n[35425] 61 6c 22 3a 22 46 65 64 65 72 61 74 65 64 20 53 74 61 74 65 73 20 6f 66\n[35449] 20 4d 69 63 72 6f 6e 65 73 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[35473] 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 65\n[35497] 64 65 72 61 74 65 64 20 53 74 61 74 65 73 20 6f 66 20 4d 69 63 72 6f 6e\n[35521] 65 73 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 69 63 72 6f 6e 65 73\n[35545] 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[35569] 22 3a 22 49 72 65 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[35593] 52 65 70 75 62 6c 69 63 20 6f 66 20 49 72 65 6c 61 6e 64 22 2c 22 6e 61\n[35617] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n[35641] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 49 72 65 6c 61 6e\n[35665] 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 49 72 65 6c 61 6e 64 22 7d 2c 22\n[35689] 67 6c 65 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 6f 62 6c 61 63\n[35713] 68 74 20 6e 61 20 68 c3 89 69 72 65 61 6e 6e 22 2c 22 63 6f 6d 6d 6f 6e\n[35737] 22 3a 22 c3 89 69 72 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[35761] 63 6f 6d 6d 6f 6e 22 3a 22 43 75 72 61 c3 a7 61 6f 22 2c 22 6f 66 66 69\n[35785] 63 69 61 6c 22 3a 22 43 6f 75 6e 74 72 79 20 6f 66 20 43 75 72 61 c3 a7\n[35809] 61 6f 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a\n[35833] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 75 6e 74 72 79 20 6f 66 20\n[35857] 43 75 72 61 c3 a7 61 6f 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 75 72 61\n[35881] c3 a7 61 6f 22 7d 2c 22 6e 6c 64 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[35905] 3a 22 4c 61 6e 64 20 43 75 72 61 c3 a7 61 6f 22 2c 22 63 6f 6d 6d 6f 6e\n[35929] 22 3a 22 43 75 72 61 c3 a7 61 6f 22 7d 2c 22 70 61 70 22 3a 7b 22 6f 66\n[35953] 66 69 63 69 61 6c 22 3a 22 50 61 69 73 20 4b c3 b2 72 73 6f 75 22 2c 22\n[35977] 63 6f 6d 6d 6f 6e 22 3a 22 50 61 69 73 20 4b c3 b2 72 73 6f 75 22 7d 7d\n[36001] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 46 72\n[36025] 65 6e 63 68 20 47 75 69 61 6e 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[36049] 22 47 75 69 61 6e 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[36073] 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 75 79 61 6e 65\n[36097] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 79 61 6e 65 20 66 72 61 6e c3\n[36121] a7 61 69 73 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n[36145] 6d 6f 6e 22 3a 22 4e 6f 72 77 61 79 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[36169] 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 4e 6f 72 77 61 79 22 2c 22 6e 61\n[36193] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6e 6e 6f 22 3a 7b 22 6f 66 66 69 63\n[36217] 69 61 6c 22 3a 22 4b 6f 6e 67 65 72 69 6b 65 74 20 4e 6f 72 65 67 22 2c\n[36241] 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 65 67 22 7d 2c 22 6e 6f 62 22 3a\n[36265] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 6f 6e 67 65 72 69 6b 65 74 20\n[36289] 4e 6f 72 67 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 6f 72 67 65 22 7d\n[36313] 2c 22 73 6d 69 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4e 6f 72 67\n[36337] 67 61 20 67 6f 6e 61 67 61 73 72 69 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e\n[36361] 22 3a 22 4e 6f 72 67 67 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[36385] 22 63 6f 6d 6d 6f 6e 22 3a 22 c3 85 6c 61 6e 64 20 49 73 6c 61 6e 64 73\n[36409] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 c3 85 6c 61 6e 64 20 49 73 6c\n[36433] 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 77 65\n[36457] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4c 61 6e 64 73 6b 61 70 65\n[36481] 74 20 c3 85 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 c3 85 6c 61\n[36505] 6e 64 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[36529] 22 3a 22 43 65 6e 74 72 61 6c 20 41 66 72 69 63 61 6e 20 52 65 70 75 62\n[36553] 6c 69 63 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 65 6e 74 72 61 6c\n[36577] 20 41 66 72 69 63 61 6e 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69\n[36601] 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61\n[36625] 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 63 65 6e 74 72 61 66 72\n[36649] 69 63 61 69 6e 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 c3 a9 70 75 62\n[36673] 6c 69 71 75 65 20 63 65 6e 74 72 61 66 72 69 63 61 69 6e 65 22 7d 2c 22\n[36697] 73 61 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b c3 b6 64 c3 b6\n[36721] 72 c3 b6 73 c3 aa 73 65 20 74 c3 ae 20 42 c3 aa 61 66 72 c3 ae 6b 61 22\n[36745] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 c3 aa 61 66 72 c3 ae 6b 61 22 7d 7d\n[36769] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 75\n[36793] 72 6b 69 6e 61 20 46 61 73 6f 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[36817] 42 75 72 6b 69 6e 61 20 46 61 73 6f 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[36841] 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[36865] c3 a9 70 75 62 6c 69 71 75 65 20 64 75 20 42 75 72 6b 69 6e 61 22 2c 22\n[36889] 63 6f 6d 6d 6f 6e 22 3a 22 42 75 72 6b 69 6e 61 20 46 61 73 6f 22 7d 7d\n[36913] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 45 72\n[36937] 69 74 72 65 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74 65\n[36961] 20 6f 66 20 45 72 69 74 72 65 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[36985] 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 af\n[37009] d9 88 d9 84 d8 a9 20 d8 a5 d8 b1 d8 aa d8 b1 d9 8a d8 a7 22 2c 22 63 6f\n[37033] 6d 6d 6f 6e 22 3a 22 d8 a5 d8 b1 d8 aa d8 b1 d9 8a d8 a7 e2 80 8e 22 7d\n[37057] 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74 61 74\n[37081] 65 20 6f 66 20 45 72 69 74 72 65 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[37105] 45 72 69 74 72 65 61 22 7d 2c 22 74 69 72 22 3a 7b 22 6f 66 66 69 63 69\n[37129] 61 6c 22 3a 22 e1 88 83 e1 8c 88 e1 88 a8 20 e1 8a a4 e1 88 ad e1 89 b5\n[37153] e1 88 ab 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 e1 8a a4 e1 88 ad e1 89 b5\n[37177] e1 88 ab 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[37201] 6e 22 3a 22 54 61 6e 7a 61 6e 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[37225] 3a 22 55 6e 69 74 65 64 20 52 65 70 75 62 6c 69 63 20 6f 66 20 54 61 6e\n[37249] 7a 61 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e\n[37273] 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 55 6e 69 74 65 64 20 52\n[37297] 65 70 75 62 6c 69 63 20 6f 66 20 54 61 6e 7a 61 6e 69 61 22 2c 22 63 6f\n[37321] 6d 6d 6f 6e 22 3a 22 54 61 6e 7a 61 6e 69 61 22 7d 2c 22 73 77 61 22 3a\n[37345] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4a 61 6d 68 75 72 69 20 79 61 20\n[37369] 4d 75 75 6e 67 61 6e 6f 20 77 61 20 54 61 6e 7a 61 6e 69 61 22 2c 22 63\n[37393] 6f 6d 6d 6f 6e 22 3a 22 54 61 6e 7a 61 6e 69 61 22 7d 7d 7d 7d 2c 7b 22\n[37417] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 4b\n[37441] 6f 72 65 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[37465] 69 63 20 6f 66 20 4b 6f 72 65 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[37489] 22 3a 7b 22 6b 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 eb 8c\n[37513] 80 ed 95 9c eb af bc ea b5 ad 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 ed 95\n[37537] 9c ea b5 ad 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[37561] 6f 6e 22 3a 22 4a 6f 72 64 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[37585] 22 48 61 73 68 65 6d 69 74 65 20 4b 69 6e 67 64 6f 6d 20 6f 66 20 4a 6f\n[37609] 72 64 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61\n[37633] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d9 85 d9 85 d9\n[37657] 84 d9 83 d8 a9 20 d8 a7 d9 84 d8 a3 d8 b1 d8 af d9 86 d9 8a d8 a9 20 d8\n[37681] a7 d9 84 d9 87 d8 a7 d8 b4 d9 85 d9 8a d8 a9 22 2c 22 63 6f 6d 6d 6f 6e\n[37705] 22 3a 22 d8 a7 d9 84 d8 a3 d8 b1 d8 af d9 86 22 7d 7d 7d 7d 2c 7b 22 6e\n[37729] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 75 72 69 74 61 6e\n[37753] 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 61 6d 69 63 20\n[37777] 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 61 75 72 69 74 61 6e 69 61 22 2c\n[37801] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66\n[37825] 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 ac d9 85 d9 87 d9 88 d8 b1 d9\n[37849] 8a d8 a9 20 d8 a7 d9 84 d8 a5 d8 b3 d9 84 d8 a7 d9 85 d9 8a d8 a9 20 d8\n[37873] a7 d9 84 d9 85 d9 88 d8 b1 d9 8a d8 aa d8 a7 d9 86 d9 8a d8 a9 22 2c 22\n[37897] 63 6f 6d 6d 6f 6e 22 3a 22 d9 85 d9 88 d8 b1 d9 8a d8 aa d8 a7 d9 86 d9\n[37921] 8a d8 a7 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[37945] 6e 22 3a 22 4c 69 74 68 75 61 6e 69 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[37969] 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4c 69 74 68 75 61 6e 69 61\n[37993] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6c 69 74 22 3a 7b 22\n[38017] 6f 66 66 69 63 69 61 6c 22 3a 22 4c 69 65 74 75 76 6f 73 20 52 65 73 70\n[38041] 75 62 6c 69 6b 6f 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 69 65 74 75\n[38065] 76 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[38089] 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 4d 69 6e 6f 72 20 4f\n[38113] 75 74 6c 79 69 6e 67 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69\n[38137] 61 6c 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 4d 69 6e 6f 72\n[38161] 20 4f 75 74 6c 79 69 6e 67 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69\n[38185] 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61\n[38209] 6c 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 4d 69 6e 6f 72 20\n[38233] 4f 75 74 6c 79 69 6e 67 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f\n[38257] 6e 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 4d 69 6e 6f 72 20\n[38281] 4f 75 74 6c 79 69 6e 67 20 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d 2c 7b 22\n[38305] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 6c 6f 76 61 6b 69\n[38329] 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 6c 6f 76 61 6b 20 52 65\n[38353] 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73\n[38377] 6c 6b 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 6c 6f 76 65 6e 73\n[38401] 6b c3 a1 20 72 65 70 75 62 6c 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[38425] 22 53 6c 6f 76 65 6e 73 6b 6f 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[38449] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 67 6f 6c 61 22 2c 22 6f 66 66 69\n[38473] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 41 6e 67 6f 6c\n[38497] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b\n[38521] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64\n[38545] 65 20 41 6e 67 6f 6c 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 67 6f\n[38569] 6c 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[38593] 22 3a 22 4b 61 7a 61 6b 68 73 74 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c\n[38617] 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 61 7a 61 6b 68 73 74 61\n[38641] 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6b 61 7a 22 3a 7b\n[38665] 22 6f 66 66 69 63 69 61 6c 22 3a 22 d2 9a d0 b0 d0 b7 d0 b0 d2 9b d1 81\n[38689] d1 82 d0 b0 d0 bd 20 d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0\n[38713] ba d0 b0 d1 81 d1 8b 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d2 9a d0 b0 d0\n[38737] b7 d0 b0 d2 9b d1 81 d1 82 d0 b0 d0 bd 22 7d 2c 22 72 75 73 22 3a 7b 22\n[38761] 6f 66 66 69 63 69 61 6c 22 3a 22 d0 a0 d0 b5 d1 81 d0 bf d1 83 d0 b1 d0\n[38785] bb d0 b8 d0 ba d0 b0 20 d0 9a d0 b0 d0 b7 d0 b0 d1 85 d1 81 d1 82 d0 b0\n[38809] d0 bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 9a d0 b0 d0 b7 d0 b0 d1 85\n[38833] d1 81 d1 82 d0 b0 d0 bd 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[38857] 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 6c 64 6f 76 61 22 2c 22 6f 66 66 69 63\n[38881] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4d 6f 6c 64 6f 76\n[38905] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 72 6f 6e 22 3a 7b\n[38929] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 61 20 4d 6f\n[38953] 6c 64 6f 76 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 6f 6c 64 6f 76 61\n[38977] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[39001] 22 4d 61 6c 69 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[39025] 6c 69 63 20 6f 66 20 4d 61 6c 69 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[39049] 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3\n[39073] a9 70 75 62 6c 69 71 75 65 20 64 75 20 4d 61 6c 69 22 2c 22 63 6f 6d 6d\n[39097] 6f 6e 22 3a 22 4d 61 6c 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[39121] 22 63 6f 6d 6d 6f 6e 22 3a 22 46 61 6c 6b 6c 61 6e 64 20 49 73 6c 61 6e\n[39145] 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 61 6c 6b 6c 61 6e 64\n[39169] 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[39193] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 46 61 6c 6b 6c\n[39217] 61 6e 64 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 46\n[39241] 61 6c 6b 6c 61 6e 64 20 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d 2c 7b 22 6e\n[39265] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 72 6d 65 6e 69 61 22\n[39289] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66\n[39313] 20 41 72 6d 65 6e 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[39337] 22 68 79 65 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d5 80 d5 a1 d5\n[39361] b5 d5 a1 d5 bd d5 bf d5 a1 d5 b6 d5 ab 20 d5 80 d5 a1 d5 b6 d6 80 d5 a1\n[39385] d5 ba d5 a5 d5 bf d5 b8 d6 82 d5 a9 d5 b5 d5 b8 d6 82 d5 b6 22 2c 22 63\n[39409] 6f 6d 6d 6f 6e 22 3a 22 d5 80 d5 a1 d5 b5 d5 a1 d5 bd d5 bf d5 a1 d5 b6\n[39433] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[39457] 22 53 61 6d 6f 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 6e 64 65\n[39481] 70 65 6e 64 65 6e 74 20 53 74 61 74 65 20 6f 66 20 53 61 6d 6f 61 22 2c\n[39505] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[39529] 66 69 63 69 61 6c 22 3a 22 49 6e 64 65 70 65 6e 64 65 6e 74 20 53 74 61\n[39553] 74 65 20 6f 66 20 53 61 6d 6f 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53\n[39577] 61 6d 6f 61 22 7d 2c 22 73 6d 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[39601] 3a 22 4d 61 6c 6f 20 53 61 ca bb 6f 6c 6f 74 6f 20 54 75 74 6f ca bb 61\n[39625] 74 61 73 69 20 6f 20 53 c4 81 6d 6f 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[39649] 22 53 c4 81 6d 6f 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[39673] 6f 6d 6d 6f 6e 22 3a 22 4a 65 72 73 65 79 22 2c 22 6f 66 66 69 63 69 61\n[39697] 6c 22 3a 22 42 61 69 6c 69 77 69 63 6b 20 6f 66 20 4a 65 72 73 65 79 22\n[39721] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f\n[39745] 66 66 69 63 69 61 6c 22 3a 22 42 61 69 6c 69 77 69 63 6b 20 6f 66 20 4a\n[39769] 65 72 73 65 79 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4a 65 72 73 65 79 22\n[39793] 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 61 69\n[39817] 6c 6c 69 61 67 65 20 64 65 20 4a 65 72 73 65 79 22 2c 22 63 6f 6d 6d 6f\n[39841] 6e 22 3a 22 4a 65 72 73 65 79 22 7d 2c 22 6e 72 66 22 3a 7b 22 6f 66 66\n[39865] 69 63 69 61 6c 22 3a 22 42 61 69 6c 6c 69 61 67 65 20 64 c3 a9 20 4a c3\n[39889] a8 72 72 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4a c3 a8 72 72 69 22 7d\n[39913] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4a\n[39937] 61 70 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4a 61 70 61 6e 22\n[39961] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6a 70 6e 22 3a 7b 22 6f\n[39985] 66 66 69 63 69 61 6c 22 3a 22 e6 97 a5 e6 9c ac 22 2c 22 63 6f 6d 6d 6f\n[40009] 6e 22 3a 22 e6 97 a5 e6 9c ac 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[40033] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 6c 69 76 69 61 22 2c 22 6f 66 66\n[40057] 69 63 69 61 6c 22 3a 22 50 6c 75 72 69 6e 61 74 69 6f 6e 61 6c 20 53 74\n[40081] 61 74 65 20 6f 66 20 42 6f 6c 69 76 69 61 22 2c 22 6e 61 74 69 76 65 4e\n[40105] 61 6d 65 22 3a 7b 22 61 79 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[40129] 22 57 75 6c 69 77 79 61 20 53 75 79 75 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[40153] 22 57 75 6c 69 77 79 61 22 7d 2c 22 67 72 6e 22 3a 7b 22 6f 66 66 69 63\n[40177] 69 61 6c 22 3a 22 54 65 74 c3 a3 20 56 6f 6c c3 ad 76 69 61 22 2c 22 63\n[40201] 6f 6d 6d 6f 6e 22 3a 22 56 6f 6c c3 ad 76 69 61 22 7d 2c 22 71 75 65 22\n[40225] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 75 6c 69 77 79 61 20 4d 61\n[40249] 6d 61 6c 6c 61 71 74 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 75 6c 69\n[40273] 77 79 61 22 7d 2c 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[40297] 22 45 73 74 61 64 6f 20 50 6c 75 72 69 6e 61 63 69 6f 6e 61 6c 20 64 65\n[40321] 20 42 6f 6c 69 76 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 6f 6c 69\n[40345] 76 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f\n[40369] 6e 22 3a 22 43 68 69 6c 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[40393] 65 70 75 62 6c 69 63 20 6f 66 20 43 68 69 6c 65 22 2c 22 6e 61 74 69 76\n[40417] 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[40441] 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 43 68 69 6c 65 22 2c\n[40465] 22 63 6f 6d 6d 6f 6e 22 3a 22 43 68 69 6c 65 22 7d 7d 7d 7d 2c 7b 22 6e\n[40489] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6e 69 74 65 64 20 53\n[40513] 74 61 74 65 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 55 6e 69 74 65\n[40537] 64 20 53 74 61 74 65 73 20 6f 66 20 41 6d 65 72 69 63 61 22 2c 22 6e 61\n[40561] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63\n[40585] 69 61 6c 22 3a 22 55 6e 69 74 65 64 20 53 74 61 74 65 73 20 6f 66 20 41\n[40609] 6d 65 72 69 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 55 6e 69 74 65 64\n[40633] 20 53 74 61 74 65 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[40657] 6f 6d 6d 6f 6e 22 3a 22 53 61 69 6e 74 20 56 69 6e 63 65 6e 74 20 61 6e\n[40681] 64 20 74 68 65 20 47 72 65 6e 61 64 69 6e 65 73 22 2c 22 6f 66 66 69 63\n[40705] 69 61 6c 22 3a 22 53 61 69 6e 74 20 56 69 6e 63 65 6e 74 20 61 6e 64 20\n[40729] 74 68 65 20 47 72 65 6e 61 64 69 6e 65 73 22 2c 22 6e 61 74 69 76 65 4e\n[40753] 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[40777] 22 53 61 69 6e 74 20 56 69 6e 63 65 6e 74 20 61 6e 64 20 74 68 65 20 47\n[40801] 72 65 6e 61 64 69 6e 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69\n[40825] 6e 74 20 56 69 6e 63 65 6e 74 20 61 6e 64 20 74 68 65 20 47 72 65 6e 61\n[40849] 64 69 6e 65 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n[40873] 6d 6f 6e 22 3a 22 42 65 72 6d 75 64 61 22 2c 22 6f 66 66 69 63 69 61 6c\n[40897] 22 3a 22 42 65 72 6d 75 64 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[40921] 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 65 72\n[40945] 6d 75 64 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 72 6d 75 64 61 22\n[40969] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[40993] 53 65 79 63 68 65 6c 6c 65 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[41017] 52 65 70 75 62 6c 69 63 20 6f 66 20 53 65 79 63 68 65 6c 6c 65 73 22 2c\n[41041] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 63 72 73 22 3a 7b 22 6f 66\n[41065] 66 69 63 69 61 6c 22 3a 22 52 65 70 69 62 6c 69 6b 20 53 65 73 65 6c 22\n[41089] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 65 73 65 6c 22 7d 2c 22 65 6e 67 22\n[41113] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[41137] 66 20 53 65 79 63 68 65 6c 6c 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[41161] 53 65 79 63 68 65 6c 6c 65 73 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66\n[41185] 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 65 73 20\n[41209] 53 65 79 63 68 65 6c 6c 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 65\n[41233] 79 63 68 65 6c 6c 65 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[41257] 63 6f 6d 6d 6f 6e 22 3a 22 42 72 69 74 69 73 68 20 49 6e 64 69 61 6e 20\n[41281] 4f 63 65 61 6e 20 54 65 72 72 69 74 6f 72 79 22 2c 22 6f 66 66 69 63 69\n[41305] 61 6c 22 3a 22 42 72 69 74 69 73 68 20 49 6e 64 69 61 6e 20 4f 63 65 61\n[41329] 6e 20 54 65 72 72 69 74 6f 72 79 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[41353] 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 72\n[41377] 69 74 69 73 68 20 49 6e 64 69 61 6e 20 4f 63 65 61 6e 20 54 65 72 72 69\n[41401] 74 6f 72 79 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 72 69 74 69 73 68 20\n[41425] 49 6e 64 69 61 6e 20 4f 63 65 61 6e 20 54 65 72 72 69 74 6f 72 79 22 7d\n[41449] 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47\n[41473] 75 61 74 65 6d 61 6c 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[41497] 70 75 62 6c 69 63 20 6f 66 20 47 75 61 74 65 6d 61 6c 61 22 2c 22 6e 61\n[41521] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63\n[41545] 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 20 47 75 61 74\n[41569] 65 6d 61 6c 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 61 74 65 6d 61\n[41593] 6c 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e\n[41617] 22 3a 22 45 63 75 61 64 6f 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[41641] 52 65 70 75 62 6c 69 63 20 6f 66 20 45 63 75 61 64 6f 72 22 2c 22 6e 61\n[41665] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63\n[41689] 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 64 65 6c 20 45 63 75\n[41713] 61 64 6f 72 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 45 63 75 61 64 6f 72 22\n[41737] 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22\n[41761] 4d 61 72 74 69 6e 69 71 75 65 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[41785] 4d 61 72 74 69 6e 69 71 75 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22\n[41809] 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d 61 72\n[41833] 74 69 6e 69 71 75 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 72 74 69\n[41857] 6e 69 71 75 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d\n[41881] 6d 6f 6e 22 3a 22 54 61 6a 69 6b 69 73 74 61 6e 22 2c 22 6f 66 66 69 63\n[41905] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 54 61 6a 69 6b 69\n[41929] 73 74 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 72 75 73\n[41953] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d0 a0 d0 b5 d1 81 d0 bf d1\n[41977] 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 20 d0 a2 d0 b0 d0 b4 d0 b6 d0 b8 d0 ba\n[42001] d0 b8 d1 81 d1 82 d0 b0 d0 bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a2\n[42025] d0 b0 d0 b4 d0 b6 d0 b8 d0 ba d0 b8 d1 81 d1 82 d0 b0 d0 bd 22 7d 2c 22\n[42049] 74 67 6b 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d2 b6 d1 83 d0 bc\n[42073] d2 b3 d1 83 d1 80 d0 b8 d0 b8 20 d0 a2 d0 be d2 b7 d0 b8 d0 ba d0 b8 d1\n[42097] 81 d1 82 d0 be d0 bd 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a2 d0 be d2\n[42121] b7 d0 b8 d0 ba d0 b8 d1 81 d1 82 d0 be d0 bd 22 7d 7d 7d 7d 2c 7b 22 6e\n[42145] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 6c 74 61 22 2c 22\n[42169] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4d\n[42193] 61 6c 74 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67\n[42217] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20\n[42241] 6f 66 20 4d 61 6c 74 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 61 6c 74\n[42265] 61 22 7d 2c 22 6d 6c 74 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[42289] 65 70 75 62 62 6c 69 6b 61 20 74 61 20 27 20 4d 61 6c 74 61 22 2c 22 63\n[42313] 6f 6d 6d 6f 6e 22 3a 22 4d 61 6c 74 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[42337] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 61 6d 62 69 61 22 2c 22 6f\n[42361] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68\n[42385] 65 20 47 61 6d 62 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[42409] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[42433] 6c 69 63 20 6f 66 20 74 68 65 20 47 61 6d 62 69 61 22 2c 22 63 6f 6d 6d\n[42457] 6f 6e 22 3a 22 47 61 6d 62 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[42481] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 67 65 72 69 61 22 2c 22 6f 66\n[42505] 66 69 63 69 61 6c 22 3a 22 46 65 64 65 72 61 6c 20 52 65 70 75 62 6c 69\n[42529] 63 20 6f 66 20 4e 69 67 65 72 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[42553] 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 46\n[42577] 65 64 65 72 61 6c 20 52 65 70 75 62 6c 69 63 20 6f 66 20 4e 69 67 65 72\n[42601] 69 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 67 65 72 69 61 22 7d 7d\n[42625] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 61\n[42649] 68 61 6d 61 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d 6f\n[42673] 6e 77 65 61 6c 74 68 20 6f 66 20 74 68 65 20 42 61 68 61 6d 61 73 22 2c\n[42697] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66\n[42721] 66 69 63 69 61 6c 22 3a 22 43 6f 6d 6d 6f 6e 77 65 61 6c 74 68 20 6f 66\n[42745] 20 74 68 65 20 42 61 68 61 6d 61 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[42769] 42 61 68 61 6d 61 73 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[42793] 6f 6d 6d 6f 6e 22 3a 22 4b 6f 73 6f 76 6f 22 2c 22 6f 66 66 69 63 69 61\n[42817] 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 6f 73 6f 76 6f 22 2c\n[42841] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 71 69 22 3a 7b 22 6f 66\n[42865] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 61 20 65 20 4b 6f 73\n[42889] 6f 76 c3 ab 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b 6f 73 6f 76 61 22\n[42913] 7d 2c 22 73 72 70 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d0 a0 d0\n[42937] b5 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 20 d0 9a d0 be d1 81 d0 be\n[42961] d0 b2 d0 be 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 9a d0 be d1 81 d0 be\n[42985] d0 b2 d0 be 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[43009] 6f 6e 22 3a 22 4b 75 77 61 69 74 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[43033] 22 53 74 61 74 65 20 6f 66 20 4b 75 77 61 69 74 22 2c 22 6e 61 74 69 76\n[43057] 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[43081] 22 3a 22 d8 af d9 88 d9 84 d8 a9 20 d8 a7 d9 84 d9 83 d9 88 d9 8a d8 aa\n[43105] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a7 d9 84 d9 83 d9 88 d9 8a d8 aa\n[43129] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[43153] 22 4d 61 6c 64 69 76 65 73 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[43177] 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 4d 61 6c 64 69 76 65 73 22\n[43201] 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 64 69 76 22 3a 7b 22 6f\n[43225] 66 66 69 63 69 61 6c 22 3a 22 de 8b de a8 de 88 de ac de 80 de a8 de 83\n[43249] de a7 de 87 de b0 de 96 de ad de 8e de ac 20 de 96 de aa de 89 de b0 de\n[43273] 80 de ab de 83 de a8 de 87 de b0 de 94 de a7 22 2c 22 63 6f 6d 6d 6f 6e\n[43297] 22 3a 22 de 8b de a8 de 88 de ac de 80 de a8 de 83 de a7 de 87 de b0 de\n[43321] 96 de ad de 8e de ac 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[43345] 6f 6d 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 53 75 64 61 6e 22 2c 22 6f 66\n[43369] 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 53 6f 75\n[43393] 74 68 20 53 75 64 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b\n[43417] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62\n[43441] 6c 69 63 20 6f 66 20 53 6f 75 74 68 20 53 75 64 61 6e 22 2c 22 63 6f 6d\n[43465] 6d 6f 6e 22 3a 22 53 6f 75 74 68 20 53 75 64 61 6e 22 7d 7d 7d 7d 2c 7b\n[43489] 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 49 72 61 6e 22 2c\n[43513] 22 6f 66 66 69 63 69 61 6c 22 3a 22 49 73 6c 61 6d 69 63 20 52 65 70 75\n[43537] 62 6c 69 63 20 6f 66 20 49 72 61 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[43561] 65 22 3a 7b 22 66 61 73 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8\n[43585] ac d9 85 d9 87 d9 88 d8 b1 db 8c 20 d8 a7 d8 b3 d9 84 d8 a7 d9 85 db 8c\n[43609] 20 d8 a7 db 8c d8 b1 d8 a7 d9 86 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8\n[43633] a7 db 8c d8 b1 d8 a7 d9 86 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[43657] 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6c 62 61 6e 69 61 22 2c 22 6f 66 66 69\n[43681] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 41 6c 62 61 6e\n[43705] 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 71 69 22 3a\n[43729] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 6b 61 20 65\n[43753] 20 53 68 71 69 70 c3 ab 72 69 73 c3 ab 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[43777] 22 53 68 71 69 70 c3 ab 72 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22\n[43801] 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 72 61 7a 69 6c 22 2c 22 6f 66 66\n[43825] 69 63 69 61 6c 22 3a 22 46 65 64 65 72 61 74 69 76 65 20 52 65 70 75 62\n[43849] 6c 69 63 20 6f 66 20 42 72 61 7a 69 6c 22 2c 22 6e 61 74 69 76 65 4e 61\n[43873] 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[43897] 52 65 70 c3 ba 62 6c 69 63 61 20 46 65 64 65 72 61 74 69 76 61 20 64 6f\n[43921] 20 42 72 61 73 69 6c 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 72 61 73 69\n[43945] 6c 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n[43969] 3a 22 53 65 72 62 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[43993] 70 75 62 6c 69 63 20 6f 66 20 53 65 72 62 69 61 22 2c 22 6e 61 74 69 76\n[44017] 65 4e 61 6d 65 22 3a 7b 22 73 72 70 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[44041] 22 3a 22 d0 a0 d0 b5 d0 bf d1 83 d0 b1 d0 bb d0 b8 d0 ba d0 b0 20 d0 a1\n[44065] d1 80 d0 b1 d0 b8 d1 98 d0 b0 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d0 a1\n[44089] d1 80 d0 b1 d0 b8 d1 98 d0 b0 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[44113] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 69 7a 65 22 2c 22 6f 66 66 69\n[44137] 63 69 61 6c 22 3a 22 42 65 6c 69 7a 65 22 2c 22 6e 61 74 69 76 65 4e 61\n[44161] 6d 65 22 3a 7b 22 62 6a 7a 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[44185] 42 65 6c 69 7a 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 69 7a 65\n[44209] 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 65\n[44233] 6c 69 7a 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 69 7a 65 22 7d\n[44257] 2c 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 65 6c 69\n[44281] 63 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 69 63 65 22 7d 7d 7d\n[44305] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4d 79 61\n[44329] 6e 6d 61 72 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[44353] 69 63 20 6f 66 20 74 68 65 20 55 6e 69 6f 6e 20 6f 66 20 4d 79 61 6e 6d\n[44377] 61 72 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6d 79 61 22 3a\n[44401] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 e1 80 95 e1 80 bc e1 80 8a e1 80\n[44425] ba e1 80 91 e1 80 b1 e1 80 ac e1 80 84 e1 80 ba e1 80 85 e1 80 af 20 e1\n[44449] 80 9e e1 80 99 e1 80 b9 e1 80 99 e1 80 90 20 e1 80 99 e1 80 bc e1 80 94\n[44473] e1 80 ba e1 80 99 e1 80 ac e1 80 94 e1 80 ad e1 80 af e1 80 84 e1 80 ba\n[44497] e1 80 84 e1 80 b6 e1 80 90 e1 80 b1 e1 80 ac e1 80 ba 22 2c 22 63 6f 6d\n[44521] 6d 6f 6e 22 3a 22 e1 80 99 e1 80 bc e1 80 94 e1 80 ba e1 80 99 e1 80 ac\n[44545] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[44569] 22 42 68 75 74 61 6e 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e\n[44593] 67 64 6f 6d 20 6f 66 20 42 68 75 74 61 6e 22 2c 22 6e 61 74 69 76 65 4e\n[44617] 61 6d 65 22 3a 7b 22 64 7a 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[44641] 22 e0 bd a0 e0 bd 96 e0 be b2 e0 bd b4 e0 bd 82 e0 bc 8b e0 bd a2 e0 be\n[44665] 92 e0 be b1 e0 bd a3 e0 bc 8b e0 bd 81 e0 bd 96 e0 bc 8b 22 2c 22 63 6f\n[44689] 6d 6d 6f 6e 22 3a 22 e0 bd a0 e0 bd 96 e0 be b2 e0 bd b4 e0 bd 82 e0 bc\n[44713] 8b e0 bd a1 e0 bd b4 e0 bd a3 e0 bc 8b 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d\n[44737] 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 56 65 6e 65 7a 75 65 6c 61 22\n[44761] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 42 6f 6c 69 76 61 72 69 61 6e 20\n[44785] 52 65 70 75 62 6c 69 63 20 6f 66 20 56 65 6e 65 7a 75 65 6c 61 22 2c 22\n[44809] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66\n[44833] 69 63 69 61 6c 22 3a 22 52 65 70 c3 ba 62 6c 69 63 61 20 42 6f 6c 69 76\n[44857] 61 72 69 61 6e 61 20 64 65 20 56 65 6e 65 7a 75 65 6c 61 22 2c 22 63 6f\n[44881] 6d 6d 6f 6e 22 3a 22 56 65 6e 65 7a 75 65 6c 61 22 7d 7d 7d 7d 2c 7b 22\n[44905] 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4c 69 62 65 72 69 61\n[44929] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[44953] 66 20 4c 69 62 65 72 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a\n[44977] 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n[45001] 62 6c 69 63 20 6f 66 20 4c 69 62 65 72 69 61 22 2c 22 63 6f 6d 6d 6f 6e\n[45025] 22 3a 22 4c 69 62 65 72 69 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[45049] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4a 61 6d 61 69 63 61 22 2c 22 6f 66 66\n[45073] 69 63 69 61 6c 22 3a 22 4a 61 6d 61 69 63 61 22 2c 22 6e 61 74 69 76 65\n[45097] 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[45121] 3a 22 4a 61 6d 61 69 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4a 61 6d\n[45145] 61 69 63 61 22 7d 2c 22 6a 61 6d 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[45169] 3a 22 4a 61 6d 61 69 63 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4a 61 6d\n[45193] 61 69 63 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[45217] 6f 6e 22 3a 22 50 6f 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a\n[45241] 22 52 65 70 75 62 6c 69 63 20 6f 66 20 50 6f 6c 61 6e 64 22 2c 22 6e 61\n[45265] 74 69 76 65 4e 61 6d 65 22 3a 7b 22 70 6f 6c 22 3a 7b 22 6f 66 66 69 63\n[45289] 69 61 6c 22 3a 22 52 7a 65 63 7a 70 6f 73 70 6f 6c 69 74 61 20 50 6f 6c\n[45313] 73 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 50 6f 6c 73 6b 61 22 7d 7d\n[45337] 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 43 61\n[45361] 79 6d 61 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[45385] 3a 22 43 61 79 6d 61 6e 20 49 73 6c 61 6e 64 73 22 2c 22 6e 61 74 69 76\n[45409] 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c\n[45433] 22 3a 22 43 61 79 6d 61 6e 20 49 73 6c 61 6e 64 73 22 2c 22 63 6f 6d 6d\n[45457] 6f 6e 22 3a 22 43 61 79 6d 61 6e 20 49 73 6c 61 6e 64 73 22 7d 7d 7d 7d\n[45481] 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 42 72 75 6e\n[45505] 65 69 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4e 61 74 69 6f 6e 20 6f\n[45529] 66 20 42 72 75 6e 65 69 2c 20 41 62 6f 64 65 20 6f 66 20 50 65 61 63 65\n[45553] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 6d 73 61 22 3a 7b 22\n[45577] 6f 66 66 69 63 69 61 6c 22 3a 22 4e 61 74 69 6f 6e 20 6f 66 20 42 72 75\n[45601] 6e 65 69 2c 20 41 62 6f 64 65 20 44 61 6d 61 69 22 2c 22 63 6f 6d 6d 6f\n[45625] 6e 22 3a 22 4e 65 67 61 72 61 20 42 72 75 6e 65 69 20 44 61 72 75 73 73\n[45649] 61 6c 61 6d 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d\n[45673] 6f 6e 22 3a 22 43 6f 6d 6f 72 6f 73 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[45697] 3a 22 55 6e 69 6f 6e 20 6f 66 20 74 68 65 20 43 6f 6d 6f 72 6f 73 22 2c\n[45721] 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66\n[45745] 66 69 63 69 61 6c 22 3a 22 d8 a7 d9 84 d8 a7 d8 aa d8 ad d8 a7 d8 af 20\n[45769] d8 a7 d9 84 d9 82 d9 85 d8 b1 d9 8a 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[45793] d8 a7 d9 84 d9 82 d9 85 d8 b1 e2 80 8e 22 7d 2c 22 66 72 61 22 3a 7b 22\n[45817] 6f 66 66 69 63 69 61 6c 22 3a 22 55 6e 69 6f 6e 20 64 65 73 20 43 6f 6d\n[45841] 6f 72 65 73 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 43 6f 6d 6f 72 65 73 22\n[45865] 7d 2c 22 7a 64 6a 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 55 64 7a\n[45889] 69 6d 61 20 77 61 20 4b 6f 6d 6f 72 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[45913] 22 4b 6f 6d 6f 72 69 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63\n[45937] 6f 6d 6d 6f 6e 22 3a 22 47 75 61 6d 22 2c 22 6f 66 66 69 63 69 61 6c 22\n[45961] 3a 22 47 75 61 6d 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 63\n[45985] 68 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 75 c3 a5 68 c3 a5\n[46009] 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 c3 a5 68 c3 a5 6e 22 7d 2c\n[46033] 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 75 61 6d 22\n[46057] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 75 61 6d 22 7d 2c 22 73 70 61 22 3a\n[46081] 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 47 75 61 6d 22 2c 22 63 6f 6d 6d\n[46105] 6f 6e 22 3a 22 47 75 61 6d 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b\n[46129] 22 63 6f 6d 6d 6f 6e 22 3a 22 54 6f 6e 67 61 22 2c 22 6f 66 66 69 63 69\n[46153] 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 54 6f 6e 67 61 22 2c 22\n[46177] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66\n[46201] 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 54 6f 6e 67 61\n[46225] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 6f 6e 67 61 22 7d 2c 22 74 6f 6e\n[46249] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f\n[46273] 66 20 54 6f 6e 67 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 54 6f 6e 67 61\n[46297] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[46321] 22 4b 69 72 69 62 61 74 69 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 49\n[46345] 6e 64 65 70 65 6e 64 65 6e 74 20 61 6e 64 20 53 6f 76 65 72 65 69 67 6e\n[46369] 20 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 69 72 69 62 61 74 69 22 2c 22\n[46393] 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66\n[46417] 69 63 69 61 6c 22 3a 22 49 6e 64 65 70 65 6e 64 65 6e 74 20 61 6e 64 20\n[46441] 53 6f 76 65 72 65 69 67 6e 20 52 65 70 75 62 6c 69 63 20 6f 66 20 4b 69\n[46465] 72 69 62 61 74 69 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4b 69 72 69 62 61\n[46489] 74 69 22 7d 2c 22 67 69 6c 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[46513] 52 69 62 61 62 65 72 69 6b 69 20 4b 69 72 69 62 61 74 69 22 2c 22 63 6f\n[46537] 6d 6d 6f 6e 22 3a 22 4b 69 72 69 62 61 74 69 22 7d 7d 7d 7d 2c 7b 22 6e\n[46561] 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 47 68 61 6e 61 22 2c 22\n[46585] 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 47\n[46609] 68 61 6e 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67\n[46633] 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20\n[46657] 6f 66 20 47 68 61 6e 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 47 68 61 6e\n[46681] 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n[46705] 3a 22 43 68 61 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n[46729] 62 6c 69 63 20 6f 66 20 43 68 61 64 22 2c 22 6e 61 74 69 76 65 4e 61 6d\n[46753] 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d8\n[46777] ac d9 85 d9 87 d9 88 d8 b1 d9 8a d8 a9 20 d8 aa d8 b4 d8 a7 d8 af 22 2c\n[46801] 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 aa d8 b4 d8 a7 d8 af e2 80 8e 22 7d 2c\n[46825] 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 c3 a9 70 75\n[46849] 62 6c 69 71 75 65 20 64 75 20 54 63 68 61 64 22 2c 22 63 6f 6d 6d 6f 6e\n[46873] 22 3a 22 54 63 68 61 64 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[46897] 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 2c 22 6f 66 66 69\n[46921] 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61\n[46945] 62 77 65 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 62 77 67 22\n[46969] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[46993] 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69\n[47017] 6d 62 61 62 77 65 22 7d 2c 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61\n[47041] 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65\n[47065] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22\n[47089] 6b 63 6b 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[47113] 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22\n[47137] 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22 6b 68 69 22 3a 7b 22 6f 66 66\n[47161] 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62\n[47185] 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65\n[47209] 22 7d 2c 22 6e 64 63 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[47233] 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d\n[47257] 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22 6e 64 65 22 3a 7b\n[47281] 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20\n[47305] 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62\n[47329] 61 62 77 65 22 7d 2c 22 6e 79 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[47353] 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c\n[47377] 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22 73 6e\n[47401] 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63\n[47425] 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22\n[47449] 5a 69 6d 62 61 62 77 65 22 7d 2c 22 73 6f 74 22 3a 7b 22 6f 66 66 69 63\n[47473] 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62\n[47497] 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d\n[47521] 2c 22 74 6f 69 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75\n[47545] 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f\n[47569] 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22 74 73 6e 22 3a 7b 22 6f\n[47593] 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69\n[47617] 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62\n[47641] 77 65 22 7d 2c 22 74 73 6f 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[47665] 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63\n[47689] 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22 76 65 6e 22\n[47713] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[47737] 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69\n[47761] 6d 62 61 62 77 65 22 7d 2c 22 78 68 6f 22 3a 7b 22 6f 66 66 69 63 69 61\n[47785] 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65\n[47809] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 5a 69 6d 62 61 62 77 65 22 7d 2c 22\n[47833] 7a 69 62 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[47857] 69 63 20 6f 66 20 5a 69 6d 62 61 62 77 65 22 2c 22 63 6f 6d 6d 6f 6e 22\n[47881] 3a 22 5a 69 6d 62 61 62 77 65 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a\n[47905] 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69 6e 74 20 4d 61 72 74 69 6e 22\n[47929] 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69 6e 74 20 4d 61 72 74 69\n[47953] 6e 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b\n[47977] 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 61 69 6e 74 2d 4d 61 72 74 69 6e\n[48001] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 61 69 6e 74 2d 4d 61 72 74 69 6e\n[48025] 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a\n[48049] 22 4d 6f 6e 67 6f 6c 69 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4d\n[48073] 6f 6e 67 6f 6c 69 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[48097] 6d 6f 6e 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d0 9c d0 be d0 bd\n[48121] d0 b3 d0 be d0 bb 20 d1 83 d0 bb d1 81 22 2c 22 63 6f 6d 6d 6f 6e 22 3a\n[48145] 22 d0 9c d0 be d0 bd d0 b3 d0 be d0 bb 20 d1 83 d0 bb d1 81 22 7d 7d 7d\n[48169] 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 50 6f 72\n[48193] 74 75 67 61 6c 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 50 6f 72 74 75\n[48217] 67 75 65 73 65 20 52 65 70 75 62 6c 69 63 22 2c 22 6e 61 74 69 76 65 4e\n[48241] 61 6d 65 22 3a 7b 22 70 6f 72 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a\n[48265] 22 52 65 70 c3 ba 62 6c 69 63 61 20 70 6f 72 74 75 67 75 c3 aa 73 22 2c\n[48289] 22 63 6f 6d 6d 6f 6e 22 3a 22 50 6f 72 74 75 67 61 6c 22 7d 7d 7d 7d 2c\n[48313] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6d 65 72 69\n[48337] 63 61 6e 20 53 61 6d 6f 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 41\n[48361] 6d 65 72 69 63 61 6e 20 53 61 6d 6f 61 22 2c 22 6e 61 74 69 76 65 4e 61\n[48385] 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[48409] 41 6d 65 72 69 63 61 6e 20 53 61 6d 6f 61 22 2c 22 63 6f 6d 6d 6f 6e 22\n[48433] 3a 22 41 6d 65 72 69 63 61 6e 20 53 61 6d 6f 61 22 7d 2c 22 73 6d 6f 22\n[48457] 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 c4 81 6d 6f 61 20 41 6d 65\n[48481] 6c 69 6b 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 53 c4 81 6d 6f 61 20 41\n[48505] 6d 65 6c 69 6b 61 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f\n[48529] 6d 6d 6f 6e 22 3a 22 52 65 70 75 62 6c 69 63 20 6f 66 20 74 68 65 20 43\n[48553] 6f 6e 67 6f 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c\n[48577] 69 63 20 6f 66 20 74 68 65 20 43 6f 6e 67 6f 22 2c 22 6e 61 74 69 76 65\n[48601] 4e 61 6d 65 22 3a 7b 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[48625] 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 75 20 43 6f 6e 67 6f 22 2c\n[48649] 22 63 6f 6d 6d 6f 6e 22 3a 22 52 c3 a9 70 75 62 6c 69 71 75 65 20 64 75\n[48673] 20 43 6f 6e 67 6f 22 7d 2c 22 6b 6f 6e 22 3a 7b 22 6f 66 66 69 63 69 61\n[48697] 6c 22 3a 22 52 65 70 75 62 69 6c 69 6b 61 20 79 61 20 4b 6f 6e 67 6f 22\n[48721] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 65 70 75 62 69 6c 69 6b 61 20 79 61\n[48745] 20 4b 6f 6e 67 6f 22 7d 2c 22 6c 69 6e 22 3a 7b 22 6f 66 66 69 63 69 61\n[48769] 6c 22 3a 22 52 65 70 75 62 6c c3 ad 6b 69 20 79 61 20 4b 6f 6e 67 c3 b3\n[48793] 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 52 65 70 75 62 6c c3 ad 6b 69 20 79\n[48817] 61 20 4b 6f 6e 67 c3 b3 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22\n[48841] 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 67 69 75 6d 22 2c 22 6f 66 66 69 63\n[48865] 69 61 6c 22 3a 22 4b 69 6e 67 64 6f 6d 20 6f 66 20 42 65 6c 67 69 75 6d\n[48889] 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 64 65 75 22 3a 7b 22\n[48913] 6f 66 66 69 63 69 61 6c 22 3a 22 4b c3 b6 6e 69 67 72 65 69 63 68 20 42\n[48937] 65 6c 67 69 65 6e 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 67 69 65\n[48961] 6e 22 7d 2c 22 66 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52\n[48985] 6f 79 61 75 6d 65 20 64 65 20 42 65 6c 67 69 71 75 65 22 2c 22 63 6f 6d\n[49009] 6d 6f 6e 22 3a 22 42 65 6c 67 69 71 75 65 22 7d 2c 22 6e 6c 64 22 3a 7b\n[49033] 22 6f 66 66 69 63 69 61 6c 22 3a 22 4b 6f 6e 69 6e 6b 72 69 6a 6b 20 42\n[49057] 65 6c 67 69 c3 ab 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 42 65 6c 67 69 c3\n[49081] ab 22 7d 7d 7d 7d 2c 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22\n[49105] 3a 22 49 73 72 61 65 6c 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 53 74\n[49129] 61 74 65 20 6f 66 20 49 73 72 61 65 6c 22 2c 22 6e 61 74 69 76 65 4e 61\n[49153] 6d 65 22 3a 7b 22 61 72 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22\n[49177] d8 af d9 88 d9 84 d8 a9 20 d8 a5 d8 b3 d8 b1 d8 a7 d8 a6 d9 8a d9 84 22\n[49201] 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 d8 a5 d8 b3 d8 b1 d8 a7 d8 a6 d9 8a d9\n[49225] 84 22 7d 2c 22 68 65 62 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 d7\n[49249] 9e d7 93 d7 99 d7 a0 d7 aa 20 d7 99 d7 a9 d7 a8 d7 90 d7 9c 22 2c 22 63\n[49273] 6f 6d 6d 6f 6e 22 3a 22 d7 99 d7 a9 d7 a8 d7 90 d7 9c 22 7d 7d 7d 7d 2c\n[49297] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 65 77 20 5a\n[49321] 65 61 6c 61 6e 64 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 4e 65 77 20\n[49345] 5a 65 61 6c 61 6e 64 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22\n[49369] 65 6e 67 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 4e 65 77 20 5a 65\n[49393] 61 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 65 77 20 5a 65 61\n[49417] 6c 61 6e 64 22 7d 2c 22 6d 72 69 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22\n[49441] 3a 22 41 6f 74 65 61 72 6f 61 22 2c 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6f\n[49465] 74 65 61 72 6f 61 22 7d 2c 22 6e 7a 73 22 3a 7b 22 6f 66 66 69 63 69 61\n[49489] 6c 22 3a 22 4e 65 77 20 5a 65 61 6c 61 6e 64 22 2c 22 63 6f 6d 6d 6f 6e\n[49513] 22 3a 22 4e 65 77 20 5a 65 61 6c 61 6e 64 22 7d 7d 7d 7d 2c 7b 22 6e 61\n[49537] 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 63 61 72 61 67 75 61\n[49561] 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65 70 75 62 6c 69 63 20 6f\n[49585] 66 20 4e 69 63 61 72 61 67 75 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65\n[49609] 22 3a 7b 22 73 70 61 22 3a 7b 22 6f 66 66 69 63 69 61 6c 22 3a 22 52 65\n[49633] 70 c3 ba 62 6c 69 63 61 20 64 65 20 4e 69 63 61 72 61 67 75 61 22 2c 22\n[49657] 63 6f 6d 6d 6f 6e 22 3a 22 4e 69 63 61 72 61 67 75 61 22 7d 7d 7d 7d 2c\n[49681] 7b 22 6e 61 6d 65 22 3a 7b 22 63 6f 6d 6d 6f 6e 22 3a 22 41 6e 67 75 69\n[49705] 6c 6c 61 22 2c 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 6e 67 75 69 6c 6c\n[49729] 61 22 2c 22 6e 61 74 69 76 65 4e 61 6d 65 22 3a 7b 22 65 6e 67 22 3a 7b\n[49753] 22 6f 66 66 69 63 69 61 6c 22 3a 22 41 6e 67 75 69 6c 6c 61 22 2c 22 63\n[49777] 6f 6d 6d 6f 6e 22 3a 22 41 6e 67 75 69 6c 6c 61 22 7d 7d 7d 7d 5d\n\n\nAbove we see that the content that is received from the API is delivered as a compressed binary string, which must be decompressed and converted back to character encoding before processing. We do this using a built-in httr function:\n\nbdy &lt;- content(response, \"text\")\n\nNo encoding supplied: defaulting to UTF-8.\n\n\nOnce we have the content extracted and converted, we can begin to process it. We previously examined the response and determined that it is in JSON format, so our step will be to load the content into a JSON object for ease of traversal:\n\nbdy_json &lt;- fromJSON(bdy)\n\nIf you examine the class and structure of the bdy_json object, you will see that jsonlite has converted the JSON structure into a nice R data frame where you can begin the process of exploration and cleaning in preparation for research.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Getting Data from the Web</span>"
    ]
  },
  {
    "objectID": "chapters/09_data-from-the-web.html#web-scraping",
    "href": "chapters/09_data-from-the-web.html#web-scraping",
    "title": "9  Getting Data from the Web",
    "section": "9.4 Web Scraping",
    "text": "9.4 Web Scraping\n\n9.4.1 What’s in a Web Page?\nModern web pages usually consist of many files:\n\nHypertext markup language (HTML) for structure and formatting\nCascading style sheets (CSS) for more formatting\nJavaScript (JS) for interactivity\nImages\n\nHTML is the only component that always has to be there. Since HTML is what gives a web page structure, it’s what we’ll focus on when scraping.\nHTML is closely related to eXtensible markup language (XML). Both languages use tags to mark structural elements of data. In HTML, the elements literally correspond to the elements of a web page: paragraphs, links, tables, and so on.\nMost tags come in pairs. The opening tag marks the beginning of an element and the closing tag marks the end. Opening tags are written &lt;NAME&gt;, where NAME is the name of the tag. Closing tags are written &lt;/NAME&gt;.\nA singleton tag is a tag that stands alone, rather than being part of a pair. Singleton tags are written &lt;NAME /&gt;. In HTML (but not XML) they can also be written &lt;NAME&gt;. Fortunately, HTML only has a few singleton tags, so they can be distinguished by name regardless of which way they’re written.\nFor example, here’s some HTML that uses the em (emphasis, usually italic) and strong (usually bold) tags, as well as the singleton br (line break) tag:\n&lt;em&gt;&lt;strong&gt;This text&lt;/strong&gt; is emphasized.&lt;br /&gt;&lt;/em&gt; Not emphasized\nA pair of tags can contain other elements (paired or singleton tags), but not a lone opening or closing tag. This creates a strict, treelike hierarchy.\nOpening and singleton tags can have attributes that contain additional information. Attributes are name-value pairs written NAME=\"VALUE\" after the tag name.\nFor instance, the HTML a (anchor) tag creates a link to the URL provided for the href attribute:\n&lt;a href=\"http://www.google.com/\" id=\"mytag\"&gt;My Search Engine&lt;/a&gt;\nIn this case the tag also has a value set for the id attribute.\nNow let’s look at an example of HTML for a complete, albeit simple, web page:\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is the page title!&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;This is a header!&lt;/h1&gt;\n    &lt;p&gt;This is a paragraph.\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's a website!&lt;/a&gt;\n    &lt;/p&gt;\n    &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nIn most web browsers, you can examine the HTML for a web page by right-clicking and choosing “View Page Source”.\nSee here for a more detailed explanation of HTML, and here for a list of valid HTML elements.\n\n\n9.4.2 R’s XML Parsers\nA parser converts structured data into familiar data structures. R has two popular packages for parsing XML (and HTML):\n\nThe XML package\nThe xml2 package\n\nThe XML package has more features. The xml2 package is more user-friendly, and as part of the Tidyverse, it’s relatively well-documented. This lesson focuses on xml2, since most of the additional features in the XML package are related to writing (rather than parsing) XML documents.\nThe xml2 package is often used in conjunction with the rvest package, which provides support for CSS selectors (described later in this lesson) and automates scraping HTML tables.\nThe first time you use these packages, you’ll have to install them:\ninstall.packages(\"xml2\")\ninstall.packages(\"rvest\")\nLet’s start by parsing the example of a complete web page from earlier. The xml2 function read_xml reads an XML document, and the rvest function read_html reads an HTML document. Both accept an XML/HTML string or a file path (including URLs):\n\nhtml = r\"(\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is the page title!&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;This is a header!&lt;/h1&gt;\n    &lt;p&gt;This is a paragraph.\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's a website!&lt;/a&gt;\n    &lt;/p&gt;\n    &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt; )\"\n\nlibrary(\"xml2\")\nlibrary(\"rvest\")\n\ndoc = read_html(html)\ndoc\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n    &lt;h1&gt;This is a header!&lt;/h1&gt;\\n    &lt;p&gt;This is a paragraph.\\n     ...\n\n\nThe xml_children function returns all of the immediate children of a given element.\nThe top element of our document is the html tag, and its immediate children are the head and body tags:\n\ntags = xml_children(doc)\n\nThe result from xml_children is a node set (xml_nodeset object). Think of a node set as a vector where the elements are tags rather than numbers or strings. Just like a vector, you can access individual elements with the indexing (square bracket [) operator:\n\nlength(tags)\n\n[1] 2\n\nhead = tags[1]\nhead\n\n{xml_nodeset (1)}\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n\n\nThe xml_text function returns the text contained in a tag. Let’s get the text in the title tag, which is beneath the head tag. First we isolate the tag, then use xml_text:\n\ntitle = xml_children(head)\nxml_text(title)\n\n[1] \"\"                        \"This is the page title!\"\n\n\nNavigating through the tags by hand is tedious and easy to get wrong, but fortunately there’s a better way to find the tags we want.\n\n\n9.4.3 XPath\nAn XML document is a tree, similar to the file system on your computer:\nhtml\n├── head\n│   └── title\n└── body\n    ├── h1\n    ├── p\n    └── p\n        └── a\nWhen we wanted to find files, we wrote file paths. We can do something similar to find XML elements.\nXPath is a language for writing paths to elements in an XML document. XPath is not R-specific. At a glance, an XPath looks similar to a file path:\n\n\n\nXPath\nDescription\n\n\n\n\n/\nroot, or element separator\n\n\n.\ncurrent tag\n\n\n..\nparent tag\n\n\n*\nany tag (wildcard)\n\n\n\nThe xml2 function xml_find_all finds all elements at given XPath:\n\nxml_find_all(doc, \"/html/body/p\")\n\n{xml_nodeset (2)}\n[1] &lt;p&gt;This is a paragraph.\\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's ...\n[2] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\nUnlike a file path, an XPath can identify multiple elements. If you only want a specific element, use indexing to get it from the result.\nXPath also has some features that are different from file paths. The // separator means “at any level beneath.” It’s a useful shortcut when you want to find a specific element but don’t care where it is.\nLet’s get all of the p elements at any level of the document:\n\nxml_find_all(doc, \"//p\")\n\n{xml_nodeset (2)}\n[1] &lt;p&gt;This is a paragraph.\\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's ...\n[2] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\nLet’s also get all a elements at any level beneath a p element:\n\nxml_find_all(doc, \"//p/a\")\n\n{xml_nodeset (1)}\n[1] &lt;a href=\"http://www.r-project.org/\"&gt;Here's a website!&lt;/a&gt;\n\n\nThe vertical bar | means “or.” You can use it to get two different sets of elements in one query.\nLet’s get all h1 or p tags:\n\nxml_find_all(doc, \"//h1|//p\")\n\n{xml_nodeset (3)}\n[1] &lt;h1&gt;This is a header!&lt;/h1&gt;\n[2] &lt;p&gt;This is a paragraph.\\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's ...\n[3] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\n\n9.4.3.1 Predicates\nIn XPath, the predicate operator [] gets elements at a position or matching a condition. Most conditions are about the attributes of the element. In the predicate operator, attributes are always prefixed with @.\nFor example, suppose we want to find all tags where the id attribute is equal to \"hello\":\n\nxml_find_all(doc, \"//*[@id = 'hello']\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\nNotice that the equality operator in XPath is =, not ==. Strings in XPath can be quoted with single or double quotes.\nYou can combine multiple conditions in the predicate operator with and and or. There are also several XPath functions you can use in the predicate operator. These functions are not R functions, but rather built into XPath. Here are a few:\n\n\n\nXPath\nDescription\n\n\n\n\nnot()\nnegation\n\n\ncontains()\ncheck string x contains y\n\n\ntext()\nget tag text\n\n\nsubstring()\nget a substring\n\n\n\nFor instance, suppose we want to get elements that contain the word “paragraph”:\n\nxml_find_all(doc, \"//*[contains(text(), 'paragraph')]\")\n\n{xml_nodeset (2)}\n[1] &lt;p&gt;This is a paragraph.\\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's ...\n[2] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\nFinally, note that you can also use the predicate operator to get elements at a specific position. For example, to get the second p element anywhere in the document:\n\nxml_find_all(doc, \"//p[2]\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\nNotice that this is the same as if we had used R to get the second element:\n\nxml_find_all(doc, \"//p\")[2]\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBeware that although the XPath predicate operator resembles R’s indexing operator, the syntax is not always the same.\n\n\nWe’ll learn more XPath in the examples. There’s a complete list of XPath functions on Wikipedia.\n\n\n\n9.4.4 The Web Scraping Workflow\nScraping a web page is part technology, part art. The goal is to find an XPath that’s concise but specific enough to identify only the elements you want. If you plan to scrape the web page again later or want to scrape a lot of similar web pages, the XPath also needs to be general enough that it still works even if there are small variations.\nFirefox and Chrome include “web developer tools” that are invaluable for planning a web scraping strategy. Press Ctrl + Shift + i (Cmd + Shift + i on OS X) in Firefox or Chrome to open the web developer tools.\nWe can also use the web developer tools to interactively identify the element that corresponds to a specific part of a web page. Press Ctrl + Shift + c and then click on the part of the web page you want to identify.\nThe best way to approach web scraping (and programming in general) is as an incremental, iterative process. Use the web developer tools to come up with a basic strategy, try it out in R, check which parts don’t work, and then repeat to adjust the strategy. Expect to go back and forth between your web browser and R several times when you’re scraping.\nMost scrapers follow the same four steps, regardless of the web page and the language of the scraper:\n\nDownload pages with an HTTP request (usually GET)\nParse pages to extract text\nClean up extracted text with string methods or regex\nSave cleaned results\n\nIn R, xml2’s read_xml function takes care of step 1 for you, although you can also use httr functions to make the request yourself.\n\n9.4.4.1 Being Polite\nMaking an HTTP request is not free! It has a real cost in CPU time and also cash. Server administrators will not appreciate it if you make too many requests or make requests too quickly. So:\n\nIf you’re making multiple requests, slow them down by using R’s Sys.sleep function to make R do nothing for a moment. Aim for no more than 20-30 requests per second, unless you’re using an API that says more are okay.\nAvoid requesting the same page twice. One way to do this is by caching (saving) the results of the requests you make. You can do this manually, or use a package that does it automatically, like the httpcache package.\n\n\n\n\n\n\n\nImportant\n\n\n\nFailing to be polite can get you banned from websites! Also check the website’s terms of service to make sure scraping is not explicitly forbidden.\n\n\n\n\n9.4.4.2 Case Study: CA Cities\nWikipedia has many pages that are just tables of data. For example, there’s this list of cities and towns in California. Let’s scrape the table to get a data frame.\nStep 1 is to download the page:\nwiki_url =\n  \"https://en.wikipedia.org/wiki/List_of_cities_and_towns_in_California\"\n\nwiki_doc = read_html(wiki_url)\nStep 2 is to extract the table element from the page. We can use Firefox or Chrome’s web developer tools to identify the table. HTML tables usually use the table tag. Let’s see if it’s the only table in the page:\n\ntables = xml_find_all(wiki_doc, \"//table\")\ntables\n\n{xml_nodeset (4)}\n[1] &lt;table class=\"wikitable sortable\"&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scope=\"row\" style=\"b ...\n[2] &lt;table class=\"wikitable plainrowheaders sortable\"&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scop ...\n[3] &lt;table class=\"nowraplinks hlist mw-collapsible autocollapse navbox-inner\" ...\n[4] &lt;table class=\"nowraplinks mw-collapsible autocollapse navbox-inner\" style ...\n\n\nThe page has 4 tables. We can either make our XPath more specific, or use indexing to get the table we want. Refining the XPath makes our scraper more robust, but indexing is easier.\nFor the sake of learning, let’s refine the XPath. Going back to the browser, we can see that the table includes \"wikitable\" and \"sortable\" in its class attribute. So let’s search for these among the table elements:\n\ntab = xml_find_all(tables, \"//*[contains(@class, 'sortable')]\")\ntab\n\n{xml_nodeset (2)}\n[1] &lt;table class=\"wikitable sortable\"&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scope=\"row\" style=\"b ...\n[2] &lt;table class=\"wikitable plainrowheaders sortable\"&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scop ...\n\n\nNow we get just two tables, and the second one is the one we want! Here we used a second XPath applied only to the results from the first, but we also could’ve done this all with one XPath: //table[contains(@class, 'sortable')].\nThe next part of extracting the data is to extract the value from each individual cell in the table. HTML tables have a strict layout order, with tags to indicate rows and cells. We could extract each cell by hand and then reassemble them into a data frame, but the rvest function html_table can do it for us automatically:\n\ncities = html_table(tab, fill = TRUE)\ncities = cities[[2]]\nhead(cities)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nCounty\nPopulation (2020)[1]\nPopulation (2010)[9]\nChange\nLand area[10]\nLand area[10]\nPopulation density[10]\nIncorporated[8]\n\n\n\n\nName\nType\nCounty\nPopulation (2020)[1]\nPopulation (2010)[9]\nChange\nsq mi\nkm2\nPopulation density[10]\nIncorporated[8]\n\n\nAdelanto\nCity\nSan Bernardino\n38,046\n31,765\n+19.8%\n52.87\n136.9\n719.6/sq mi (277.8/km2)\nDecember 22, 1970\n\n\nAgoura Hills\nCity\nLos Angeles\n20,299\n20,330\n−0.2%\n7.80\n20.2\n2,602.4/sq mi (1,004.8/km2)\nDecember 8, 1982\n\n\nAlameda\nCity\nAlameda\n78,280\n73,812\n+6.1%\n10.45\n27.1\n7,490.9/sq mi (2,892.3/km2)\nApril 19, 1854\n\n\nAlbany\nCity\nAlameda\n20,271\n18,539\n+9.3%\n1.79\n4.6\n11,324.6/sq mi (4,372.4/km2)\nSeptember 22, 1908\n\n\nAlhambra\nCity\nLos Angeles\n82,868\n83,089\n−0.3%\n7.63\n19.8\n10,860.8/sq mi (4,193.4/km2)\nJuly 11, 1903\n\n\n\n\n\n\nThe fill = TRUE argument ensures that empty cells are filled with NA. We’ve successfully imported the data from the web page into R, so we’re done with step 2.\nStep 3 is to clean up the data frame. The column names contain symbols, the first row is part of the header, and the column types are not correct.\n\n# Fix column names.\nnames(cities) = c(\n  \"city\", \"type\", \"county\", \"population2020\", \"population2010\",\n  \"population_change\", \"mi2\", \"km2\", \"density\", \"date\"\n)\n\n# Remove fake first row.\ncities = cities[-1, ]\n# Reset row names.\nrownames(cities) = NULL\n\nHow can we clean up the date column? The as.Date function converts a string into a date R understands. The idea is to match the date string to a format string where the components of the date are indicated by codes that start with %. For example, %m stands for the month as a two-digit number. You can read about the different date format codes in ?strptime.\nHere’s the code to convert the dates in the data frame:\n\ndates = as.Date(cities$date, \"%B %m, %Y\")\ncities$date = dates\n\nWe can also convert the population to a number:\n\nclass(cities$population2020)\n\n[1] \"character\"\n\n# Remove commas and footnotes (e.g., [1]) before conversion\nlibrary(\"stringr\")\n\npop = str_replace_all(cities$population2020, \",\", \"\")\npop = str_replace_all(pop, \"\\\\[[0-9]+\\\\]\", \"\")\npop = as.numeric(pop)\n\n# Check for missing values, which can mean conversion failed\nany(is.na(pop))\n\n[1] FALSE\n\ncities$population2020 = pop\n\n\n\n9.4.4.3 Case Study: The CA Aggie\nSuppose we want to scrape The California Aggie.\nIn particular, we want to get all the links to news articles on the features page https://theaggie.org/category/features/. This could be one part of a larger scraping project where we go on to scrape individual articles.\nFirst for Step 1, let’s download the features page so we can extract the links:\nurl = \"https://theaggie.org/category/features/\"\ndoc = read_html(url)\nWe know that links are in a tags, but we only want links to articles. Looking at the features page with the web developer tools, the links to feature articles are all inside of a div tag with class td_block_inner. So for Step 2, let’s get that tag:\n\nxml_find_all(doc, \"//div[contains(@class, 'td_block_inner')]\")\n\n{xml_nodeset (9)}\n[1] &lt;div id=\"tdi_50\" class=\"td_block_inner td-fix-index\"&gt;\\n&lt;div class=\"tdb-ma ...\n[2] &lt;div id=\"tdi_51\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[3] &lt;div id=\"tdi_52\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[4] &lt;div id=\"tdi_53\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[5] &lt;div id=\"tdi_54\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[6] &lt;div id=\"tdi_55\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[7] &lt;div id=\"tdi_56\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[8] &lt;div id=\"tdi_57\" class=\"td_block_inner\"&gt;\\r\\n        &lt;div class=\"tdb_modul ...\n[9] &lt;div id=\"tdi_74\" class=\"td_block_inner tdb-block-inner td-fix-index\"&gt;\\r\\n ...\n\n# OR html_nodes(doc, \"div.td-block-inner\")\n\nThat returns a lot of results, so let’s try using the id attribute, which is \"tdi_113\", instead. Usually the id of an element is unique, so this ensures that we get the right section.\nWe can also add in a part about getting links now:\n\ndiv = xml_find_all(doc, \"//div[@id = 'tdi_113']\")\n# OR html_nodes(doc, \"div#tdi_113\")\n\nlinks = xml_find_all(div, \".//a\")\n# OR html_nodes(div, \"a\")\n\nlength(links)\n\n[1] 0\n\n\nThat gives us 0 links, but there are only 15 articles on the page, so something’s still not right. Inspecting the page again, there are actually three links to each article: on the image, on the title, and on “Continue Reading”.\nLet’s focus on the title link. All of the title links are inside of an h3 tag. Generally it’s more robust to rely on tags (structure) than to rely on attributes (other than id and class). So let’s use the h3 tag here:\n\nlinks = xml_find_all(div, \".//h3/a\")\n# OR html_nodes(div, \"h3 &gt; a\")\n\nlength(links)\n\n[1] 0\n\n\nNow we’ve got the 15 links, so let’s get the URLs from the href attribute.\n\nfeature_urls = xml_attr(links, \"href\")\n\nThe other article listings (Sports, Science, etc) on The Aggie have a similar structure, so we can potentially reuse our code to scrape those.\nSo let’s turn our code into a function. The input will be a downloaded page, and the output will be the article links.\n\nparse_article_links = function(page) {\n  div = xml_find_all(page, \"//div[@id = 'tdi_113']\")\n  links = xml_find_all(div, \".//h3/a\")\n  xml_attr(links, \"href\")\n}\n\nWe can test this out on the Sports page. First we download the page:\nsports = read_html(\"https://theaggie.org/category/sports\")\nThen we call the function on the document:\n\nsports_urls = parse_article_links(sports)\nhead(sports_urls)\n\ncharacter(0)\n\n\nIt looks like the function works even on other pages! We can also set up the function to extract the link to the next page, in case we want to scrape multiple pages of links.\nThe link to the next page of features (an arrow at the bottom) is an a tag with attribute aria-label in a div with class page-nav. Let’s see if that’s specific enough to isolate the tag:\n\nnav = xml_find_all(doc, \"//div[contains(@class, 'page-nav')]\")\n# OR html_nodes(doc, \"div.page-nav\")\nnext_page = xml_find_all(nav, \".//a[contains(@aria-label, 'next-page')]\")\n# OR html_nodes(nav, \"a[aria-label *= 'next-page']\")\n\nIt looks like it is. We use contains here rather than = because it is common for the class attribute to have many parts. Using contains makes our code robust against changes in the future.\nWe can now modify our parser function to return the link to the next page:\n\nparse_article_links = function(page) {\n  # Get article URLs\n  div = xml_find_all(page, \"//div[@id = 'tdi_113']\")\n  links = xml_find_all(div, \".//h3/a\")\n  urls = xml_attr(links, \"href\")\n\n  # Get next page URL\n  nav = xml_find_all(page, \"//div[contains(@class, 'page-nav')]\")\n  next_page = xml_find_all(nav, \".//a[contains(@aria-label, 'next-page')]\")\n  next_url = xml_attr(next_page, \"href\")\n\n  # Using a list allows us to return two objects\n  list(urls = urls, next_url = next_url)\n}\n\nSince our function gets URL for the next page, what happens on the last page?\nLooking at the last page in the browser, there is no link to the next page. Let’s see what our scraper function does:\nlast_page = read_html(\"https://theaggie.org/category/features/page/187/\")\n\nparse_article_links(last_page)\n\n$urls\ncharacter(0)\n\n$next_url\n[1] \"https://theaggie.org/category/features/page/188/\"\n\n\nWe get an empty character vector as the URL for the next page. This is because the xml_find_all function returns an empty node set for the next page URL, so there aren’t any href fields for xml_attr to extract. It’s convenient that the xml2 functions behave this way, but we could also add an if-statement to the function to check (and possibly return NA as the next URL in this case).\nThen the code becomes:\n\nparse_article_links = function(page) {\n  # Get article URLs\n  div = xml_find_all(page, \"//div[@id = 'tdi_113']\")\n  links = xml_find_all(div, \".//h3/a\")\n  urls = xml_attr(links, \"href\")\n\n  # Get next page URL\n  nav = xml_find_all(page, \"//div[contains(@class, 'page-nav')]\")\n  next_page = xml_find_all(nav, \".//a[contains(@aria-label, 'next-page')]\")\n  if (length(next_page) == 0) {\n    next_url = NA\n  } else {\n    next_url = xml_attr(next_page, \"href\")\n  }\n\n  # Using a list allows us to return two objects\n  list(urls = urls, next_url = next_url)\n}\n\nNow our function should work well even on the last page.\nIf we want to scrape links to all of the articles in the features section, we can use our function in a loop:\n# NOTE: This code is likely to take a while to run, and is meant more for\n# reading than for you to run and try out.\n\nurl = \"https://theaggie.org/category/features/\"\narticle_urls = list()\ni = 1\n\n# On the last page, the next URL will be `NA`.\nwhile (!is.na(url)) {\n  # Download and parse the page.\n  page = read_html(url)\n  result = parse_article_links(page)\n\n  # Save the article URLs in the `article_urls` list. The variable `i` is the\n  # page number.\n  article_urls[[i]] = result$url\n  i = i + 1\n\n  # Set the URL to the next URL.\n  url = result$next_url\n\n  # Sleep for 1/30th of a second so that we never make more than 30 requests\n  # per second.\n  Sys.sleep(1/30)\n}\nNow we’ve got the basis for a simple scraper.\n\n\n\n9.4.5 CSS Selectors\nCascading style sheets (CSS) is a language used to control the formatting of an XML or HTML document.\nCSS selectors are the CSS way to write paths to elements. CSS selectors are more concise than XPath, so many people prefer them. Even if you prefer CSS selectors, it’s good to know XPath because CSS selectors are less flexible.\nHere’s the basic syntax of CSS selectors:\n\n\n\nCSS\nDescription\n\n\n\n\na\ntags a\n\n\na &gt; b\ntags b directly beneath a\n\n\na b\ntags b anywhere beneath a\n\n\na, b\ntags a or b\n\n\n#hi\ntags with attribute id=\"hi\"\n\n\n.hi\ntags with attribute class that contains \"hi\"\n\n\n[foo=\"hi\"]\ntags with attribute foo=\"hi\"\n\n\n[foo*=\"hi\"]\ntags with attribute foo that contains \"hi\"\n\n\n\nIf you want to learn more, CSS Diner is an interactive tutorial that covers the entire CSS selector language.\nIn Firefox, you can get CSS selectors from the web developer tool. Right-click the tag you want a selector for and choose “Copy Unique Selector”. Beware that the selectors Firefox generates are often too specific to be useful for anything beyond the simplest web scrapers.\nThe rvest package uses CSS selectors by default. Behind the scenes, the package translates these into XPath and passes them to xml2.\nHere are a few examples of CSS selectors, using rvest’s html_nodes function:\n\nhtml = r\"(\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is the page title!&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;This is a header!&lt;/h1&gt;\n    &lt;p&gt;This is a paragraph.\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's a website!&lt;/a&gt;\n    &lt;/p&gt;\n    &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt; )\"\n\ndoc = read_html(html)\n\n# Get all p elements\nhtml_nodes(doc, \"p\")\n\n{xml_nodeset (2)}\n[1] &lt;p&gt;This is a paragraph.\\n      &lt;a href=\"http://www.r-project.org/\"&gt;Here's ...\n[2] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;\n\n# Get all links\nhtml_nodes(doc, \"a\")\n\n{xml_nodeset (1)}\n[1] &lt;a href=\"http://www.r-project.org/\"&gt;Here's a website!&lt;/a&gt;\n\n# Get all tags with id=\"hello\"\nhtml_nodes(doc, \"#hello\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"hello\"&gt;This is another paragraph.&lt;/p&gt;",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Getting Data from the Web</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html",
    "href": "chapters/10_strings-regex.html",
    "title": "10  Strings and Regular Expressions",
    "section": "",
    "text": "10.1 Printing Output\nThe message function prints a string in the R console. If you pass multiple arguments, they are concatenated:\nmessage(\"Hello\")\n\nHello\n\nmessage(\"Hello\", \"Nick\")\n\nHelloNick",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html#printing-output",
    "href": "chapters/10_strings-regex.html#printing-output",
    "title": "10  Strings and Regular Expressions",
    "section": "",
    "text": "Pitfall 1\n\n\n\nPrinting a string is different from returning a string. The message function only prints (and always returns NULL). For example:\n\nf = function() {\n  message(\"Hello\")\n}\n\nx = f()\n\nHello\n\nx\n\nNULL\n\n\nIf you just want to concatenate some strings (but not necessarily print them), use paste instead of message. The paste function returns a string. The str_c function in stringr (a package we’ll learn about later in this lesson) can also concatenate strings.\n\n\n\n\n\n\n\n\nPitfall 2\n\n\n\nRemember to print strings with the message function, not the print function. The print function prints R’s representation of an object, the same as if you had entered the object in the console without calling print.\nFor instance, print prints quotes around strings, whereas message does not:\n\nprint(\"Hello\")\n\n[1] \"Hello\"\n\nmessage(\"Hello\")\n\nHello",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html#escape-sequences",
    "href": "chapters/10_strings-regex.html#escape-sequences",
    "title": "10  Strings and Regular Expressions",
    "section": "10.2 Escape Sequences",
    "text": "10.2 Escape Sequences\nIn a string, an escape sequence or escape code consists of a backslash followed by one or more characters. Escape sequences make it possible to:\n\nWrite quotes or backslashes within a string\nWrite characters that don’t appear on your keyboard (for example, characters in a foreign language)\n\nFor example, the escape sequence \\n corresponds to the newline character. Notice that the message function translates \\n into a literal new line, whereas the print function doesn’t:\n\nx = \"Hello\\nNick\"\n\nmessage(x)\n\nHello\nNick\n\nprint(x)\n\n[1] \"Hello\\nNick\"\n\n\nAs another example, suppose we want to put a literal quote in a string. We can either enclose the string in the other kind of quotes, or escape the quotes in the string:\n\nx = 'She said, \"Hi\"'\n\nmessage(x)\n\nShe said, \"Hi\"\n\ny = \"She said, \\\"Hi\\\"\"\n\nmessage(y)\n\nShe said, \"Hi\"\n\n\nSince escape sequences begin with backslash, we also need to use an escape sequence to write a literal backslash. The escape sequence for a literal backslash is two backslashes:\n\nx = \"\\\\\"\n\nmessage(x)\n\n\\\n\n\n\n\n\n\n\n\nSee also\n\n\n\nThere’s a complete list of escape sequences for R in the ?Quotes help file. Other programming languages also use escape sequences, and many of them are the same as in R.\n\n\n\n10.2.1 Raw Strings\nA raw string is a string where escape sequences are turned off. Raw strings are especially useful for writing regular expressions, which we’ll do later in this lesson.\nRaw strings begin with r\" and an opening delimiter (, [, or {. Raw strings end with a matching closing delimiter and quote. For example:\n\nx = r\"(quotes \" and backslashes \\)\"\n\nmessage(x)\n\nquotes \" and backslashes \\\n\n\nRaw strings were added to R in version 4.0 (April 2020), and won’t work correctly in older versions.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html#character-encodings",
    "href": "chapters/10_strings-regex.html#character-encodings",
    "title": "10  Strings and Regular Expressions",
    "section": "10.3 Character Encodings",
    "text": "10.3 Character Encodings\nComputers store data as numbers. In order to store text on a computer, we have to agree on a character encoding, a system for mapping characters to numbers. For example, in ASCII, one of the most popular encodings in the United States, the character a maps to the number 97.\nMany different character encodings exist, and sharing text used to be an inconvenient process of asking or trying to guess the correct encoding. This was so inconvenient that in the 1980s, software engineers around the world united to create the Unicode standard. Unicode includes symbols for nearly all languages in use today, as well as emoji and many ancient languages (such as Egyptian hieroglyphs).\nUnicode maps characters to numbers, but unlike a character encoding, it doesn’t dictate how those numbers should be mapped to bytes (sequences of ones and zeroes). As a result, there are several different character encodings that support and are synonymous with Unicode. The most popular of these is UTF-8.\nIn R, we can write Unicode characters with the escape sequence \\U followed by the number for the character in base 16. For instance, the number for a in Unicode is 97 (the same as in ASCII). In base 16, 97 is 61. So we can write an a as:\n\nx = \"\\U61\" # or \"\\u61\"\n\nx\n\n[1] \"a\"\n\n\nUnicode escape sequences are usually only used for characters that are not easy to type. For example, the cat emoji is number 1f408 (in base 16) in Unicode. So the string \"\\U1f408\" is the cat emoji.\n\n\n\n\n\n\nNote\n\n\n\nBeing able to see printed Unicode characters also depends on whether the font your computer is using has a glyph (image representation) for that character. Many fonts are limited to a small number of languages. The NerdFont project patches fonts commonly used for programming so that they have better Unicode coverage. Using a font with good Unicode coverage is not essential, but it’s convenient if you expect to work with many different natural languages or love using emoji.\n\n\n\n10.3.1 Character Encodings in Text Files\nMost of the time, R will handle character encodings for you automatically. However, if you ever read or write a text file (including CSV and other formats) and the text looks like gibberish, it might be an encoding problem. This is especially true on Windows, the only modern operating system that does not (yet) use UTF-8 as the default encoding.\nEncoding problems when reading a file can usually be fixed by passing the encoding to the function doing the reading. For instance, the code to read a UTF-8 encoded CSV file on Windows is:\n\nread.csv(\"my_data.csv\", fileEncoding = \"UTF-8\")\n\nOther reader functions may use a different parameter to set the encoding, so always check the documentation. On computers where the native language is not set to English, it can also help to set R’s native language to English with Sys.setlocale(locale = \"English\").\nEncoding problems when writing a file are slightly more complicated to fix. See this blog post for thorough explanation.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html#stringr-and-the-tidyverse",
    "href": "chapters/10_strings-regex.html#stringr-and-the-tidyverse",
    "title": "10  Strings and Regular Expressions",
    "section": "10.4 stringr and the tidyverse",
    "text": "10.4 stringr and the tidyverse\n\n10.4.1 The Tidyverse\nThe Tidyverse is a popular collection of packages for doing data science in R. The packages are made by many of the same people that make RStudio. They provide alternatives to R’s built-in tools for:\n\nManipulating strings (package stringr)\nMaking visualizations (package ggplot2)\nReading files (package readr)\nManipulating data frames (packages dplyr, tidyr, tibble)\nAnd more\n\nThink of the Tidyverse as a different dialect of R. Sometimes the syntax is different, and sometimes ideas are easier or harder to express concisely. Whether to use base R or the Tidyverse is mostly subjective. As a result, the Tidyverse is somewhat polarizing in the R community. It’s useful to be literate in both, since both are popular.\nOne advantage of the Tidyverse is that the packages are usually well-documented. For example, there are documentation websites and cheat sheets for most Tidyverse packages.\n\n\n10.4.2 stringr\nThe rest of this lesson uses stringr, the Tidyverse package for string processing. R also has built-in functions for string processing. The main advantage of stringr is that all of the functions use a common set of parameters, so they’re easier to learn and remember.\nThe first time you use stringr, you’ll have to install it with install.packages (the same as any other package). Then you can load the package with the library function:\n\n# install.packages(\"stringr\")\nlibrary(\"stringr\")\n\nThe typical syntax of a stringr function is:\nstr_NAME(string, pattern, ...)\nWhere:\n\nNAME describes what the function does\nstring is the string to search within or transform\npattern is the pattern to search for\n... is additional, function-specific arguments\n\nFor example, the str_detect function detects whether the pattern appears within the string:\n\nstr_detect(\"hello\", \"el\")\n\n[1] TRUE\n\nstr_detect(\"hello\", \"ol\")\n\n[1] FALSE\n\n\nMost of the stringr functions are vectorized:\n\nstr_detect(c(\"hello\", \"goodbye\", \"lo\"), \"lo\")\n\n[1]  TRUE FALSE  TRUE\n\n\nThere are a lot of stringr functions. The remainder of this lesson focuses on three that are especially important, as well as some of their variants:\n\nstr_split_fixed\nstr_replace\nstr_match\n\n\n\n\n\n\n\nSee also\n\n\n\nYou can find a complete list of stringr functions with examples in the documentation or cheat sheet.\n\n\n\n10.4.2.1 Splitting Strings\nThe str_split function splits the string at each position that matches the pattern. The characters that match are thrown away.\nFor example, suppose we want to split a sentence into words. Since there’s a space between each word, we can use a space as the pattern:\n\nx = \"The students in this class are great!\"\n\nresult = str_split(x, \" \")\nresult\n\n[[1]]\n[1] \"The\"      \"students\" \"in\"       \"this\"     \"class\"    \"are\"      \"great!\"  \n\n\nThe str_split function always returns a list with one element for each input string. Here the list only has one element because x only has one element. We can get the first element with:\n\nresult[[1]]\n\n[1] \"The\"      \"students\" \"in\"       \"this\"     \"class\"    \"are\"      \"great!\"  \n\n\nWe have to use the double square bracket [[ operator here because x is a list (for a vector, we could use the single square bracket operator instead). Notice that in the printout for result, R gives us a hint that we should use [[ by printing [[1]].\nTo see why the function returns a list, consider what happens if we try to split two different sentences at once:\n\nx = c(x, \"Are you listening?\")\n\nresult = str_split(x, \" \")\nresult[[1]]\n\n[1] \"The\"      \"students\" \"in\"       \"this\"     \"class\"    \"are\"      \"great!\"  \n\nresult[[2]]\n\n[1] \"Are\"        \"you\"        \"listening?\"\n\n\nEach sentence has a different number of words, so the vectors in the result have different lengths. So a list is the only way to store both.\nThe str_split_fixed function is almost the same as str_split, but takes a third argument for the maximum number of splits to make. Because the number of splits is fixed, the function can return the result in a matrix instead of a list. For example:\n\nstr_split_fixed(x, \" \", 3)\n\n     [,1]  [,2]       [,3]                      \n[1,] \"The\" \"students\" \"in this class are great!\"\n[2,] \"Are\" \"you\"      \"listening?\"              \n\n\nThe str_split_fixed function is often more convenient than str_split because the nth piece of each input string is just the nth column of the result.\nFor example, suppose we want to get the area code from some phone numbers:\n\nphones = c(\"717-555-3421\", \"629-555-8902\", \"903-555-6781\")\nresult = str_split_fixed(phones, \"-\", 3)\n\nresult[, 1]\n\n[1] \"717\" \"629\" \"903\"\n\n\n\n\n10.4.2.2 Replacing Parts of Strings\nThe str_replace function replaces the pattern the first time it appears in the string. The replacement goes in the third argument.\nFor instance, suppose we want to change the word \"dog\" to \"cat\":\n\nx = c(\"dogs are great, dogs are fun\", \"dogs are fluffy\")\nstr_replace(x, \"dog\", \"cat\")\n\n[1] \"cats are great, dogs are fun\" \"cats are fluffy\"             \n\n\nThe str_replace_all function replaces the pattern every time it appears in the string:\n\nstr_replace_all(x, \"dog\", \"cat\")\n\n[1] \"cats are great, cats are fun\" \"cats are fluffy\"             \n\n\nWe can also use the str_replace and str_replace_all functions to delete part of a string by setting the replacement to the empty string \"\".\nFor example, suppose we want to delete the comma:\n\nstr_replace(x, \",\", \"\")\n\n[1] \"dogs are great dogs are fun\" \"dogs are fluffy\"            \n\n\nIn general, stringr functions with the _all suffix affect all matches. Functions without _all only affect the first match.\nWe’ll learn about str_match at the end of the next section.",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/10_strings-regex.html#regular-expressions",
    "href": "chapters/10_strings-regex.html#regular-expressions",
    "title": "10  Strings and Regular Expressions",
    "section": "10.5 Regular Expressions",
    "text": "10.5 Regular Expressions\nThe stringr functions (including the ones we just learned) use a special language called regular expressions or regex for the pattern. The regular expressions language is also used in many other programming languages besides R.\nA regular expression can describe a complicated pattern in just a few characters, because some characters, called metacharacters, have special meanings. Letters and numbers are never metacharacters. They’re always literal.\nHere are a few examples of metacharacters (we’ll look at examples in the subsequent sections):\n\n\n\nMetacharacter\nMeaning\n\n\n\n\n.\nany single character (wildcard)\n\n\n\\\nescape character (in both R and regex)\n\n\n^\nbeginning of string\n\n\n$\nend of string\n\n\n[ab]\n'a' or 'b'\n\n\n[^ab]\nany character except 'a' or 'b'\n\n\n?\nprevious character appears 0 or 1 times\n\n\n*\nprevious character appears 0 or more times\n\n\n+\nprevious character appears 1 or more times\n\n\n()\nmake a group\n\n\n\nMore metacharacters are listed on the stringr cheat sheet, or in ?regex.\nThe str_view function is especially helpful for testing regular expressions. It opens a browser window with the first match in the string highlighted. We’ll use it in the subsequent regex examples.\nThe RegExr website is also helpful for testing regular expressions; it provides an interactive interface where you can write regular expressions and see where they match a string.\n\n10.5.1 The Wildcard\nThe regex wildcard character is . and matches any single character.\nFor example:\n\nx = \"dog\"\nstr_view(x, \"d.g\")\n\n[1] │ &lt;dog&gt;\n\n\nBy default, regex searches from left to right:\n\nstr_view(x, \".\")\n\n[1] │ &lt;d&gt;&lt;o&gt;&lt;g&gt;\n\n\n\n\n10.5.2 Escape Sequences\nLike R, regular expressions can contain escape sequences that begin with a backslash. These are computed separately and after R escape sequences. The main use for escape sequences in regex is to turn a metacharacter into a literal character.\nFor example, suppose we want to match a literal dot .. The regex for a literal dot is \\.. Since backslashes in R strings have to be escaped, the R string for this regex is \"\\\\.. Then the regex works:\n\nstr_view(\"this.string\", \"\\\\.\")\n\n[1] │ this&lt;.&gt;string\n\n\nThe double backslash can be confusing, and it gets worse if we want to match a literal backslash. We have to escape the backslash in the regex (because backslash is the regex escape character) and then also have to escape the backslashes in R (because backslash is also the R escape character). So to match a single literal backslash in R, the code is:\n\nstr_view(\"this\\\\that\", \"\\\\\\\\\")\n\n[1] │ this&lt;\\&gt;that\n\n\nRaw strings are helpful here, because they make the backslash literal in R strings (but still not in regex). We can use raw strings to write the above as:\n\nstr_view(r\"(this\\that)\", r\"(\\\\)\")\n\n[1] │ this&lt;\\&gt;that\n\n\nYou can turn off regular expressions entirely in stringr with the fixed function:\n\nstr_view(x, fixed(\".\"))\n\nIt’s good to turn off regular expressions whenever you don’t need them, both to avoid mistakes and because they take longer to compute.\n\n\n10.5.3 Anchors\nBy default, a regex will match anywhere in the string. If you want to force a match at specific place, use an anchor.\nThe beginning of string anchor is ^. It marks the beginning of the string, but doesn’t count as a character in the match.\nFor example, suppose we want to match an a at the beginning of the string:\n\nx = c(\"abc\", \"cab\")\n\nstr_view(x, \"a\")\n\n[1] │ &lt;a&gt;bc\n[2] │ c&lt;a&gt;b\n\nstr_view(x, \"^a\")\n\n[1] │ &lt;a&gt;bc\n\n\nIt doesn’t make sense to put characters before ^, since no characters can come before the beginning of the string.\nLikewise, the end of string anchor is $. It marks the end of the string, but doesn’t count as a character in the match.\n\n\n10.5.4 Character Classes\nIn regex, square brackets [ ] create a character class. A character class counts as one character, but that character can be any of the characters inside the square brackets. The square brackets themselves don’t count as characters in the match.\nFor example, suppose we want to match a c followed by either a or t:\n\nx = c(\"ca\", \"ct\", \"cat\", \"cta\")\n\nstr_view(x, \"c[ta]\")\n\n[1] │ &lt;ca&gt;\n[2] │ &lt;ct&gt;\n[3] │ &lt;ca&gt;t\n[4] │ &lt;ct&gt;a\n\n\nYou can use a dash - in a character class to create a range. For example, to match letters p through z:\n\nstr_view(x, \"c[p-z]\")\n\n[2] │ &lt;ct&gt;\n[4] │ &lt;ct&gt;a\n\n\nRanges also work with numbers and capital letters. To match a literal dash, place the dash at the end of the character class (instead of between two other characters), as in [abc-].\nMost metacharacters are literal when inside a character class. For example, [.] matches a literal dot.\nA hat ^ at the beginning of the character class negates the class. So for example, [^abc] matches any one character except for a, b, or c:\n\nstr_view(\"abcdef\", \"[^abc]\")\n\n[1] │ abc&lt;d&gt;&lt;e&gt;&lt;f&gt;\n\n\n\n\n10.5.5 Quantifiers\nQuantifiers are metacharacters that affect how many times the preceding character must appear in a match. The quantifier itself doesn’t count as a character in the match.\nFor example, the ? quantifier means the preceding character can appear 0 or 1 times. In other words, ? makes the preceding character optional.\nFor example:\n\nx = c(\"abc\", \"ab\", \"ac\", \"abbc\")\n\nstr_view(x, \"ab?c\")\n\n[1] │ &lt;abc&gt;\n[3] │ &lt;ac&gt;\n\n\nThe * quantifier means the preceding character can appear 0 or more times. In other words, * means the preceding character can appear any number of times or not at all.\n\nstr_view(x, \"ab*c\")\n\n[1] │ &lt;abc&gt;\n[3] │ &lt;ac&gt;\n[4] │ &lt;abbc&gt;\n\n\nThe + quantifier means the preceding character must appear 1 or more times.\nQuantifiers are greedy, meaning they always match as many characters as possible.\n\n\n10.5.6 Groups\nIn regex, parentheses create a group. Groups can be affected by quantifiers, making it possible to repeat a pattern (rather than just a character). The parentheses themselves don’t count as characters in the match.\nFor example:\n\nx = c(\"cats, dogs, and frogs\", \"cats and frogs\")\n\nstr_view(x, \"cats(, dogs,)? and frogs\")\n\n[1] │ &lt;cats, dogs, and frogs&gt;\n[2] │ &lt;cats and frogs&gt;\n\n\n\n\n10.5.7 Extracting Matches\nGroups are especially useful with the stringr functions str_match and str_match_all.\nThe str_match function extracts the overall match to the pattern, as well as the match to each group. So you can use str_match to split a string in more complicated ways than str_split, or to extract specific pieces of a string.\nFor example, suppose we want to split an email address:\n\nstr_match(\"naulle@ucdavis.edu\", \"([^@]+)@(.+)[.](.+)\")\n\n     [,1]                 [,2]     [,3]      [,4] \n[1,] \"naulle@ucdavis.edu\" \"naulle\" \"ucdavis\" \"edu\"",
    "crumbs": [
      "Fundamentals",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings and Regular Expressions</span>"
    ]
  },
  {
    "objectID": "chapters/11_optical-character-recognition.html",
    "href": "chapters/11_optical-character-recognition.html",
    "title": "11  Optical Character Recognition",
    "section": "",
    "text": "11.1 What is Optical Character Recognition?\nMuch of the data we’ve used in the course thus far has been born-digital. That is, we’ve used data that originates from a digital source and does not exist elsewhere in some other form. Think back, for example, to the lecture on strings in R (Chapter 10): your homework required you to type text directly into RStudio, manipulate it, and print it to screen. But millions, even billions, of data-rich documents do not originate from digital sources. The United States Census, for example, dates back to 1790; we still have these records and could go study them to get a sense of what the population was like hundreds of years ago. Likewise, printing and publishing far precedes the advent of computers; much of the literary record is still bound up between the covers books or stowed away in archives. Computers, however, can’t read the way we read, so if we wanted to use digital methods to analyze such materials, we’d need to convert them into a computationally tractable form. How do we do so?\nOne way would be to transcribe documents by hand, either by typing out plain text versions with word processing software or by using other data entry methods like keypunching to record the information those documents contain. Amazon’s Mechanical Turk service is an example of this kind of data entry. It’s also worth noting that, for much of the history of computing, data entry was highly gendered and considered to be “dumb”, secretarial work that young women would perform. Much of the divisions between “cool” coding and computational grunt work that, in a broad, cultural sense, continue to inform how we think about programming, and indeed who gets to program, stem from such perceptions. In spite of (or perhaps because of) such perceptions, huge amounts of data owe their existence to manual data entry. That said, the process itself is expensive, time consuming, error-prone, and, well, dull.\nOptical character recognition, or OCR, is an attempt to offload the work of digitization onto computers. Speaking in a general sense, this process ingests images of print pages (such as those available on Google Books or HathiTrust), applies various preprocessing procedures to those images to make them a bit easier to read, and then scans through them, trying to match the features it finds with a “vocabulary” of text elements it keeps as a point of reference. When it makes a match, OCR records a character and enters it into a text buffer (a temporary data store). Oftentimes this buffer also includes formatting data for spaces, new lines, paragraphs, and so on. When OCR is finished, it outputs its matches as a data object, which you can then further manipulate or analyze using other code.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Optical Character Recognition</span>"
    ]
  },
  {
    "objectID": "chapters/11_optical-character-recognition.html#loading-page-images",
    "href": "chapters/11_optical-character-recognition.html#loading-page-images",
    "title": "11  Optical Character Recognition",
    "section": "11.2 Loading Page Images",
    "text": "11.2 Loading Page Images\nOCR “reads” by tracking pixel variations across page images. This means every page you want to digitize must be converted into an image format. For the purposes of introducing you to OCR, we won’t go through the process of creating these images from scratch; instead, we’ll be using ready-made examples. The most common page image formats you’ll encounter are PDF and PNG. They’re lightweight, portable, and usually retain the image quality OCR software needs to find text.\nThe pdftools package is good for working with these files:\n\n# install.packages(\"pdftools\")\nlibrary(\"pdftools\")\n\nOnce you’ve downloaded/installed it, you can load a PDF into RStudio from your computer by entering its path as a string and assigning that string to a variable, like so:\n\npdf &lt;- \"data/pdf_sample.pdf\"\n\nNote that we haven’t used a special reater function, like read.csv or readRDS. The pdftools package will grab this file from its location and load it properly when you run a process on it.\n\n\n\n\n\n\nNote\n\n\n\nYou can also just write the string out in whatever function you want to call, but we’ll keep our pdf variable for the sake of clarity.\n\n\nThe same method works with web addresses. We’ll be using web material. First, write out an address and assign it to a variable.\npdf &lt;- \"https://datalab.ucdavis.edu/adventures-in-datascience/pdf_sample.pdf\"\nSome PDF files will have text data already encoded into them. This is especially the case if someone made a file with word processing software (like when you write a paper in Word and email a PDF to your TA or professor). You can check whether a PDF has text data with the pdf_text function. Assign the function’s output to a variable and print it to screen with message, like so:\n\ntext_data &lt;- pdf_text(pdf)\nmessage(text_data)\n\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\n\n\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\n\n                                             The quick brown fox jumps over the lazy dog.\n                                             The quick brown fox jumps over the lazy dog.\n                                             The quick brown fox jumps over the lazy dog.\n                                             The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\n\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog.\n\n                                               The quick brown fox jumps over the lazy dog.\n                                               The quick brown fox jumps over the lazy dog.\n                                               The quick brown fox jumps over the lazy dog.\n                                               The quick brown fox jumps over the lazy dog.\n\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\nThe quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\n\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n                       The quick brown fox jumps over the lazy dog.\n\n\nNotice the printout recreates the original formatting from the PDF. If you were to use the print function on the text output, you’d see all the line breaks and spaces pdf_text created to match its output with the file. This re-creation would be even more apparent if you were to save the output to a new file with write. Doing so would produce a close, plain text approximation of the original PDF.\nYou can also process multi-page PDF files with pdf_text. It can transcribe whole books and will keep them in a single text buffer, which you can then assign to a variable or save to a file. Keep in mind, however, that if your PDF files have headers, footers, page numbers, chapter breaks, or other such paratextual information, pdf_text will include these in its output.\nIf, when you run pdf_text, you find that your file already contains text data, you’re set! There’s no need to perform OCR and you can immediately start working with your data. However, if you run the function and find that it outputs a blank character string, you’ll need to OCR it. The next section shows you how.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Optical Character Recognition</span>"
    ]
  },
  {
    "objectID": "chapters/11_optical-character-recognition.html#running-ocr",
    "href": "chapters/11_optical-character-recognition.html#running-ocr",
    "title": "11  Optical Character Recognition",
    "section": "11.3 Running OCR",
    "text": "11.3 Running OCR\nFirst, you’ll need to download/install another package, tesseract, which complements pdftools. The latter only loads/reads PDFs, whereas tesseract actually performs OCR. Download/install tesseract:\n\n# install.packages(\"tesseract\")\nlibrary(\"tesseract\")\n\nLet’s use a different PDF to try out tesseract:\nnew_pdf &lt;- \"https://jeroen.github.io/images/ocrscan.pdf\"\nTo run OCR on this PDF, use the following:\n\nocr_output &lt;- ocr(new_pdf)\n\nPrint the output to screen with message and see if the process worked:\n\nmessage(ocr_output)\n\nTHE SLEREXE COMPANY LIMITED\nSAPORS LANE - BOOLE - DORSET - BH 25 8ER\ne sous (4513) 617 - Tk 12345\nOur Ref. 350/BIC/EAC 186 Janvary, 1972.\nDe. PN, Cundall,\nKining Surveys Lid.,\nHolroyd Road,\nReading,\nBerks.\nDear Pece,\n\nPernit ne to introduce you to the facility of facsinile\ntransmission.\n\nIn facainile a photocell is coused to perforn a raster scan over\nthe subject copy. The varistions of princ density on the docunent\ncause the photecell o generate an analogous electrical video signal.\nThis signal is used to mdulate a carrier, vhich is cransmitted to o\ncemote destination over & radio or cable commnications link.\n\n¢ the remote cerminal, demodulation reconstructs the video\nsignal, which is used to modulate the density of print produced by @\nprinting device. Tnis device is scanning in 4 raster scan synchronised\nUich that at the cransmitring terminal. As & result, a facsimile\ncopy of the subject document is produced.\n\nProbably you have uees for this facility in your organisation.\n\nYours sincerely,\nP.J. cross\nGroup Leader - Facsinile Research\n\n\nVoila! You’ve just digitized text. The formatting is a little off, but things look good overall. And most importantly, it looks like everything has been transcribed correctly.\nAs you ran this process, you might’ve noticed that a new PNG file briefly appeared on your computer. This is because tesseract converts the PDF file to PNG file as part of its behind-the-scenes pre-processing work and silently deletes the PNG file when it finishes running. If you have a collection of PDF files that you’d like to OCR, it can sometimes be faster and less memory intensive to convert them all to PNG files first. You can perform this conversion like so:\n\npng &lt;- pdf_convert(\n  new_pdf, format = \"png\", filenames = \"images/ch11/png_example.png\"\n)\n\nWarning in sprintf(filenames, pages, format): 2 arguments not used by format\n'images/ch11/png_example.png'\n\n\nConverting page 1 to images/ch11/png_example.png... done!\n\n\nIn addition to returning the a PNG object in your R session, the pdf_convert function will also save the file in your working directory. You could, for example, use a for-loop and a vector of paths to PDF files to convert all of them to PNG files. Since pdf_convert saves them to disk, they can be stored until you’re ready to OCR them.\npdfs &lt;- c(\"list.pdf\", \"of.pdf\", \"files.pdf\", \"to.pdf\", \"convert.pdf\")\noutfiles &lt;- c(\"list.png\", \"of.png\", \"files.png\", \"to.png\", \"convert.png\")\n\nfor (i in 1:length(pdfs)) {\n  pdf_convert(pdfs[i], format=\"png\", filenames=outfiles[i])\n}\nThe ocr function works with a number of different file types (typically images). For instance, it accepts PNGs as well as PDFs:\n\npng_ocr_output &lt;- ocr(png)",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Optical Character Recognition</span>"
    ]
  },
  {
    "objectID": "chapters/11_optical-character-recognition.html#accuracy",
    "href": "chapters/11_optical-character-recognition.html#accuracy",
    "title": "11  Optical Character Recognition",
    "section": "11.4 Accuracy",
    "text": "11.4 Accuracy\nIf you use message to print the output from OCRing the PNG file in the example above, you might notice that the text is messier than it was when we used pdf_text_ocr:\n\nmessage(png_ocr_output)\n\nTHE SLEREXE COMPANY LIMITED\nSAPORS LANE - BOOLE - DORSET - BH 25 8ER\ne sous (4513) 617 - Tk 12345\nOur Ref. 350/BIC/EAC 186 Janvary, 1972.\nDe. PN, Cundall,\nKining Surveys Lid.,\nHolroyd Road,\nReading,\nBerks.\nDear Pece,\n\nPernit ne to introduce you to the facility of facsinile\ntransmission.\n\nIn facainile a photocell is coused to perforn a raster scan over\nthe subject copy. The varistions of princ density on the docunent\ncause the photecell o generate an analogous electrical video signal.\nThis signal is used to mdulate a carrier, vhich is cransmitted to o\ncemote destination over & radio or cable commnications link.\n\n¢ the remote cerminal, demodulation reconstructs the video\nsignal, which is used to modulate the density of print produced by @\nprinting device. Tnis device is scanning in 4 raster scan synchronised\nUich that at the cransmitring terminal. As & result, a facsimile\ncopy of the subject document is produced.\n\nProbably you have uees for this facility in your organisation.\n\nYours sincerely,\nP.J. cross\nGroup Leader - Facsinile Research\n\n\nThis doesn’t have to do with the PNG file format per se but rather with the way we created our file. If you open it, you’ll see that it’s quite blurry, which has made it harder for ocr to match the text it represents:\n\n\n\n\n\n\nFigure 11.1\n\n\n\nThis blurriness is because pdf_convert defaults to 72 dots per inch (DPI). DPI is a measure of how many pixels, or dots, a digital image file uses to represent an inch of the image. DPI quantifies resolution and originated in inkjet printing. More pixels means higher image resolution, though this comes with a trade off: images with a high DPI are also bigger and take up more space on your computer. Usually, a DPI of 150 is sufficient for most OCR jobs, especially if your documents were printed with technologies like typewriters, dot matrix printers, and so on, and if they feature fairly legible typefaces (Times New Roman, for example). A DPI of 300, however, is ideal. You can set the DPI in pdf_convert by adding a dpi argument in the call:\n\nhi_res_png &lt;- pdf_convert(\n  new_pdf, format=\"png\", dpi=150,\n  filenames=\"images/ch11/hi_res_png_example.png\"\n)\n\nWarning in sprintf(filenames, pages, format): 2 arguments not used by format\n'images/ch11/hi_res_png_example.png'\n\n\nConverting page 1 to images/ch11/hi_res_png_example.png... done!\n\n\nAnother function, ocr_data, outputs a data frame that contains all of the words tesseract found when it scanned through your image, along with a column of confidence scores. These scores, which range from 0-100, provide valuable information about how well the OCR process has performed, which in turn may tell you whether you need to modify your PDF or PNG files further before OCRing them (more on this below). Generally, you can trust scores of 93 and above.\nTo get confidence scores for an OCR job, call ocr_data and subset the confidence column, like so:\n\nocr_data &lt;- ocr_data(hi_res_png)\nconfidence_scores &lt;- ocr_data$confidence\nconfidence_scores\n\n  [1] 92.00555 92.16185 91.26955 91.26955 93.30071 92.80251 93.25327 71.22106\n  [9] 93.01385 87.86584 89.25087 89.25087 39.46595 39.46595 96.18760 92.64400\n [17] 88.31395 96.62357 91.38167 88.73389 88.73389 87.54987 87.54987 92.04705\n [25] 89.52077 91.29449 90.80710 92.46021 92.75455 89.72379 92.27145 92.01097\n [33] 91.00894 89.22992 91.89604 91.02854 92.30912 90.34227 90.34227 91.70280\n [41] 92.35736 91.17986 91.17986 92.30919 89.62785 82.76822 40.42221 91.66215\n [49] 91.92680 93.24316 90.77785 90.77785 91.95331 91.95331 92.47021 93.19882\n [57] 91.73550 91.52353 91.88087 61.49971 91.50322 92.83280 88.38924 88.38924\n [65] 92.01638 92.67615 91.98049 43.38534 90.48783 92.81612 92.41699 91.47611\n [73] 91.84003 91.84003 92.20630 86.01997 91.97392 92.16437 91.10802 92.11120\n [81] 89.69808 92.23833 92.46779 91.11872 91.73578 91.94142 91.98083 92.07896\n [89] 92.07896 92.64109 91.36734 91.36734 91.05901 92.81266 92.59015 91.31464\n [97] 90.42278 90.42278 92.18396 92.17403 92.28313 91.59138 90.33145 92.01377\n[105] 92.01377 91.19365 91.39406 91.58421 79.49812 91.90497 91.70367 91.50892\n[113] 92.86395 93.07679 91.78714 92.10359 92.12737 91.94938 89.91416 91.05914\n[121] 92.03944 93.12405 93.26999 93.26999 92.23213 90.81768 70.74520 92.39217\n[129] 89.55022 86.20355 89.34053 88.06285 92.31555 93.13564 92.01375 91.13263\n[137] 91.13263 92.17674 92.80893 91.49842 90.36536 90.36536 91.31169 92.65086\n[145] 92.95564 91.97475 91.96663 91.11794 91.92394 91.60635 91.32370 91.32370\n[153] 91.62907 93.08089 92.95688 92.60538 92.07363 91.69480 92.84332 92.31062\n[161] 91.96275 91.96792 91.56029 91.68050 92.09031 84.39836 88.10213 92.19061\n[169] 92.44096 93.29742 92.41998 91.57234 84.95621 85.53573 85.33029 91.52122\n[177] 96.01897 88.61853 82.43198 89.51816 77.73746 76.97222 71.24612 58.29185\n[185] 66.72427 46.87411\n\n\nThe mean is a good indicator of the overall OCR quality:\n\nconfidence_mean &lt;- mean(confidence_scores)\nconfidence_mean\n\n[1] 88.93843\n\n\nLooks pretty good, though there were a few low scores that dragged the score down a bit. Let’s look at the median:\n\nconfidence_median &lt;- median(confidence_scores)\nconfidence_median\n\n[1] 91.68765\n\n\nWe can work with that!\nIf we want to check our output a bit more closely, we can do two things. First, we can look directly at ocr_data and compare, row by row, a given word and its confidence score.\n\nhead(ocr_data, 25)\n\n          word confidence              bbox\n1       SAPORS   92.00555   422,194,497,208\n2         LANE   92.16185   508,194,560,208\n3            -   91.26955   570,203,575,205\n4        BOOLE   91.26955   585,193,651,208\n5            -   93.30071   661,202,666,205\n6       DORSET   92.80251   676,193,755,208\n7            -   93.25327   764,203,769,205\n8         BH25   71.22106   780,193,831,208\n9            8   93.01385   842,193,850,208\n10          ER   87.86584   856,194,883,208\n11   TELEPHONE   89.25087   449,232,534,243\n12       BOOLE   89.25087   544,232,589,243\n13        (945   39.46595   600,229,634,246\n14         13)   39.46595   640,229,664,246\n15       51617   96.18760   675,229,719,244\n16           -   92.64400   730,237,735,240\n17       TELEX   88.31395   746,232,792,243\n18      123456   96.62357   804,228,857,244\n19         Our   91.38167   211,392,246,408\n20        Ref.   88.73389   261,391,306,407\n21 350/PJC/EAC   88.73389   325,389,459,409\n22        18th   87.54987   863,389,910,405\n23    January,   87.54987  924,389,1020,408\n24       1972.   92.04705 1038,388,1095,405\n25         Dr.   89.52077   212,492,244,508\n\n\nThat’s a lot of information though. Something a little more sparse might be better. We can use base R’s table function to count the number of times unique words appear in the OCR data. We do this with the word column in our ocr_data variable from above:\n\nocr_vocabulary &lt;- table(ocr_data$word)\nocr_vocabulary &lt;- as.data.frame(ocr_vocabulary)\n\nLet’s look at the first 30 words:\n\nhead(ocr_vocabulary, 30)\n\n             Var1 Freq\n1               -    5\n2               .    1\n3            (945    1\n4               1    1\n5          123456    1\n6             13)    1\n7            18th    1\n8           1972.    1\n9            2038    1\n10    350/PJC/EAC    1\n11          51617    1\n12              8    1\n13             80    1\n14              a    9\n15             an    1\n16      analogous    1\n17             As    1\n18             at    1\n19             At    1\n20         Berks.    1\n21           BH25    1\n22          BOOLE    2\n23             by    1\n24          cable    1\n25       carrier,    1\n26          cause    1\n27         caused    1\n28 communications    1\n29           copy    1\n30          copy.    1\n\n\nThis representation makes it easy to spot errors like discrepancies in spelling. We could correct those either manually or with string matching. One way to further examine this table is to look for words that only appear once or twice in the output; among such entries you’ll often find misspellings. The table does, however, have its limitations. Looking at this data can quickly become overwhelming if you send in too much text. Additionally, notice that punctuation “sticks” to words and that uppercase and lowercase variants of words are counted separately, rather than together. These quirks are fine, useful even, if we’re just spot-checking for errors, but we’d need to further clean this data if we wanted to use it in computational text analysis. A later lecture will discuss other methods that we can use to clean text.\nWhen working in a data-forensic mode with page images, it’s a good idea to pull a few files at random and run them through ocr_data to see what you’re working with. OCR accuracy is often wholly reliant on the quality of the page images, and most of the work that goes into digitizing text involves properly preparing those images for OCR. Adjustments include making sure images are converted to black and white, increasing image contrast and brightness, increasing DPI, and rotating images so that their text is more or less horizontal. The tesseract package performs some of these tasks itself, but you can also do them ahead of time and often you’ll have more control over quality this way. The tesseract documentation goes into detail about what you can do to improve accuracy before even opening R; we can’t cover this in depth, but keep the resource in mind as you work with this type of material. And remember: the only way to completely trust your accuracy is to go through the OCR output yourself. It’s a very common thing to have to make small tweaks to output. In this sense, we haven’t quite left the era of hand transcription.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Optical Character Recognition</span>"
    ]
  },
  {
    "objectID": "chapters/11_optical-character-recognition.html#unreadable-text",
    "href": "chapters/11_optical-character-recognition.html#unreadable-text",
    "title": "11  Optical Character Recognition",
    "section": "11.5 Unreadable Text",
    "text": "11.5 Unreadable Text\nAll that said, these various strategies for improving accuracy will only get you so far if your page images are composed in a way OCR just can’t read. OCR systems contain a lot of in-built assumptions about what “normal” text is, and they are incredibly brittle when they encounter text that diverges from that norm. Early systems, for example, required documents to be printed with special, machine-readable typefaces; texts that contained anything other than this design couldn’t be read. Now, OCR is much better at handling a variety of text styling, but systems still struggle with old print materials like blackletter.\n\n\n\n\n\n\nFigure 11.2\n\n\n\nRunning:\n\nballad &lt;- \"https://ebba.english.ucsb.edu/images/cache/hunt_1_18305_2448x2448.jpg\"\nballad_out &lt;- ocr(ballad)\n\nProduces:\n\nmessage(ballad_out)\n\n- @€ QADdifcriptionof Roxtons faleehod ’\nafPozkie byze, and of hig fatall favewel.\nfLhe fatal fineof Lraitours loes ;\n% 4Bp Fufice due, deferupngfoe. - 1\nT Iate (alas) the great bntrath  Ehe Crane wwoldefipebptothe punte,  Roto, bis futerpug long (be fure) o\nDf Traitours, hoto (£ fped g heardit once of olve s _ @diplipay bis foes atlaf: : ,\nT boliff to knoin, Hal berez.wae Sndwoith the Lpng of bpaoes did frine Pig mercpe moued once atwap, |\nPotv late allegeance fev, 1Bp Fame, 3 beardittolves = Pe Hall them &uigbt out caff i\n« 3f Reucrsrage agamnit the Hea. GAnddofvoeihe welve not fal benoy aaith fentence infk fo2 theit butruth, .\nAnd ffwell Wwith oddeine rapnes 1But higher Epld nipMOUAL 2 and bacakpng of his fwpll s :\nPotu glao are they to fall agapne, ST il pait her teach((aithoroevepote) £Lhe fruits oftheir fedicfous (s, :\nAndtracetheic onted traine? Shame madea backevecour SChebarnes of cavth thail fpll.\n8l 36 five by fozce Wwolde fozge the fall 3 touch no Grmes herefn atall, TCheir foules God wot foze clogd 1 crime\nDf any fumptuoule place, AButfhetna fable fopfes __ Qnd theirpofteritie\nB 36 water flods byd bim leaueof, T hofemozall fence doth repr 4Befpotted foze With theirabule,\ns flames he wyll difgrace, DEclpmers bye theguple. Ano fEand by theit follie.\n| 3t Goo command the Wwpides to ceafe, Tuho buploes a houle of many 5 heiclinpngs left theiv namea hante,\ni is blaffes ave lapd full lotu ¢ anbdlaith not ground Wogkr heir dedes ith poplon fped: :\ni 3fBod command the feas focalme, 4Butdoth ertotethe groundk i3&gt;  Theivdeathesawage foz wantof grace §\n: 2Chey wyll notrage 02 flolu. Pis bufldpng can notdure. SCheir honours quite is dead.\n4 Gl thinges at Gods commandemet be, @ TWhofekes furmifingtodilp SCheir flefh tofedethe kptes and crolues |\n3f betheir fateregarde s : a Ruler fentbp GOD 2 ACheir arnies a mase foa men s b\nHl andnoman liues whole veffinie 35 fubiect fure, Deuoide of grace. Cheir guerdon as examples are ¥\n1By hum i8 bupzeparde. Checauleof his otonerod. 2Co dafh dolte Dunces den.\n{15t when a man foxfakes theip, - Q byve that Wyl hernefEdefple SChaotn bp pout fouts pou Auggifh foxte  §\n8 - anorowlesin allowing Wwaues 1By vight Hould lofe a wyngs 3 oumumming malkyng route : -;\nAnd of bis boluntarfe wyll, Gud then is e no fying fo Wi CErtoll your erclamations bp, g\n! Bis onite god hap depraues 1But ot agother thyng. ABaals chapletnes,champions ffoute,\ni Wow fal hehopeto lcape the gulfe 2 anbhe that lofeth all at games, Datke fute fo2 pardons, papilts braue,\n: Bot Hal be thinke todeale 2 D3 fpendes infoiole ercefle: Foztraitours indulgence\n. 1o Mal bis fanfie baing him lound Qnbhopes by hapsto bealehisharme, . fend ot fome purgatosic (craps, i\n£ 4T o @afties MHoze Wwith laple 2 Mufk vzinke of deare piffrefle, Some WBulls tuith Peter pence.\n; Botv hall is fratght in fine (uccede 2 o fpeatie of bapdles fovelirapne D fwavime of D2ones, how dare pefipl |\n4 Qlas what Hall hegapne 2 Trhis wylfull wapardereive $ Twith labourpng Wees contend\n| wubatfeare by oams Do matke bimquake hey cave not foz the boke of Gov, Pou fonght fo2honie from thehiues, v\ni Hotw ofte [ubleceto papne 2 1o P2inces, men bntrue. 1B ut gall you foundinend. b\not funozie times in Dangers ven o cuntepe, caufers of much woe, SChefe tafpes oo Wwafk, their fings beont &\n33 thootone theman bnivple 2 ﬁts'i‘faitbfull frdendes, afall: heir fpight topll nofanaple: i\n8l @uhoclimes Withouten bolde ot bye, b ftheiv otone effates, afipng, ZChefle Peacocks pronvearenaked lefee [\n= ABewware, 3 hint aduise. T 5 others, avpeasgall. DF theiv difplayed taple. h\n8 Qllfuch as teatt to falle confrads, D 1Loz0e, hotu long thefe Liserdsluvke, Chele Lurkpe cocks fu cullourred,\n3 D2 feseet harmes confpive? BGos GO D, holv greata fuhple _ Holong banelurkt alofe &\n{ 15¢(ure, with Hoxtonsithey hal taffe  Wlere thepin hand with fefgnedbarts  Ehe WBeare (althongh but fot of fwote) \"\nQ right deferucd bire, heir cuntrye to defple? Path pluct bis wynges by piofe,\n& Thep can not loke foz better (pede, oto did thep frame their turniture?  SCbe Mone ber bozowenlighthath loff, [\nDo death foz (uch to fell 7 Poiv fitthey mave theirtoles : Sbe wapnedas wele\n& Godgrantthe futticeof the Wozive Poiw Hymon feught our englplh Trofe  TWhohoped by bap of othersharnes, 4\nPut by the papnes of bell, o bapng to Romaine feoles. 4 full Poneonce tobie,\ni oz fuchapentiuccale it is, Potu Himon Pagus playd bis parte, 4The Lpon (uffred long the Wull,\n: TChat Cnglifh barts diddare 39t 1Babilon balvoe dibrage: 1is noble mpnd totrye:\n& 700 palle the boundes of dutieslatve, Potw WBafan bulles begon to bell, Wntpll the 1Bull Wwas rageypng wod, :\n: D3 of their cuntriecare. Hofu Judas fought bis wage. dndfrombisfakedid hye. 3\ni dnomerciehath (o longreleal 13oin Jannes and Jambzes 0id abyde fChen time it was to bid him Fap\n] Dfenvours (God doth knofv) TChe baunt of baaineficke ads, Perfozce, bishomestocut\ni andbountic of our curteous Nuécne Yot Dathan, Choze, Abivam (md Andmake him leauebis rageing tunes ¢\nS T long hath fpared her foe. o dath out Poyples faas. 3In(cilence to be put. £\nb 1But Gov, Wwhofegrace fpiresherharte, ol Romaine marchant feta frefh Andall the calues of WBalan kynd i\ni AW pll not abyoethe fpight g pardons baauea fale, Are weaned from their Wwifh s i\ni Df RAebels rage, Wwho rampets veach Potw aliapes fomeagain( the aenty  ELheBivcan Tigers tanmed notn, 0\ni Fromber, hee title quight. Tioloe dzeame afencelestale.  dlemathon eatesnofifh). i\nB4 Qithough e dotwe inpititull seale, BGos bicar frombis god receaucd 4Beholoe befoze pour balefull epes\nAnd loueth to fucke noblod 3 Che kepes to lofeand bpnds Lhepurchace of pour pacte,\ni1 ¢t Gona caueat topll her lend 4Baals chaplein thoght he fire wolk ™ 1o SHutuey pour fodefneforolful fight\nI appealethole Wipers mode, Huch was his pagan mynd. i ith fighes of dubble harte,\nB q man that (s bis bouleon fire, Gob 1Lozve hotn bits the tert theie ts  Lament thelackeof pouralies i\nvl feke to quench the flame : TThat faith fuch men thall bé  Religiousrebellgalls 5\nit Clsfrom thefpoylefomepacteconuey, Futheic reltgﬂonbo;no;tnlhz ABetuepethat pll fuccele of pours, b\nC1s feke the heate to tame, D much bavietie. Come curfe pour (odeine fall, G\nR wnho (@ea penthoule wether beate, and fund2p (02tsof fects furk nd Wben pe hauc pour guiles out fought\n| And heares a boiftroule fopndes iuifion Mall appeare &lt; And all your craft appzoued,\nil s3utheoefull fafetic of himlelte, dgaintE thefatber; fonnefhe  ue, Peccanimus Hall be your fong .\nT pll foace him fuccour fynde 2 Gaint mother, daughter 2 Pour ground wozke is renoued,\nAChepitifull pacient Pellican, 9 it not come to pafe trofy pra? QAud lokehotv Poztons (ped their wills\n; Per blod although Hee Hed e ea, baftards furethey bees €uen (o thetr fee MHall haue, e\nil 3oct Wopll (hee femeber dateto end, qrho our gwd mother Nuane o, . 4 o better et thenthope to gapne e\n!‘ n ﬂbzcarle hﬁzwnung befped. b m(lgthtzang rzbelllnu?xz.g ol 15ut gallotwes without graue, :\ni1 he Cagle fipnges ber yong ones dotone Lan o0 bis bengeance long etais ey 3\nit what ﬁfght lnf fg]nne vefule 2 mbell;z})is e (pruants ficle CEINTS léha ibl'nn. L\n8l Wnperfed foiles (e deadly hates, Fniuvfoule (pights of godlelemeit, @Xg * i\n. Anv rightlp fuch mirble, \\ wuhe turne as doth & Whele2 A 0 @‘@ @A@ 2\n£ » it\n¢ @ Tmp2inted at London by Fleyandet Lacfe, foz Hentrie Tipskeham, divellyng at the figne\no o of the blacke 3Bope, at themivdle {po2th Doze of Paules chuveh, 2 :\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy the way, this example used a JPG file. The ocr function can handle those too!\n\n\nEven though every page is an “image” to OCR, OCR struggles with imagistic or unconventional page layouts, as well as inset graphics. Add to that sub-par scans of archival documents, as in the newspaper page below, and the output will contain way more errors than correct matches.\n\n\n\n\n\n\nFigure 11.3\n\n\n\n\nnewspaper &lt;- \"https://chroniclingamerica.loc.gov/data/batches/mimtptc_inkster_ver01/data/sn88063294/00340589130/1945120201/0599.pdf\"\nnewspaper_ocr &lt;- ocr(newspaper)\n\nBeautifully messy output results:\n\nmessage(newspaper_ocr)\n\n\n\n\nOne strategy you might use to work with sources like this is to crop out everything you don’t want to OCR. This would be especially effective if, for example, you had a newspaper column that always appeared in the top left-hand corner of the page. You could preprocess your page images so that they only showed that part of the newspaper and left out any ads, images, or extra text. Doing so would likely increase the quality of your OCR output. Such a strategy can be achieved outside of R with software ranging from Adobe Photoshop or the open-source GIMP to Apple’s Automator workflows. Within R, packages like tabulizer and magick enable this. You won’t, however, be required to use these tools in the course, though we may have a chance to demonstrate some of them during lecture.\nThere are several other scenarios where OCR might not be able to read text. Two final (and major) ones are worth highlighting. First, for a long time OCR support for non-alphabetic writing systems was all but nonexistent. New datasets have been released in recent years that mostly rectify these absences, but sometimes support remains spotty and your mileage may vary. Second, OCR continues to struggle with handwriting. While it is possible to train unsupervised learning processes on datasets of handwriting and get good results, as of yet there is no general purpose method for OCRing handwritten texts. The various ways people write just don’t conform to the standardized methods of printing that enable computers to recognize text in images. If, someday, you figure out a solution for this, you’ll have solved one of the most challenging problems in computer vision and pattern recognition to date!",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Optical Character Recognition</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html",
    "href": "chapters/12_statistics.html",
    "title": "12  Statistics",
    "section": "",
    "text": "12.1 Introduction\nIt is useful to begin with some concrete examples of statistical questions to motivate the material that we’ll cover in this lesson. This will also help confirm that your R environment is working.\n# install.packages(\"ggformula\")\n# install.packages(\"mosaic\")\n# remotes::install_github(\"ProjectMOSAIC/mosaicModel\")\nlibrary(\"ggformula\")\nlibrary(\"mosaic\")\nlibrary(\"mosaicModel\")\nNow load the data sets:\nmice_pot = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/mice_pot.csv\")\nbarnacles = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/barnacles.csv\")\nBirths78 = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/births.csv\")\nsmoking = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/smoking.csv\")\nadipose = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/adipose.csv\")",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#introduction",
    "href": "chapters/12_statistics.html#introduction",
    "title": "12  Statistics",
    "section": "",
    "text": "Note\n\n\n\nThe examples that follow use several data sets, which we read directly from CSV files.\nThe data sets come from the fosdata package, which you can optionally install to your computer in order to get access to all of the associated help files. The fosdata package is hosted on GitHub but not CRAN, so to install it you need another package, remotes, for its install_github function. Here’s how to install both:\n# This is optional!\n# install.packages(\"remotes\")\nremotes::install_github(\"speegled/fosdata\")\n\n\n\n\n\n\n12.1.1 The mice_pot Data Set\nThe mice_pot data set comes from an experiment where four groups of mice were dosed with different levels of THC. There was a low, medium, and high dosage group, as well as a control group that got no THC. The mice were then observed for a while and their total movement was quantified as a percentage of the baseline group mean. Two statistical questions that might arise here are:\n\nWere there differences in the typical amount of movement between mice of different groups?\nWhat was the average amount of movement by mice in the medium dose group?\n\nBoth of these questions can be approached by summarizing the sample with descriptive statistics. Here’s one way to compute the average (mean) movement for each group:\n\naggregate(mice_pot[\"percent_of_act\"], mice_pot[\"group\"], mean)\n\n  group percent_of_act\n1   0.3       97.32250\n2     1       99.05235\n3     3       70.66787\n4   VEH      100.00000\n\n\nThe means aren’t identical! So there are clearly differences between all of the groups, right? Yes, in terms of this sample. But if you want to generalize your conclusion to cover what would happen to other mice that weren’t in the study, then you need to think about the population. In this case, that’s the population of all the mice that could have been dosed with THC.\nBecause we can’t see data from mice that weren’t part of the study, we rely on statistical inference to reach conclusions about the population. How is that possible? Statistical methods can tell us about the distribution of the sample relative to the population.\n\n\n12.1.2 The barnacles Data Set\nThis data set was collected by counting the barnacles in 88 grid squares on the Flower Garden Banks coral reef in the Gulf of Mexico. The counts were normalized to barnacles per square meter. Some questions that you might approach with statistical methods are:\n\nWhat is the average number of barnacles per square meter, and is it greater than 300?\n\nYou can use R to compute the average:\n\nmean(barnacles$per_m)\n\n[1] 332.0186\n\n\nFrom that calculation, we see that the mean is 332 barnacles per square meter, which is greater than 300. But again, the first calculation has told us only about the mean of the particular locations that were sampled. Wouldn’t it be better to answer the questions in reference to the number of barnacles per square meter of reef, rather than square meter of measurement? Here, the population is the entire area of the Flower Garden Banks reef. Again, we will be able to answer the questions relative to the entire reef by working out the sample mean’s distribution relative to the population.\n\n\n12.1.3 Sample and Population\nSamples and populations are fundamental concepts in statistics. A sample is data—the hard numbers that go into your calculations. The population is trickier: it’s the units to which you are able to generalize your conclusions.\nFor the barnacles data, in order to draw conclusions about the population (the entire Flower Garden Banks reef), the sample must be carefully selected to ensure it is representative. For instance, randomly sampling locations so that any location on the reef might be selected is one sampling strategy.\nFor the mice_pot data, the population is all the mice that might have been selected for use in the experiment. How big that population is depends on how the mice were selected for the experiment. Randomly selecting the experimental units from a group is a common way of ensuring that the results can generalize to that whole group.\nA non-random sample tends to mean that the population to which you can generalize is quite limited. What sort of population do you think we could generalize about if we recorded the age of everyone in this class?",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#uses-of-simulation",
    "href": "chapters/12_statistics.html#uses-of-simulation",
    "title": "12  Statistics",
    "section": "12.2 Uses of Simulation",
    "text": "12.2 Uses of Simulation\nThe study of statistics started in the 1800s, but slowly. Most statistical methodology and theory was developed during the first half of the 20th century—a time when data and processing power were in short supply. Today, that’s not so much the case. If you did the assigned reading, then you saw that statisticians are very much still grappling with how to teach statistics in light of the advances in computing over the past 40 years.\nTraditionally, statisticians are very concerned with assessing the normality of a sample, because the conclusions you get from traditional statistical methods depend on a sample coming from a normal distribution. Nowadays, there are a lot of clever methods that can avoid the need to assume normality. We’re going to learn some of those methods, because they usually don’t require any complicated math. If you want to know more, one of the assigned readings was the introduction to a book that would be a great reference for self-guided study.\nWe will use simulation-based methods extensively today.\nThis is the density curve of a standard normal distribution:\n\n\n\n\n\n\n\n\n\nAnd this is a histogram of samples taken from that same distribution:\n\n# Sample 20 numbers from a standard normal and draw the histogram\nx = rnorm(20)\nround(sort(x), 2)\n\n [1] -1.86 -1.83 -1.39 -1.22 -0.84 -0.76 -0.57 -0.29 -0.09  0.06  0.08  0.20\n[13]  0.31  0.36  0.48  0.57  0.75  0.78  0.85  1.45\n\nhist(x)\n\n\n\n\n\n\n\n\nDo the numbers seem to come from the high-density part of the normal density curve? Are there any that don’t? It isn’t surprising if some of your x samples are not particularly close to zero. One out of twenty (that’s five percent) samples from a standard normal population are greater than two or less than negative two, on average. That’s “on average” over the population. Your sample may be different.\nHere is the density of the exponential distribution:\n\n\n\n\n\n\n\n\n\nAnd here is a histogram of 20 samples taken from that distribution:\n\n# Sample 20 numbers from a histogram and plot the histogram\nex = rexp(20)\nround(sort(ex), 2)\n\n [1] 0.04 0.09 0.22 0.23 0.28 0.29 0.45 0.46 0.56 0.56 0.61 0.64 0.76 0.84 0.93\n[16] 0.97 1.04 1.19 1.38 3.21\n\nhist(ex)\n\n\n\n\n\n\n\n\nThe histograms are clearly different, but it would be difficult to definitively name the distribution of the data by looking at a sample.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#mathematical-statistics",
    "href": "chapters/12_statistics.html#mathematical-statistics",
    "title": "12  Statistics",
    "section": "12.3 Mathematical Statistics",
    "text": "12.3 Mathematical Statistics\nThe mean has some special properties: you’ve seen how we can calculate the frequency of samples being within an interval based on known distributions. But we need to know the distribution. It turns out that the distribution of the sample mean approaches the normal distribution as the sample size increases, for almost any independent data. That allows us to create intervals and reason about the distribution of real data, even though the data’s distribution is unknown.\n\n12.3.1 Law of Large Numbers\nThe Law of Large Numbers says that if the individual measurements are independent, then the mean of a sample tends toward the mean of the population as the sample size gets larger. This is what we’d expect, since we showed the rate at which the variance of the sample mean gets smaller is \\(1/n\\).\n\nnn = c(1, 2, 4, 8, 12, 20, 33, 45, 66, 100)\nmeans = sapply(nn, function(n) mean(rnorm(n)))\n\nplot(nn, means, bty = 'n', ylab = \"sample mean\")\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n\n\n\n\n12.3.2 Central Limit Theorem\nThe most important mathematical result in statistics, the Central Limit Theorem, says that if you take (almost) any sample of random numbers and calculate its mean, the distribution of the mean tends toward a normal distribution. We illustrate the “tending toward” with an arrow and it indicates that the distribution of a sample mean is only approximately normal. But if the original samples were from a normal distribution then the sample mean has an exactly normal distribution. From here, I’ll start writing the mean of a random variable \\(X\\) as \\(\\bar{X}\\) and the mean of a sample \\(x\\) as \\(\\bar{x}\\).\n\\[ \\bar{X} \\rightarrow N(\\mu, \\frac{\\sigma^2}{n}) \\]\nAnd because of the identities we learned before, you can write this as\n\\[\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow N(0, 1) \\]\nThis is significant because we can use the standard normal functions on the right, and the data on the left, to start answering questions like, “what is the 95% confidence interval for the population mean?”\n\n# Generate 20 samples from a uniform distribution and plot their histogram\nN = 20\nu = rexp(N)\nhist(u)\n\n\n\n\n\n\n\n# Generate 100 repeated samples of the same size, calculate the mean of each\n# one, and plot the histogram of the means.\nB = 100\nmeans = numeric(B)\nfor (i in 1:B) {\n  means[[i]] = mean(rexp(N))\n}\n\nhist(means)\n\n\n\n\n\n\n\n\nWhat happens as B and N get larger or smaller? Do they play different roles?",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#statistical-inference",
    "href": "chapters/12_statistics.html#statistical-inference",
    "title": "12  Statistics",
    "section": "12.4 Statistical Inference",
    "text": "12.4 Statistical Inference\n\n12.4.1 Confidence Intervals\nRecall the mice_pot data set, which contains data from an experiment where mice were dosed with THC and then measured for motor activity as a percentage of their baseline activity. We are going to look at the group that got a medium dose of THC.\n\n# Extract just the mice that got the medium dose of THC\nmice_med = mice_pot[ mice_pot$group == 1, ]\n\n# Assess normality with histogram and QQ plot\nhist(mice_med$percent_of_act)\n\n\n\n\n\n\n\nqqnorm(mice_med$percent_of_act)\n\n\n\n\n\n\n\n\n\n12.4.1.1 Finding Confidence Intervals\nNow we are using our sample to make some determination about the population, so this is statistical inference. Our best guess of the population mean is the sample mean, mean(mice_med$percent_of_act), which is 99.1%. But to get a confidence interval, we need to use the formula:\n\\[ \\bar{x} \\pm t_{n-1, 0.1} * S / \\sqrt{n} \\]\nFortunately, R can do all the work for us:\n\n# 80% confidence interval for location of mice_med mean:\nt.test(mice_med$percent_of_act, conf.level = 0.8)\n\n\n    One Sample t-test\n\ndata:  mice_med$percent_of_act\nt = 13.068, df = 11, p-value = 4.822e-08\nalternative hypothesis: true mean is not equal to 0\n80 percent confidence interval:\n  88.71757 109.38712\nsample estimates:\nmean of x \n 99.05235 \n\n\n\n\n\n12.4.2 Two-population Test\nThe test of \\(\\mu_0 = 100\\) is a one-population test because it seeks to compare a single population against a specified standard. On the other hand, you may wish to assess the null hypothesis that the movement of mice in the high-THC group is equal to the movement of mice in the medium-THC group. This is called a two-population test, since there are two populations to compare against each other. The null hypothesis is \\(\\mu_{0, med} = \\mu_{0, high}\\). Testing a two-population hypothesis requires first assessing normality and also checking whether the variances are equal. There are separate procedures when the variances are equal vs. unequal.\n\n# Extract the samples to be compared\ngroup1 = mice_pot$percent_of_act[mice_pot$group == 1]\ngroup3 = mice_pot$percent_of_act[mice_pot$group == 3]\n\n# Check for equal variances---these are close enough\nvar(group1)\n\n[1] 689.4729\n\nvar(group3)\n\n[1] 429.4551\n\n# Confirm equal variances with a boxplot\nboxplot(group1, group3)\n\n\n\n\n\n\n\n# Check whether the high-THC mice movement is normal\n# (we already checked for the medium-dose mice)\nqqnorm(group3)\n\n\n\n\n\n\n\n# Two-pop test\nt.test(group1, group3, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  group1 and group3\nt = 2.7707, df = 20, p-value = 0.0118\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  7.014608 49.754345\nsample estimates:\nmean of x mean of y \n 99.05235  70.66787 \n\n\n\n\n12.4.3 Hypothesis Tests for Non-normal Data\nJust as with the confidence intervals, there is a bootstrap hypothesis test that can be used where the data are not normal. There are other options, too, with clever derivations. The one I’ll show you is the Wilcoxon test, which is based on the ranks of the data.\nSince we’ve already seen that the barnacles per square meter data are not normal, I will illustrate testing the null hypothesis that \\(\\mu_0 = 300\\) barnacles per square meter. This is a one-population test, and a two-sided alternative.\n\n# Wilcoxon test for 300 barnacles per square meter\nwilcox.test(barnacles$per_m)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  barnacles$per_m\nV = 3916, p-value = 3.797e-16\nalternative hypothesis: true location is not equal to 0",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#regression",
    "href": "chapters/12_statistics.html#regression",
    "title": "12  Statistics",
    "section": "12.5 Regression",
    "text": "12.5 Regression\nRegression is a mathematical tool that allows you to estimate how some response variable is related to some predictor variable(s). There are methods that handle continuous or discrete responses of many different distributions, but we are going to focus on linear regression here.\nLinear regression means that the relationship between the predictor variable(s) and the response is a linear one. To illustrate, we’ll create a plot of the relationship between the waist measurement and body mass index (BMI) of 81 adults:\n\n# Plot the relationship between the waist_cm and bmi variables\nwith(adipose, plot(waist_cm, bmi), bty = 'n')\n\n\n\n\n\n\n\n\nThe relationship between the two is apparently linear (you can imagine drawing a straight line through the data). The general mathematical form of a linear regression line is:\n\\[ y = a + \\beta x + \\epsilon \\]\nHere, the response variable (BMI) is called \\(y\\) and the predictor (waist measurement) is \\(x\\). The coefficient \\(\\beta\\) indicates how much the response changes for a change in the predictors (that is, the expected change in BMI with a 1 cm change in waist measurement). Variable \\(a\\) denotes the intercept, which is a constant offset that aligns the mean of \\(y\\) with the mean of \\(x\\). Finally, \\(\\epsilon\\) is the so-called residual error in the relationship. It represents the variation in the response that is not due to the predictor(s).\n\n12.5.1 Fitting a Regression Line\nThe R function to fit the model is called lm. Let’s take a look at an example:\n\n# Fit the linear regression BMI vs waist_cm\nfit = lm(bmi ~ waist_cm, data = adipose)\n\n# Plot the fitted regression: begin with the raw data\nwith(adipose, plot(waist_cm, bmi, bty = 'n'))\n\n# Now plot the fitted regression line (in red)\nabline(coef(fit)[[1]], coef(fit)[[2]], col = 'red')\n\n\n\n\n\n\n\n\n\n\n12.5.2 Assumptions and Diagnostics\n“Fitting” a linear regression model involves estimating \\(a\\) and \\(\\beta\\) in the regression equation. You can can do this fitting procedure using any data, but the results won’t be reliable unless some conditions are met. The conditions are:\n\nA linear model is appropriate (linearity).\nThe residual error is normally distributed.\nThe variance of the residual error is constant for all observations.\nObservations are independent.\n\nThe first of these conditions can’t be checked—it has to do with the design of the experiment. The rest can be checked, though, and I’ll take them in order.\n\n12.5.2.1 Checking Linearity\nIn the case of a simple linear regression model (one predictor variable), you can check this by plotting the predictor against the response and looking for a linear trend. If you have more than one predictor variable, then you need to plot the predictions against the response to look for a linear trend. We’ll see an example by adding height as a predictor for BMI (in addition to waist measurement).\n\n# Linear model for BMI using waist size and height as predictors\nfit2 = lm(bmi ~ waist_cm + stature_cm, data=adipose)\n\n# Plot the fitted versus the predicted values\nplot(fit2$fitted.values, adipose$bmi, bty = 'n')\n\n\n\n\n\n\n\n\n\n\n12.5.2.2 Checking that the Residuals Are Normally Distributed\nWe have already learned about the QQ plot, which shows visually whether some values are Normally distributed. In order to depend upon the fit from a linear regression model, we need to see that the residuals are Normally distributed, and we use the QQ plot to check.\n\n\n12.5.2.3 Checking that the Variance Is Constant\nIn an earlier part, we saw that the variance is the average of the squared error. But that would just be a single number, when we want to see if there is a trend. So like the QQ plot, you’ll plot the residuals and use your eyeball to discern whether there is a trend in the residuals or if they are approximately constant - this is called the scale-location plot. The QQ plot and scale-location plot are both created by plotting the fitted model object\n\n# Set up the pattern of the panels\nlayout(matrix(1:4, 2, 2))\n\n# Make the diagnostic plots\nplot(fit)\n\n\n\n\n\n\n\n\nThe “Residuals vs. Fitted” plot is checking whether the linear model is correct. There should be no obvious pattern if the data are linear (as is the case here). The Scale-Location plot will have no obvious pattern if the variance of the residuals is constant, as is the case here (you might see a slight pattern in the smoothed red line but it isn’t obvious). And the QQ plot will look like a straight line if the residuals are from a Normal distribution, as is the case here. So this model is good. The fourth diagnostic plot is the Residuals vs. Leverage plot, which is used to identify influential outliers. We won’t get into that here.\n\n\n\n12.5.3 Functions for Inspecting Regression Fits\nWhen you fit a linear regression model, you are estimating the parameters of the regression equation. In order to see those estimates, use the summary() function on the fitted model object.\n\n# Get the model summary\nsummary(fit2)\n\n\nCall:\nlm(formula = bmi ~ waist_cm + stature_cm, data = adipose)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1290 -1.0484 -0.2603  1.2661  5.2572 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 14.38196    3.82700   3.758 0.000329 ***\nwaist_cm     0.29928    0.01461  20.491  &lt; 2e-16 ***\nstature_cm  -0.08140    0.02300  -3.539 0.000680 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.724 on 78 degrees of freedom\nMultiple R-squared:  0.844, Adjusted R-squared:   0.84 \nF-statistic:   211 on 2 and 78 DF,  p-value: &lt; 2.2e-16\n\n\nHere you can see that the average marginal effect of one additional centimeter of waist measurement is to increase BMI by 0.3 and an additional centimeter of height is associated with a change to BMI of r round(coef(fit2)[[3]], 2). You can get the coefficients from the fitted model object using the coef() function, and there are some other functions that allow you to generate the values shown in the summary table.\n\n# Get the coefficients of the fitted regression\nbeta = coef(fit2)\nround(beta, 2)\n\n(Intercept)    waist_cm  stature_cm \n      14.38        0.30       -0.08 \n\n\nGet the variance-covariance matrix:\n\nround(vcov(fit2), 4)\n\n\n# Compare the square root of the diagonals of the variance-covariance matrix to\n# the standard errors are reported in the summary table:\nse = sqrt(diag(vcov(fit2)))\n\n# Here are the standard errors:\nround(se, 3)\n\n(Intercept)    waist_cm  stature_cm \n      3.827       0.015       0.023 \n\n\n\n# Calculate the t-statistics for the regression coefficients (compare these to\n# the t-statistics reported in the summary table)\nt_stats = beta / se\n\n# Show the t-statistics:\nround(t_stats, 2)\n\n(Intercept)    waist_cm  stature_cm \n       3.76       20.49       -3.54 \n\n\n\n# Calculate the p-values:\npval = 2 * pt(abs(t_stats), df=78, lower.tail=FALSE)\nround(pval, 4)\n\n(Intercept)    waist_cm  stature_cm \n      3e-04       0e+00       7e-04 \n\n\n\n# This is the residual standard error:\nsd(fit2$residuals) * sqrt(80 / 78)\n\n[1] 1.72357\n\n# R-squared is the proportion of variance\n# explained by the regression model\nround(1 - var(fit2$residuals) / var(adipose$bmi), 3)\n\n[1] 0.844\n\n\n\n\n12.5.4 A Model that Fails Diagnostics\nWe’ve seen a model that has good diagnostics. Now let’s look at one that doesn’t. This time, we’ll use linear regression to make a model of the relationship between waist measurement and the visceral adipose tissue fat (measured in grams). The visceral adipose tissue fat is abbreviated vat in the data. First, since the model uses a single predictor variable, let’s look at the relationship with a pair plot.\n\n# plot the relationship between waist_cm and vat\nwith(adipose, plot(waist_cm, vat, bty = 'n'))\n\n\n\n\n\n\n\n\nThe plot is obviously not showing a linear relationship, which will violate one of the conditions for linear regression. Also, you can see that there is less variance of vat among the observations that have smaller waist measurements. So that will violate the assumption that the residual variance has no relationship to the fitted values. To see how these will show up in the diagnostic plots, we need to fit the linear regression model.\n\n# Estimate the model for vat\nfit_vat = lm(vat ~ waist_cm, data = adipose)\n\n# There is no problem creating the summary table:\nsummary(fit_vat)\n\n\nCall:\nlm(formula = vat ~ waist_cm, data = adipose)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-996.25 -265.96  -61.87  191.24 1903.46 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3604.196    334.241  -10.78   &lt;2e-16 ***\nwaist_cm       51.353      3.937   13.04   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 479 on 79 degrees of freedom\nMultiple R-squared:  0.6829,    Adjusted R-squared:  0.6789 \nF-statistic: 170.2 on 1 and 79 DF,  p-value: &lt; 2.2e-16\n\n# Show the diagnostic plots\nlayout(matrix(1:4, 2, 2))\nplot(fit_vat)\n\n\n\n\n\n\n\n\nThere is obviously a curved pattern in the Residuals vs. Fitted plot, and in the Scale vs. Location plot. Residuals vs. Fitted shows a fan-shaped pattern, too, which reflects the increasing variance among the greater fitted values. The QQ plot is not a straight line, although the difference is not as obvious. In particular, the upper tail of residuals is heavier than expected. Together, all of these are indications that we may need to do a log transformation of the response. A log transformation helps to exaggerate the differences between smaller numbers (make the lower tail heavier) and collapse some difference among larger numbers (make the upper tail less heavy).\n\n# Fit a regression model where the response is log-transformed\nfit_log = lm(log(vat) ~ waist_cm, data = adipose)\n\n# Plot the diagnostics for the log-transformed model\nplot(fit_log)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe diagnostics do not look good after the log transformation, but now the problem is the opposite: a too-heavy lower tail and residual variance decreases as the fitted value increases. Perhaps a better transformation is something in between the raw data and the log transform. Try a square-root transformation:\n\n# Fit a model where the vat is square root transformed\nfit_sqrt = lm(sqrt(vat) ~ waist_cm, data = adipose)\n\n# Plot the diagnostics for the log-transformed model\nplot(fit_sqrt)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese look acceptable for real-world data.\n\n\n12.5.5 Predictions and Variability\nThere are two scales of uncertainty for a regression model: uncertainty in the fitted relationship, and the uncertainty of a predicted outcome. The uncertainty of a prediction is always greater because it is calculated by adding the uncertainty of the fitted line to the uncertainty of a single data point around that fitted line. We can illustrate using the example of the model we just created to relate the waist measurement to the square root of vat.\nFor this example, we’ll need the mvtnorm library to be loaded:\n\n# install.packages(\"mvtnorm\")\nlibrary(\"mvtnorm\")\n\n# Draw the data on the transformed scale\nwith(adipose, plot(waist_cm, sqrt(vat), bty = 'n'))\n\n# Plot the fitted regression line\nabline(coef(fit_sqrt)[[1]], coef(fit_sqrt)[[2]], col = 'red')\n\n# Plot 100 samples from the distribution of the regression line.\nfor (i in 1:100) {\n  cc = rmvnorm(n = 1, mean = coef(fit_sqrt), sigma = vcov(fit_sqrt))\n  abline(cc[[1]], cc[[2]], col = grey(0.8))\n}\n\n\n\n\n\n\n\n\nClearly, the variability of the data points is greater than the variability of the fitted line (that’s why they lie outside the envelope of the fitted lines). We can extract a confidence interval for fitted values or predictions with the predict function.\n\n# Draw the data on the transformed scale\nwith(adipose, plot(waist_cm, sqrt(vat), bty = 'n'))\n\n# Plot the fitted regression line\nabline(coef(fit_sqrt)[[1]], coef(fit_sqrt)[[2]], col = 'red')\n\n# Define some waist measurements where we'll construct confidence intervals\npred_pts = data.frame(waist_cm = c(70, 85, 110))\n\n# Calculate the 90% CI at each of the pred_pts\nff = predict(fit_sqrt, pred_pts, interval = \"confidence\", level = 0.9)\npp = predict(fit_sqrt, pred_pts, interval = \"prediction\", level = 0.9)\n\n# Convert the confidence intervals to data.frames\nff = as.data.frame(ff)\npp = as.data.frame(pp)\n\n# Add the three confidence intervals to the plots\n# (offset them a bit for clarity in the plot)\nfor (i in 1:3) {\n  lines(\n    x = rep(pred_pts$waist_cm[[i]] - 0.5, 2),\n    y = c(ff$lwr[[i]], ff$upr[[i]]),\n    col = 'blue',\n    lwd = 2\n  )\n\n  lines(\n    x = rep(pred_pts$waist_cm[[i]] + 0.5, 2),\n    y = c(pp$lwr[[i]], pp$upr[[i]]),\n    col = 'orange',\n    lwd = 2\n  )\n}\n\n# Add a legend\nlegend(\n  c(\"90% CI (fitted values)\", \"90% CI (predicted values)\"),\n  col = c(\"blue\", \"orange\"),\n  x = \"topleft\", lwd = 2, bty = 'n'\n)\n\n\n\n\n\n\n\n\nOne thing to notice about the confidence intervals is that the interval is smallest (so the precision of the estimation is greatest) at the mean of the predictor variable. This is a general rule of fitting regression.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#model-selection",
    "href": "chapters/12_statistics.html#model-selection",
    "title": "12  Statistics",
    "section": "12.6 Model Selection",
    "text": "12.6 Model Selection\nChoosing how to represent your data is a common task in statistics. The most common target is to choose the representation (or model) that does the best job of predicting new data. We set this target because if we have a representation that predicts the future, then we can say it must accurately represent the process that generates the data.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/12_statistics.html#cross-validation",
    "href": "chapters/12_statistics.html#cross-validation",
    "title": "12  Statistics",
    "section": "12.7 Cross-validation",
    "text": "12.7 Cross-validation\nUnfortunately, we rarely have information about the future, so there isn’t new data to predict. One way to do prediction with the available data is to break it into a training part and a testing part. You make represent the training part with a model, and then use it to predict the left-out testing part. If you then swap the to parts and repeat the process, you’ll have a prediction for every data point. This would be called two-fold cross validation because the data was broken into two parts.\nIt’s more common to break the data into more than two parts - typically five or ten or one per data point. Then one part is taken as the testing part and all the others go into the training part. The result is five-fold or ten-fold, or leave-one-out cross validation.\nLet’s use cross-validation to do model selection. The model this time is a representation of the number of births per day in 1978 in the United States.\n\n# Plot the data\ngf_point(births ~ day_of_year, color = ~wknd, data = Births78)\n\n\n\n\n\n\n\n# Make models with two through ten knots in the spline for day_of_year\nbmod2  = lm(births ~ wknd + ns(day_of_year,  2), data = Births78)\nbmod4  = lm(births ~ wknd + ns(day_of_year,  4), data = Births78)\nbmod6  = lm(births ~ wknd + ns(day_of_year,  6), data = Births78)\nbmod8  = lm(births ~ wknd + ns(day_of_year,  8), data = Births78)\nbmod10 = lm(births ~ wknd + ns(day_of_year, 10), data = Births78)\n\n# Plot the 2 and 10 knot models\nmod_plot(bmod2, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n\n\n\n\n\n\n\nmod_plot(bmod10, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n\n\n\n\n\n\n\n# Cross-validate to choose the best model\nmod_cv(bmod2, bmod4, bmod6, bmod8, bmod10, k = nrow(Births78), ntrials = 1)\n\n       mse  model\n1 190815.9  bmod2\n2 143305.1  bmod4\n3 104875.7  bmod6\n4 106094.2  bmod8\n5 107130.5 bmod10\n\n# Plot the data\nmod_plot(bmod6, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n\n\n\n\n\n\n\n\nCross-validation suggests that six knots is the ideal number, because it has the smallest mean-squared error (mse). The resulting model looks good, too.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/13_reshaping-tabular-data.html",
    "href": "chapters/13_reshaping-tabular-data.html",
    "title": "13  Reshaping Tabular Data",
    "section": "",
    "text": "13.1 Introduction\nLet’s look at some examples of tidy and untidy data sets. The tidyr package provides examples, and as we’ll see later, it also provides functions to make untidy data sets tidy. As usual, we first need to load the package:\n# install.packages(\"tidyr\")\nlibrary(\"tidyr\")\nLet’s start with an example of tidy data. This data set is included in the tidyr package and records the number of tuberculosis cases across several different countries and years:\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\nWhen you first look at a data set, think about what the observations are and what the features are. If the data set comes with documentation, it may help you figure this out. Since this data set is a tidy data set, we already know each row is an observation and each column is a feature.\nFeatures in a data set tend to take one of two roles. Some features are identifiers that describe the observed subject. These are usually not what the researcher collecting the data is trying to find out. For example, in the tuberculosis data set, the country and year columns are identifiers.\nOther features are measurements. These are usually the reason the researcher collected the data. For the tuberculosis data set, the cases and population columns are measurements.\nThinking about whether features are identifiers or measurements can be helpful when you need to use tidyr to rearrange a data set.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping Tabular Data</span>"
    ]
  },
  {
    "objectID": "chapters/13_reshaping-tabular-data.html#columns-into-rows",
    "href": "chapters/13_reshaping-tabular-data.html#columns-into-rows",
    "title": "13  Reshaping Tabular Data",
    "section": "13.2 Columns into Rows",
    "text": "13.2 Columns into Rows\nTidy data rule 1 says each observation must have its own row. Here’s a table that breaks rule 1:\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nAll of the numbers measure the same thing: cases. To make the data tidy, we must rotate the 1999 and 2000 column names into rows, one for each value in the columns. The new columns are year and cases.\nThis process means less columns (generally) and more rows, so the data set becomes longer.\nWe can use the pivot_longer function to rotate columns into rows. We need to specify:\n\nColumns to rotate as cols.\nName(s) of new identifier column(s) as names_to.\nName(s) of new measurement column(s) as values_to.\n\nHere’s the code:\n\npivot_longer(table4a, -country, names_to = \"year\", values_to = \"cases\")\n\n# A tibble: 6 × 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n\n\n\n\n\n\nHow to Pivot Longer without tidyr\n\n\n\n\n\nYou also can do this without tidyr:\n\nSubset columns to separate 1999 and 2000 into two data frames.\nAdd a year column to each.\nRename the 1999 and 2000 columns to cases.\nStack the two data frames with rbind.\n\n\n# Step 1\ndf99 = table4a[-3]\ndf00 = table4a[-2]\n\n# Step 2\ndf99$year = \"1999\"\ndf00$year = \"2000\"\n\n# Step 3\nnames(df99)[2] = \"cases\"\nnames(df00)[2] = \"cases\"\n\n# Step 4\nrbind(df99, df00)\n\n# A tibble: 6 × 3\n  country      cases year \n  &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;\n1 Afghanistan    745 1999 \n2 Brazil       37737 1999 \n3 China       212258 1999 \n4 Afghanistan   2666 2000 \n5 Brazil       80488 2000 \n6 China       213766 2000",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping Tabular Data</span>"
    ]
  },
  {
    "objectID": "chapters/13_reshaping-tabular-data.html#rows-into-columns",
    "href": "chapters/13_reshaping-tabular-data.html#rows-into-columns",
    "title": "13  Reshaping Tabular Data",
    "section": "13.3 Rows into Columns",
    "text": "13.3 Rows into Columns\nTidy data rule 2 says each feature must have its own column. Let’s look at a table that breaks rule 2:\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\nHere the count column contains two different features: cases and population. To make the data tidy, we must rotate the count values into columns, one for each type value. New columns are cases and population.\nThis process means less rows and more columns, so the data set becomes wider.\nWe can use pivot_wider to rotate rows into columns. We need to specify:\n\nColumn names to rotate as names_from.\nMeasurements to rotate as values_from.\n\nHere’s the code:\n\npivot_wider(table2, names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\n\n\n\nHow to Pivot Wider without tidyr\n\n\n\n\n\nYou can also do this without tidyr:\n\nSubset rows to separate cases and population values.\nRemove the type column from each.\nRename the count column to cases and population.\nMerge the two subsets by matching country and year.\n\n\n# Step 1\ncases = table2[table2$type == \"cases\", ]\npop = table2[table2$type == \"population\", ]\n\n# Step 2\ncases = cases[-3]\npop = pop[-3]\n\n# Step 3\nnames(cases)[3] = \"cases\"\nnames(pop)[3] = \"population\"\n\n# Step 4\ntidy = cbind(cases, pop[3])\n\nThis code uses the cbind function to merge the two subsets, but it would be better to use the merge function. The cbind function does not use identifier columns to check that the rows in each subset are from the same observations.\n\n\n\n\n\n\n\n\n\nSee also\n\n\n\nRun vignette(\"pivot\") for more examples of how to use tidyr.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping Tabular Data</span>"
    ]
  },
  {
    "objectID": "chapters/13_reshaping-tabular-data.html#separating-values",
    "href": "chapters/13_reshaping-tabular-data.html#separating-values",
    "title": "13  Reshaping Tabular Data",
    "section": "13.4 Separating Values",
    "text": "13.4 Separating Values\nTidy data rule 3 says each value must have its own cell. Here’s a table that breaks rule 3:\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\nCells in the rate column contain two values: cases and population. These are two different features, so to make the data set tidy, we need to separate them into two different columns.\nSo how can we separate the rate column? The rate column is a character vector (you can check this with str(table3)), so we can use the string processing functions in the stringr package. In particular, we can use the str_split_fixed function:\n\nlibrary(\"stringr\")\n\ncolumns = str_split_fixed(table3$rate, fixed(\"/\"), 2)\n\nNow we have a character matrix where the values are in separate columns. Now we need to combine these with the original data frame. There are several ways to approach this, but to be safe, let’s make a new data frame rather than overwrite the original. First we make a copy of the original:\n\ntidy_tb = table3\n\nNext, we need to assign each column in the character matrix to a column in the tidy_tb data frame. Since the columns contain numbers, we can also use the as.numeric function to convert them to the correct data type:\n\ntidy_tb$cases = as.numeric(columns[, 1])\ntidy_tb$population = as.numeric(columns[, 2])\n\nExtracting values, converting to appropriate data types, and then combining everything into a single data frame is an extremely common pattern in data science.\nUsing stringr functions is the most general way to separate out values in a column, but the tidyr package also provides a function separate specifically for the case we just worked through. Either package is appropriate for solving this problem.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Reshaping Tabular Data</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html",
    "href": "chapters/14_network-analysis.html",
    "title": "14  Network Analysis",
    "section": "",
    "text": "14.1 What Is a Network?\nYou are all most likely familiar now with tabular data; rows and columns containing information. It looks like this:\nWhile this is a tidy way to store data, it artificially atomizes or separates many of the things we are interested in as researchers, social or otherwise. Network analysis is a tool to work with relational data: information about how entities are connected with each other.\nFor example, the diagram below shows the same data as the table above, with the added benefit of showing how these individuals are connected to each other. Hover over the people to reveal the data about them.\nRather than looking only at attributes of specific data points, we are looking at the connections between data. In network analysis, data points are called nodes or vertices, and the connections between them are called edges or ties. Vertices can be anything—people, places, words, concepts—they are usually mapped into rows in a data frame. Edges contain any information on how these things connect or are related to each other. These components create a network or graph, defined as “finite set or sets of actors and the relation or relations defined on them” (Wasserman and Faust 1994).",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#what-is-a-network",
    "href": "chapters/14_network-analysis.html#what-is-a-network",
    "title": "14  Network Analysis",
    "section": "",
    "text": "Person\nName\nAge\nWidgets\n\n\n\n\n\nJ\n30\n1\n\n\n\nY\n21\n3\n\n\n\nG\n32\n4\n\n\n\nZ\n48\n8\n\n\n\n\n\n\n\n\n14.1.1 Networks in Research\n\n14.1.1.1 Social Sciences\n\nOne of the first instances of social network analysis was originally published in 1932 as part of Jacob Moreno’s Who Shall Survive (1953). This study used the friendship networks of girls within a reform school to show that the ties between them were a stronger predictor of runaways than any attribute of the girls themselves. Since then, networks have been used widely in the social sciences, but only really picked up as the tools to understand SNA became more available.\n\n\n14.1.1.2 Neuroscience\n\nNeuroscientists use networks to study the brain, given their ready application to neurons and pathways. Bassett and Sporns (2017) provide an overview of how to translate neuroscience problems into network ones, and the tools available to study them.\n\n\n14.1.1.3 Chemistry\n\nChemistry was quick to see the applications of networks. As early at 1985 papers were published detailing the potential networks provided in terms of understanding and finding new ways to measure and understand the bonds between atoms and molecules (Balaban 1985).\n\n\n14.1.1.4 The Internet\n\nThe internet is a network! Beyond the various social network sites, servers themselves act as nodes and the information flows between them along edges. Google used this property in the first version of their search engine, which used the network metric of PageRank to determine which sites to show at the top of search results (Page 2001).\n\n\n14.1.1.5 Infrastructure\n\nFand and Mostafavi (2019) showed how you can use social media network data to find where infrastructure is failing during disasters, such as hurricane Harvey in 2017. Their system promises a method to monitor physical infrastructure like roads, bridges, and barriers like more easily monitored infrastructure like the electrical grid.\n\n\n14.1.1.6 Security\n\nNetwork analysis has also been used for offensive purposes. One of the most prominent uses is mapping crime or terror networks (Krebs 2002), though it is fraught with ethical concerns. There are specific tools made for this purpose, such as the keyplayer package (An and Liu 2016), which helps find what nodes in a network would fragment them the most if removed.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#network-data",
    "href": "chapters/14_network-analysis.html#network-data",
    "title": "14  Network Analysis",
    "section": "14.2 Network Data",
    "text": "14.2 Network Data\nNetworks are based on relational data. This means the core data requirement is that we have some measure of how nodes are connected. The two most common network data formats are the edgelist and adjacency matrix. Either of these will work for nearly any network purpose, and it is easy to convert between them. You will also need an attributes file, which gives information about the nodes being connected.\n\n14.2.1 Edgelist\nAn edgelist is a two-column data frame with a from and to column. Each row represents one edge or tie, with the possibility of adding in more information. Here’s an example of a basic edgelist:\n\n# Load in the data\ntoy_edgelist = read.csv(\n  \"data/toy_edgelist.csv\", header = TRUE, stringsAsFactors = FALSE\n)\n\n# Show the first 10 rows\nhead(toy_edgelist, n = 10)\n\n\n\n\n\nto\nfrom\n\n\n\n\nb33f00bd1109e1ae3ffa757d0aef0a25942f2ba3\nzuko\n\n\n19d5b2694036f6fab966564c1c44bc74330f22c2\nzuko\n\n\n9483b16c4904908115f4538525e37f776f4596d4\nzuko\n\n\nf8452649773eb7e024bfa59c395afa0c302d1928\nzuko\n\n\neea677240a425ed7ccdeff69feb2d377a5542599\nzuko\n\n\n9dbcce359070c879f20843e19564aee545f80d2d\nzuko\n\n\n749e81272630eb4755e4a7bca10fe3e3524d77ce\nzuko\n\n\ntoph\nzuko\n\n\n5737a840aa867025dcb506f24cb5546f16b4d777\nzuko\n\n\n028f5d1f351d38cd6553ab4674b19725d5ea3d3c\nzuko\n\n\n\n\n\n\n\n\n14.2.2 Adjacency Matrix\nThe same data can also be displayed in a table format. The information is the same, but it is presented in a way more usable by our code to create measures we care out. In this format, every node has both a row and column. If there is an edge between two nodes, a 1 is placed in the intersection of their row and column.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb33f00bd1109e1ae3ffa757d0aef0a25942f2ba3\n19d5b2694036f6fab966564c1c44bc74330f22c2\n9483b16c4904908115f4538525e37f776f4596d4\nf8452649773eb7e024bfa59c395afa0c302d1928\neea677240a425ed7ccdeff69feb2d377a5542599\n9dbcce359070c879f20843e19564aee545f80d2d\n749e81272630eb4755e4a7bca10fe3e3524d77ce\ntoph\n5737a840aa867025dcb506f24cb5546f16b4d777\n028f5d1f351d38cd6553ab4674b19725d5ea3d3c\nzuko\n\n\n\n\nb33f00bd1109e1ae3ffa757d0aef0a25942f2ba3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n19d5b2694036f6fab966564c1c44bc74330f22c2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n9483b16c4904908115f4538525e37f776f4596d4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\nf8452649773eb7e024bfa59c395afa0c302d1928\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\neea677240a425ed7ccdeff69feb2d377a5542599\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n9dbcce359070c879f20843e19564aee545f80d2d\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n749e81272630eb4755e4a7bca10fe3e3524d77ce\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\ntoph\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n5737a840aa867025dcb506f24cb5546f16b4d777\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n028f5d1f351d38cd6553ab4674b19725d5ea3d3c\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\nzuko\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n14.2.3 Edge Weights\nEdges can also have weights, meaning some edges are valued more than others. In an edgelist, you can add a third “weight” column, entering higher numbers to denote a more important connection. In an adjacency matrix, you can put numbers other than 1 in the intersection to denote more important connections. For our example, we’ll stick with un-weighted connections for now.\n\n\n14.2.4 Attributes\nEach network also typically has an attributes table, which looks just like typical tabular data, with each row belonging to a specific node in our network. Let’s load in and look at the sample attributes file.\n\n# Load in data\ntoy_attributes = read.csv(\n  \"data/toy_attributes.csv\", header = TRUE, stringsAsFactors = FALSE\n)\n\n# Show top of attributes table\nhead(toy_attributes, n = 10)\n\n\n\n\n\nid\nyear\ncolor\n\n\n\n\nzuko\n2\npurple\n\n\nnezuko\n2\npurple\n\n\nwinnie the pooh\n2\nblue\n\n\ntoph\n2\npurple\n\n\nchicken joe\n2\ngreen\n\n\nthe rat from ratatouille\n5\nblue\n\n\nspider-man\n3\nblue\n\n\nyamaguchi tadashi\n1\npurple\n\n\njude sweetwine\n2\npurple\n\n\nlord future\n2\nblue\n\n\n\n\n\n\n\n\n14.2.5 Create an Example Network\nBefore we start exploring specific measures, we’ll create a toy network to use as an example. Let’s start by loading in some packages.\nThe statnet package is a popular package for network analysis in R. It allows you to compute many of the most common network measures, and run simulations called exponential random graph models. We’ll stick with the basics for now!\n\n# Run this to load statnet, if you need to install it, do so now.\n# install.packages(\"statnet\")\nlibrary(\"statnet\")\n\nNow that we have our tools loaded, let’s create out first network. We’ll use the data you loaded in before. This toy network will be used as a visual for learning the measurements below.\nWe are going to turn the attributes file and edgelist into a statnet network object. A network object is a special kind of list in R. It is formatted in a way that the other statnet functions expect. While you could edit it like a normal list, it is highly recommended you use the other statnet functions to manipulate this object to make sure you don’t break any of the data expectations.\nWe’ll use the network function to create our network object. Before we create it, we will sort our attributes file alphabetically. This is super important, as the network object will automatically sort things itself.\n\n\n\n\n\n\nImportant\n\n\n\nIf we do not sort our attributes data frame to match, all of our measures later will be misaligned!\n\n\n\n# Sort your attributes frame alphabetically. Super important!\ntoy_attributes = toy_attributes[order(toy_attributes$id), ]\n\n# Make network!\n# We will cover the `directed = FALSE` argument soon.\ntoy_network = network(toy_edgelist, directed = FALSE)\n\nBefore we move on, let’s add a net_id column to our attributes data frame. This will let us easily check what the network object IDs are for our nodes.\n\n# Add ID column\ntoy_attributes$net_id = 1:nrow(toy_attributes)\n\nWe can inspect our new network by calling the summary function on it. Don’t worry too much about the output yet.\n\nsummary(toy_network)\n\nNetwork attributes:\n  vertices = 96\n  directed = FALSE\n  hyper = FALSE\n  loops = FALSE\n  multiple = FALSE\n  bipartite = FALSE\n total edges = 88 \n   missing edges = 0 \n   non-missing edges = 88 \n density = 0.01929825 \n\nVertex attributes:\n  vertex.names:\n   character valued attribute\n   96 valid vertex names\n\nNo edge attributes\n\nNetwork edgelist matrix:\n      [,1] [,2]\n [1,]    1   25\n [2,]    2   25\n [3,]    3   25\n [4,]    4   25\n [5,]    5   25\n [6,]    6   25\n [7,]    7   25\n [8,]    8   25\n [9,]    9   25\n[10,]   10   25\n[11,]   11   87\n[12,]   12   87\n[13,]   13   87\n[14,]   14   87\n[15,]   15   87\n[16,]   16   88\n[17,]   17   88\n[18,]   18   88\n[19,]   19   88\n[20,]   20   88\n[21,]   21   88\n[22,]   22   88\n[23,]   23   88\n[24,]   24   88\n[25,]   25   88\n[26,]   26    8\n[27,]   27    8\n[28,]   28    8\n[29,]   29    8\n[30,]   30    8\n[31,]   31   89\n[32,]   32   89\n[33,]   33   89\n[34,]   34   89\n[35,]   35   89\n[36,]   36   89\n[37,]   37   89\n[38,]   38   89\n[39,]   39   90\n[40,]   40   90\n[41,]   41   90\n[42,]   42   90\n[43,]   43   90\n[44,]   44   90\n[45,]   45   90\n[46,]   46   90\n[47,]   47   90\n[48,]   48   91\n[49,]   49   91\n[50,]   50   91\n[51,]   51   91\n[52,]   52   91\n[53,]   53   91\n[54,]   54   91\n[55,]   55   24\n[56,]   56   24\n[57,]   57   24\n[58,]   58   24\n[59,]   59   24\n[60,]   17   24\n[61,]   60   24\n[62,]   61   24\n[63,]   62   24\n[64,]   63   92\n[65,]   64   92\n[66,]   65   92\n[67,]   66   92\n[68,]   17   92\n[69,]   67   93\n[70,]   68   93\n[71,]   69   93\n[72,]   70   93\n[73,]   71   93\n[74,]   72   94\n[75,]   73   94\n[76,]   74   94\n[77,]   75   94\n[78,]   76   94\n[79,]   77   95\n[80,]   78   95\n[81,]   79   95\n[82,]   80   95\n[83,]   81   95\n[84,]   82   96\n[85,]   83   96\n[86,]   84   96\n[87,]   85   96\n[88,]   86   96\n\n\nThen we’ll add the node attributes to the network object. If you run summary again you should see the values from our toy_attributes have been added.\n\n# Add each attribute to network.\n# Do this by looking at every column, then adding it to the network\nfor(col_name in colnames(toy_attributes)) {\n    toy_network = set.vertex.attribute(\n      x = toy_network, attrname = col_name, value = toy_attributes[,col_name]\n    )\n}\n\nLet’s see what out network looks like!\n\nplot(toy_network)\n\n\n\n\n\n\n\n\nThe default plotting in statnet is ugly. For the sake of our eyes, and for exploring some of the measure we create, we’ll use the visNetwork package to visualize our networks. It will make the code a bit more cumbersome, but it will be worth it. From now on, we will need to use the edges and attributes data frames for plotting. This means we will often need to run commands twice, once for the network and once for the data frames. When you are working with networks for research, you would usually do everything you need on your network, than create a data frame from it all at once. We will need to deal with a bit of redundancy to take things one step at a time.\nLet’s try plotting again with visNetwork, using the data frames. We’ll give the visNetwork function our edgelist and attributes data frame. We’ll also tell it to plot the names from our attributes data frame so we can see them when we hover over the nodes in the plot.\n\n# Add pop-up tooltips with names\n# visNetwork uses the \"title\" column to create pop-up boxes\ntoy_attributes$title = toy_attributes$id\n\n# Plot!\nvisNetwork(nodes = toy_attributes, edges = toy_edgelist) %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\nNice.\n\n\n14.2.6 Components\nMost often when working with networks you want to limit your analysis to one cluster or component, typically the largest one in your network. If segments of your network aren’t connected, you can’t answer many of the relational questions network analysis is good for! Let’s limit our network to the largest component:\n\n# Find what nodes are part of the largest component\ntoy_network%v%\"lc\" = component.largest(toy_network)\n\n# Delete those nodes that are not in the network\nin_lc = toy_network%v%\"lc\"\ntoy_network = delete.vertices(toy_network, which(!in_lc))\n\n# In our data frames\ntoy_attributes = toy_attributes[\n  toy_attributes$id %in% as.character(toy_network%v%\"id\"),\n]\n\nin_lc = toy_edgelist$to %in% toy_attributes$id |\n  toy_edgelist$from %in% toy_attributes$id\ntoy_edgelist = toy_edgelist[which(in_lc), ]\n\n# Plot!\nvisNetwork(nodes = toy_attributes, edges = toy_edgelist) %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\n\n\n14.2.7 Limitations of Network Data\nBefore we move on we should take a moment to talk about some the the caveats when using network data. While powerful, network analysis is particularly picky when in comes to data requirements. I’ll cover the two biggest ones below. You should always keep these in mind when using or interpreting network tools.\n\n14.2.7.1 Missing Data\nNetwork analysis is very vulnerable to missing data. A simple way to understand why is to make a small adjustment to our network. I’ve highlighted one node in green. This node is structurally vital to the network; without it, the shape of the network as a whole will change.\n\n\n\n\n\n\nIf we remove this node, the network changes in a major way! Imagine these nodes are people, and that missing node is the one person you forget to survey, or was sick the day data was collected. This could massively change the outcome of your analyses. There is some advanced research going on to detect and replace missing data like this if you have enough context, but it is not something to rely on.\n\n\n\n\n\n\n\n\n14.2.7.2 Network Boundaries\nNetwork analysis is all about looking at the relationships between entities. However, following all connections an entity has can quickly spiral out of hand. For example, if you wanted to map your own social network, where would you start? You would include yourself, then your friends and family, but what about after that? Your friends and family have friends and family, as do their friends and family, and so on. If you are looking at human networks, every human will be included if you look far enough, so how do you decide when to stop?\nThere is no easy answer. If you are looking at a pre-defined group (for example, this class), you can set the boundaries to include everyone in this class and the connection between them. However, that doesn’t really capture the social networks of people in this class as most people will have friends elsewhere.\nAnother common method is setting an arbitrary number of “steps” or connections from a target population. If we were interested in a 2-step network from an individual, we would collect all of their relevant connections, and then ask all the people they nominated about their connections. Some sort of justification will be needed as to why you picked the number of steps that you did.\n\n\n\n\n\n\nFigure 14.1\n\n\n\n\n\n\n14.2.8 Projected Networks\nOften, you will not have individual level network data, but you will have data on group membership. For example, if you wanted to map the social networks of student, but don’t know who they actually hang around with, you may be able to use class rosters to build an approximate network. This is call a bipartite network, two-mode network, or projected network. You can see an example below.\n\n\n\n\n\n\nFigure 14.2: In this figure there are two kinds of nodes, students and classes. You can “collapse” this into a student network by assuming every student connected to a class is connected to each other. The same is true with classes, such that classes are related to each other if a single student is enrolled in both. This assumption may not always be correct, and you need to take care if you are going to make it in your research. If a class has 300 students, it is most likely not correct to assume every student knows every other student in that class.\n\n\n\nFor reference, this is what out projected class network looks like:",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#graph-level-properties",
    "href": "chapters/14_network-analysis.html#graph-level-properties",
    "title": "14  Network Analysis",
    "section": "14.3 Graph Level Properties",
    "text": "14.3 Graph Level Properties\nNow that we know what networks are and have some examples of how they are used and the data required, let’s get into actually analyzing them. There are a number of measures we can compute to understand the structure of a network as a whole. We will go over some basic network level ones here. These are single measures or attributes used to describe the entire network, and can be used to compare one network against another.\n\nDirected or Undirected\nDensity\nCentralization\n\n\n14.3.1 Directed or Undirected\nNetworks can either be directed or undirected. A directed network treats the edges between nodes as having a specific direction of flow, while an undirected network considers all edges to be mutual. An example of each is presented below.\nBoth edgelist and adjacency matrix datasets are inherently directed. For edgelists, the sender is often the first column, and the receiver is the second. For adjacency matrices the rows are considered senders and columns are receivers. Directionality is often specified when the network objects are created. When we created our toy network, we specified directed = FALSE to simplify things. If you want a directed network, the default is directed = TRUE for statnet networks.\nA directed network tracks which node is the source and which node is the receiver for an edge. Take for example the follow mechanic on Twitter. User A can follow User B, creating a directed edge from A to B, but B does not have to follow A in return. This can be useful when trying to understand the flows of resources that are finite such as money or goods.\n\n# visNetwork uses a column called \"arrows\" to show directionality in its plots.\n# For our edgelist, we'll just say every row is \"to\" for now\ntoy_edgelist$arrows = \"to\"\n\n# This will show us what our network would look like if it was directed.\nvisNetwork(toy_attributes, toy_edgelist, main = \"Directed\") %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\nAn undirected network treats all ties as mutual, such that A and B are both involved equally in a tie. An example is the friend mechanic on Facebook. Once a friendship is established, both users are considered equal in the tie. This can be helpful when you do not have information on what node initiates a tie, or when events happen equally to a group of nodes, such as all nodes being connected through co-membership in a group.\n\n# Let's drop the arrow column for now since our network is undirected.\ntoy_edgelist = toy_edgelist[,c(\"from\", \"to\")]\n\n# Plot\nvisNetwork(toy_attributes, toy_edgelist, main = \"Undirected\") %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\nWhich of these will be useful to you will likely change from project to project. However, it is vital to understand what kind of network you are working with, as many network calculations we will talk about later change their behavior based on if the network is directed or not.\n\n\n14.3.2 Density\nDensity is the first real graph level metric that helps you understand what is particular about the network you are looking at. The density of a network is a numerical score showing how many ties exist in a network, given the max possible in that network. Mathematically that is \\(\\frac{Actual Edges}{Possible\nEdges}\\), where actual edges is the number of edges in the network, and possible edges is the number of edges if every single node in the network was connected to every other node.\nNetworks that are more densely connected are considered to be more cohesive and robust. This means that the removal of any specific edge or node will not have a great effect of the network as a whole. It also typically means that any one node in the network will be more likely to have access to whatever resources are in the network, as there are more potential connections in the network to search for resources.\nTo calculate the density of a network, we use the network.density function. You can also see it if you use summary on your network object. Below is our toy network and a less dense version to try and visualize the difference. Density is all about how many edges exist in the network. Notice that there are the same number of nodes in both of these networks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.3.3 Centralization\nFreeman centralization (usually just called centralization) gives a sense of the shape of the network, namely how node level measures are distributed in a network. We’ll discuss node level measures next, but for now it is only important to understand that node level measures are numeric scores assigned to specific nodes rather than the network as a whole. This means that each node may have a different value.\nConsider the two networks below. The first “star” network would be considered highly centralized, as one node connects to all the others, while the rest of the nodes have no connections to each other. This star network would have a edge centralization score of 1, as 100% of the ties are connected with one node. The loop network would have a score of 0, as every node is equally connected to each other.\nCentralization is a measure of how unevenly node level metrics are distributed in a network. This is helpful when trying to understand if some nodes in the network have a larger influence, or are is some way more important than others.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#node-level-properties",
    "href": "chapters/14_network-analysis.html#node-level-properties",
    "title": "14  Network Analysis",
    "section": "14.4 Node Level Properties",
    "text": "14.4 Node Level Properties\nNode level measures are numeric representations of a node’s position and importance in a network. There are several common node level measures, and we will go over some of them here. Each measure tries to quantify a different aspect of a node’s position in the network so we can make an argument about why that specific node or class of nodes is important in some way. We will go over:\n\nDegree\nGeodesic distance\nBetweenness centrality\nEigenvector centrality\n\nMost node level measures are only helpful within the context of the network they were generated for. This is because the measures are created in part using network level measures like density. This means it is alright to compare one node to another within the same network, but toy should node compare the node level measures between networks.\n\n14.4.1 Degree\nDegree counts how many edges are connected to a node. You can count incoming, outgoing, or total (Freeman) degree. Incoming and outgoing degree only matter in directed networks. In undirected networks, only total edges are applicable. Degree gives a very rough measure of how popular or central a node is in the network. If a node has more ties, it may indicate that node as being more central or important the network as a whole.\nDegree is a raw count of the number of edges a node has, this makes the interpretation of degree highly dependent on the size of the network. In a small network with only 25 total edges, having 10 of them would be significant. In a larger network with 250 total edges, 10 edges could be less impressive. Degree should thus be interpreted in the cortex of other nodes in the network.\nLet’s scale the node sizes of our toy network based on their total degree numbers. We’ll get degree counts for each of our nodes using the degree() function. We can save that into our data frame and network for use later. For now I am naming columns to work specifically with visNetwork, we’ll make a proper data frame for analyses later using data we saved in the network object. In our visualization, you can click on any node to highlight only the edges connected to that node.\n\n# Find the degree of each node and save in the network.\n#\n# We will use the special `%v%` operator when assigning values to a network.\n# `%v%` works like `$` for data frames, allowing you to ask for specific values\n# in the network.\n#\n# In this case `%v%` stands for vertex, and you can use `%e%` if you want to\n# work with edges. So let's get the degree counts, and assign them to the\n# \"degree\" variable in our network object\ntoy_network%v%\"degree\" = degree(toy_network)\n\n# visNetwork uses the \"value\" column to determine node size, so let's put it\n# there as well for now.\n#\n# We'll square the values just to make them more distinct\ntoy_attributes$value = degree(toy_network)^2\n\n# Plot!\nvisNetwork(toy_attributes, toy_edgelist, main = \"Degree Example\") %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\n\n\n14.4.2 Geodesic Distance\nGeodesic distance is “the length of the shortest path via the edges or binary connections between nodes” (Kadushin 2012). In other words, if we treat the network as a map we can move along, with the nodes being stopping places and the edges being paths, the geodesic is the shortest possible path we can use to walk between two nodes.\nNodes that on average have a shorter geodesic distance between all the other nodes in the network are considered to have have greater access to the resources in a network. This is because a node with a low average geodesic distance can theoretically “reach” the other nodes with less effort because it does not need to travel as far.\nTo find the mean geodesic distance for each node in the network we will first need to find the geodesic distance from each node to every other node, then take the mean. Not super difficult, but there isn’t a single function to do it for us. First we will use the geodist function to get all the geodesics.\n\n# Get all the geodesics\n# I use the $gdist so we only get geodesics not counts\ngeodist(toy_network)$gdist\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    0    2    2    2    2    2    2    2    2     2     3     3     3\n [2,]    2    0    2    2    2    2    2    2    2     2     3     3     3\n [3,]    2    2    0    2    2    2    2    2    2     2     3     3     3\n [4,]    2    2    2    0    2    2    2    2    2     2     3     3     3\n [5,]    2    2    2    2    0    2    2    2    2     2     3     3     3\n [6,]    2    2    2    2    2    0    2    2    2     2     3     3     3\n [7,]    2    2    2    2    2    2    0    2    2     2     3     3     3\n [8,]    2    2    2    2    2    2    2    0    2     2     3     3     3\n [9,]    2    2    2    2    2    2    2    2    0     2     3     3     3\n[10,]    2    2    2    2    2    2    2    2    2     0     3     3     3\n[11,]    3    3    3    3    3    3    3    3    3     3     0     2     2\n[12,]    3    3    3    3    3    3    3    3    3     3     2     0     2\n[13,]    3    3    3    3    3    3    3    3    3     3     2     2     0\n[14,]    3    3    3    3    3    3    3    3    3     3     2     2     2\n[15,]    3    3    3    3    3    3    3    3    3     3     2     2     2\n[16,]    3    3    3    3    3    3    3    3    3     3     2     2     2\n[17,]    3    3    3    3    3    3    3    3    3     3     2     2     2\n[18,]    3    3    3    3    3    3    3    3    3     3     2     2     2\n[19,]    3    3    3    3    3    3    3    3    3     3     2     1     2\n[20,]    1    1    1    1    1    1    1    1    1     1     2     2     2\n[21,]    3    3    3    3    3    3    3    1    3     3     4     4     4\n[22,]    3    3    3    3    3    3    3    1    3     3     4     4     4\n[23,]    3    3    3    3    3    3    3    1    3     3     4     4     4\n[24,]    3    3    3    3    3    3    3    1    3     3     4     4     4\n[25,]    3    3    3    3    3    3    3    1    3     3     4     4     4\n[26,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[27,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[28,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[29,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[30,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[31,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[32,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[33,]    4    4    4    4    4    4    4    4    4     4     3     2     3\n[34,]    5    5    5    5    5    5    5    5    5     5     4     2     4\n[35,]    5    5    5    5    5    5    5    5    5     5     4     2     4\n[36,]    5    5    5    5    5    5    5    5    5     5     4     2     4\n[37,]    5    5    5    5    5    5    5    5    5     5     4     2     4\n[38,]    2    2    2    2    2    2    2    2    2     2     1     1     1\n[39,]    4    4    4    4    4    4    4    4    4     4     3     1     3\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n [1,]     3     3     3     3     3     3     1     3     3     3     3     3\n [2,]     3     3     3     3     3     3     1     3     3     3     3     3\n [3,]     3     3     3     3     3     3     1     3     3     3     3     3\n [4,]     3     3     3     3     3     3     1     3     3     3     3     3\n [5,]     3     3     3     3     3     3     1     3     3     3     3     3\n [6,]     3     3     3     3     3     3     1     3     3     3     3     3\n [7,]     3     3     3     3     3     3     1     3     3     3     3     3\n [8,]     3     3     3     3     3     3     1     1     1     1     1     1\n [9,]     3     3     3     3     3     3     1     3     3     3     3     3\n[10,]     3     3     3     3     3     3     1     3     3     3     3     3\n[11,]     2     2     2     2     2     2     2     4     4     4     4     4\n[12,]     2     2     2     2     2     1     2     4     4     4     4     4\n[13,]     2     2     2     2     2     2     2     4     4     4     4     4\n[14,]     0     2     2     2     2     2     2     4     4     4     4     4\n[15,]     2     0     2     2     2     2     2     4     4     4     4     4\n[16,]     2     2     0     2     2     2     2     4     4     4     4     4\n[17,]     2     2     2     0     2     2     2     4     4     4     4     4\n[18,]     2     2     2     2     0     2     2     4     4     4     4     4\n[19,]     2     2     2     2     2     0     2     4     4     4     4     4\n[20,]     2     2     2     2     2     2     0     2     2     2     2     2\n[21,]     4     4     4     4     4     4     2     0     2     2     2     2\n[22,]     4     4     4     4     4     4     2     2     0     2     2     2\n[23,]     4     4     4     4     4     4     2     2     2     0     2     2\n[24,]     4     4     4     4     4     4     2     2     2     2     0     2\n[25,]     4     4     4     4     4     4     2     2     2     2     2     0\n[26,]     3     3     3     3     3     1     3     5     5     5     5     5\n[27,]     3     3     3     3     3     1     3     5     5     5     5     5\n[28,]     3     3     3     3     3     1     3     5     5     5     5     5\n[29,]     3     3     3     3     3     1     3     5     5     5     5     5\n[30,]     3     3     3     3     3     1     3     5     5     5     5     5\n[31,]     3     3     3     3     3     1     3     5     5     5     5     5\n[32,]     3     3     3     3     3     1     3     5     5     5     5     5\n[33,]     3     3     3     3     3     1     3     5     5     5     5     5\n[34,]     4     4     4     4     4     3     4     6     6     6     6     6\n[35,]     4     4     4     4     4     3     4     6     6     6     6     6\n[36,]     4     4     4     4     4     3     4     6     6     6     6     6\n[37,]     4     4     4     4     4     3     4     6     6     6     6     6\n[38,]     1     1     1     1     1     1     1     3     3     3     3     3\n[39,]     3     3     3     3     3     2     3     5     5     5     5     5\n      [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37]\n [1,]     4     4     4     4     4     4     4     4     5     5     5     5\n [2,]     4     4     4     4     4     4     4     4     5     5     5     5\n [3,]     4     4     4     4     4     4     4     4     5     5     5     5\n [4,]     4     4     4     4     4     4     4     4     5     5     5     5\n [5,]     4     4     4     4     4     4     4     4     5     5     5     5\n [6,]     4     4     4     4     4     4     4     4     5     5     5     5\n [7,]     4     4     4     4     4     4     4     4     5     5     5     5\n [8,]     4     4     4     4     4     4     4     4     5     5     5     5\n [9,]     4     4     4     4     4     4     4     4     5     5     5     5\n[10,]     4     4     4     4     4     4     4     4     5     5     5     5\n[11,]     3     3     3     3     3     3     3     3     4     4     4     4\n[12,]     2     2     2     2     2     2     2     2     2     2     2     2\n[13,]     3     3     3     3     3     3     3     3     4     4     4     4\n[14,]     3     3     3     3     3     3     3     3     4     4     4     4\n[15,]     3     3     3     3     3     3     3     3     4     4     4     4\n[16,]     3     3     3     3     3     3     3     3     4     4     4     4\n[17,]     3     3     3     3     3     3     3     3     4     4     4     4\n[18,]     3     3     3     3     3     3     3     3     4     4     4     4\n[19,]     1     1     1     1     1     1     1     1     3     3     3     3\n[20,]     3     3     3     3     3     3     3     3     4     4     4     4\n[21,]     5     5     5     5     5     5     5     5     6     6     6     6\n[22,]     5     5     5     5     5     5     5     5     6     6     6     6\n[23,]     5     5     5     5     5     5     5     5     6     6     6     6\n[24,]     5     5     5     5     5     5     5     5     6     6     6     6\n[25,]     5     5     5     5     5     5     5     5     6     6     6     6\n[26,]     0     2     2     2     2     2     2     2     4     4     4     4\n[27,]     2     0     2     2     2     2     2     2     4     4     4     4\n[28,]     2     2     0     2     2     2     2     2     4     4     4     4\n[29,]     2     2     2     0     2     2     2     2     4     4     4     4\n[30,]     2     2     2     2     0     2     2     2     4     4     4     4\n[31,]     2     2     2     2     2     0     2     2     4     4     4     4\n[32,]     2     2     2     2     2     2     0     2     4     4     4     4\n[33,]     2     2     2     2     2     2     2     0     4     4     4     4\n[34,]     4     4     4     4     4     4     4     4     0     2     2     2\n[35,]     4     4     4     4     4     4     4     4     2     0     2     2\n[36,]     4     4     4     4     4     4     4     4     2     2     0     2\n[37,]     4     4     4     4     4     4     4     4     2     2     2     0\n[38,]     2     2     2     2     2     2     2     2     3     3     3     3\n[39,]     3     3     3     3     3     3     3     3     1     1     1     1\n      [,38] [,39]\n [1,]     2     4\n [2,]     2     4\n [3,]     2     4\n [4,]     2     4\n [5,]     2     4\n [6,]     2     4\n [7,]     2     4\n [8,]     2     4\n [9,]     2     4\n[10,]     2     4\n[11,]     1     3\n[12,]     1     1\n[13,]     1     3\n[14,]     1     3\n[15,]     1     3\n[16,]     1     3\n[17,]     1     3\n[18,]     1     3\n[19,]     1     2\n[20,]     1     3\n[21,]     3     5\n[22,]     3     5\n[23,]     3     5\n[24,]     3     5\n[25,]     3     5\n[26,]     2     3\n[27,]     2     3\n[28,]     2     3\n[29,]     2     3\n[30,]     2     3\n[31,]     2     3\n[32,]     2     3\n[33,]     2     3\n[34,]     3     1\n[35,]     3     1\n[36,]     3     1\n[37,]     3     1\n[38,]     0     2\n[39,]     2     0\n\n\nThis output is just like an adjacency matrix, with row and columns being the network node IDs (net_id in our attributes data frame). Next we would want sum all the columns for each row (so adding up all the geodesics for a node), and divide by the total number of nodes it can have an edge with to get the average geodesic distance for that node. This gives us the average geodesic distance for each node!\n\n# `colSums` gives us the sum of all columns for a row.\n# We subtract one from the denominator because a node cannot have a geodesic\n# distance with itself.\ncolSums(geodist(toy_network)$gdist) / (nrow(as.sociomatrix(toy_network)) - 1)\n\n [1] 3.131579 3.131579 3.131579 3.131579 3.131579 3.131579 3.131579 2.868421\n [9] 3.131579 3.131579 2.947368 2.447368 2.947368 2.947368 2.947368 2.947368\n[17] 2.947368 2.947368 2.368421 2.157895 3.842105 3.842105 3.842105 3.842105\n[25] 3.842105 3.342105 3.342105 3.342105 3.342105 3.342105 3.342105 3.342105\n[33] 3.342105 4.184211 4.184211 4.184211 4.184211 1.973684 3.210526\n\n\nLet’s add this to our network and plot it. We’ll also add color and labels so it’s easier to see what this measure means. The red node has the longest average geodesic distance, and would need to travel through the whole network to reach the nodes on the opposite side. Meanwhile, the blue node has the smallest average geodesic distance because it is located near the middle of the network.\n\n# Add mean geodesic distance to network object\ntoy_network%v%\"mean_distance\" =\n  (colSums(geodist(toy_network)$gdist))/(nrow(as.sociomatrix(toy_network)) - 1)\n\n# Set all node colors in visNetwork to grey as default\ntoy_attributes$color = \"grey\"\n\n# Add label as geodesic distance, rounding to 3 digits\ntoy_attributes$label = round(toy_network%v%\"mean_distance\", 3)\n\n# Replace min average geodesic with blue, max with red\ntoy_attributes$color[which(toy_network%v%\"mean_distance\" == max(toy_network%v%\"mean_distance\"))] = \"red\"\ntoy_attributes$color[which(toy_network%v%\"mean_distance\" == min(toy_network%v%\"mean_distance\"))] = \"blue\"\n\n# Make sure edges are grey too\ntoy_edgelist$color = \"grey\"\n\n# Plot\nvisNetwork(toy_attributes, toy_edgelist, main = \"Geodesic Example\") %&gt;%\n  visInteraction(zoomView = FALSE)\n\n\n\n\n\nNote that while there is a correlation between degree counts (node size) and mean geodesic distance, one does not cause the other. This is our first instance of how network structure, not node attributes, can inform us about the nodes in a network. Essentially, looking at the network as a whole can tell us things about the people in it that is lost if we look only at individuals.\n\n\n14.4.3 Centrality\nCentrality scores encompass a wide range of measures computed at the node level. Each tries to understand the importance of a single node within the structure of a network by looking at the nodes connection patterns to other nodes. Any centrality measure can be used to create a network level centralization score like we discussed above. We will go through some of the common centrality measures here, but know there are several more we will not cover.\n\n14.4.3.1 Betweenness Centrality\nBetweenness centrality is one of the most common centrality measures. It tries to calculate the extent to which a node acts as a gatekeeper or broker in the network. A broker bridges two otherwise disconnected segments in a network. If there are two parts of a network that would otherwise be broken apart if a node was removed, they would have a high betweenness centrality. The fragmenting of a network is not a prerequisite however, simply acting as an effective “shortcut” in a network can also raise a node’s betweenness centrality. Betweenness is calculated using geodesic distances, and gives a higher score to nodes that lie on more geodesic paths.\nThe next network plot shows the size of nodes as their degree, with a label showing their betweenness centrality score. Centrality score are usually normalized such that their scores all sum to 1. This way, you can easily compare nodes within the network (but not between networks), and understand how nodes relate to each other structurally. It is possible for a node to have a 0 betweenness score if no geodesic distances pass through them.\nLike last time I’ve colored the nodes so that the node with the highest betweenness centrality is red, while the lowest is blue. Compared to distance however, it is considered advantageous to have a high betweenness centrality, as this means that nodes acts as a gatekeeper in the network, which can be a powerful position. Contrast this with having a low mean distance, which meant you were closer to all other nodes.\n\n# Add eigenvector centrality to network object as \"norm_betweenness\".\n#\n# We also tell it we are treating our data as undirected (\"graph\"), rather than\n# the default directed (\"digraph\"), same with `cmode = \"undirected\"`.\n#\n# We also say we want a normalized (0-1, sum to 1) score using `rescale =\n# TRUE`.\n\ntoy_network%v%\"norm_betweenness\" =\n  betweenness(\n    dat = toy_network, gmode = \"graph\", rescale = TRUE, cmode = \"undirected\"\n  )\n\n# Add label as geodesic distance, rounding to 3 digits\ntoy_attributes$label = round(toy_network%v%\"norm_betweenness\", 3)\n\n# Reset all nodes to grey\ntoy_attributes$color = c(\"grey\")\n\n# Replace min average geodesic with blue, max with red\ntoy_attributes$color[which(toy_network%v%\"norm_betweenness\" == max(toy_network%v%\"norm_betweenness\"))] = \"red\"\ntoy_attributes$color[which(toy_network%v%\"norm_betweenness\" == min(toy_network%v%\"norm_betweenness\"))] = \"blue\"\n\n# Plot\nvisNetwork(toy_attributes, toy_edgelist, main = \"Betweenness Centrality Example\") %&gt;% visInteraction(zoomView = FALSE)\n\n\n\n\n\n\n\n14.4.3.2 Eigenvector Centrality\nEigenvector Centrality is commonly known as a measure of “popular friends.” Rather than looking at the network position of a node, it looks at the network positions of nodes connected to it. Nodes with a high eigenvector score will be connected to nodes more prominent in the network. Nodes with low degree can have high eigenvector scores if they are connected to important nodes. In real life networks this can be interpreted as being close to influential others in a network.\nI’ve colored the nodes so that the node with the highest eigenvector centrality is red, while the lowest is blue. It is considered advantageous to have a high eigenvector centrality, as this means you are well connected to other popular nodes.\n\n# Add eigenvector centrality to network object as \"evc\".\n#\n# We also tell it we are treating our data as undirected (\"graph\"), rather than\n# the default directed (\"digraph\").\n#\n# We also say we want a normalized (0-1, sum to 1) score using `rescale =\n# TRUE`.\ntoy_network%v%\"evc\" = evcent(toy_network, gmode = \"graph\", rescale = TRUE)\n\n# Add label as geodesic distance, rounding to 3 digits\ntoy_attributes$label = round(toy_network%v%\"evc\", 3)\n\n# Reset all nodes to grey\ntoy_attributes$color = \"grey\"\n\n# Replace min average geodesic with blue, max with red\ntoy_attributes$color[which(toy_network%v%\"evc\" == max(toy_network%v%\"evc\"))] = \"red\"\ntoy_attributes$color[which(toy_network%v%\"evc\" == min(toy_network%v%\"evc\"))] = \"blue\"\n\n# Plot\nvisNetwork(\n  toy_attributes, toy_edgelist, main = \"Eigenvector Centrality Example\"\n) %&gt;% visInteraction(zoomView = FALSE)",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#network-workflow",
    "href": "chapters/14_network-analysis.html#network-workflow",
    "title": "14  Network Analysis",
    "section": "14.5 Network Workflow",
    "text": "14.5 Network Workflow\nWe have been taking our analyses one step at a time and plotting them. This is useful for learning, but slightly annoying in practice. Below I’ve aggregated how you would actually run analyses in practice so you can refer to it later.\n\n# Data load\ntoy_edgelist = read.csv(\n  \"data/toy_edgelist.csv\", header = TRUE, stringsAsFactors = FALSE\n)\ntoy_attributes = read.csv(\n  \"data/toy_attributes.csv\", header = TRUE, stringsAsFactors = FALSE\n)\n\n# Make a network\n#\n# Sort your attributes frame alphabetically. Super important!\ntoy_attributes = toy_attributes[order(toy_attributes$id), ]\n\n# Make network!\ntoy_network_total = network(toy_edgelist, directed = FALSE)\n\n# Largest component\n#\n# Find what nodes are part of the largest component\ntoy_network_total%v%\"lc\" = component.largest(toy_network_total)\n\n# Delete those nodes that are not in the component\nin_lc = toy_network_total%v%\"lc\"\ntoy_network = delete.vertices(toy_network_total, which(!in_lc))\n\n# In our data frames\ntoy_attributes = toy_attributes[\n  toy_attributes$id %in% as.character(toy_network_total%v%\"vertex.names\"),\n]\n\nin_lc = toy_edgelist$to %in% toy_attributes$id |\n  toy_edgelist$from %in% toy_attributes$id\ntoy_edgelist = toy_edgelist[which(in_lc),]\n\n# Generate measures\n\n# Degree\ntoy_network_total%v%\"degree\" = degree(toy_network_total)\n\n# Mean geodesic\ntoy_network_total%v%\"mean_distance\" =\n  (colSums(geodist(toy_network_total)$gdist)) /\n  (nrow(as.sociomatrix(toy_network_total)) - 1)\n\n# Normalized betweenness\ntoy_network_total%v%\"norm_betweenness\" = betweenness(\n  dat = toy_network_total, gmode = \"graph\", rescale = TRUE,\n  cmode = \"undirected\"\n)\n\n# Eigenvector\ntoy_network_total%v%\"evc\" = evcent(\n  toy_network_total, gmode = \"graph\", rescale = TRUE\n)\n\n# Add back to attributes data frame\n\n# Degree\ntoy_attributes$degree = toy_network_total%v%\"degree\"\n\n# Mean geodesic\ntoy_attributes$mean_distance = toy_network_total%v%\"mean_distance\"\n\n# Normalized betweenness\ntoy_attributes$norm_betweenness = toy_network_total%v%\"norm_betweenness\"\n\n## Eigenvector\ntoy_attributes$evc = toy_network_total%v%\"evc\"\n\nFinally, we can then look at the network measures for our nodes. This data frame can be used for plotting or further analyses.\n\nhead(toy_attributes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nyear\ncolor\ndegree\nmean_distance\nnorm_betweenness\nevc\n\n\n\n\n22\n028f5d1f351d38cd6553ab4674b19725d5ea3d3c\nNA\nNA\n2\n3.131579\n0\n0.0218579\n\n\n15\n19d5b2694036f6fab966564c1c44bc74330f22c2\nNA\nNA\n2\n3.131579\n0\n0.0218579\n\n\n30\n1ae1327030b801f0046278d197378603b51de4b7\nNA\nNA\n2\n3.131579\n0\n0.0218579\n\n\n67\n258f00e649e6a452acb67cb9297c88820c05e2a7\nNA\nNA\n2\n3.131579\n0\n0.0218579\n\n\n65\n2e9fed34d6b2d42052850b46aeaa97f9fe6542dc\nNA\nNA\n2\n3.131579\n0\n0.0218579\n\n\n75\n3220545023e21c80db2a4d4e10b3eb4217b90605\nNA\nNA\n2\n3.131579\n0\n0.0218579",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#network-tools",
    "href": "chapters/14_network-analysis.html#network-tools",
    "title": "14  Network Analysis",
    "section": "14.6 Network Tools",
    "text": "14.6 Network Tools\nThere are several ways to interact with network data in R. Thus far we have been using a combination of statnet for analysis and visNetwork for visualization. Here we’ll gloss over some other tools and what they are used for. Rather than a comprehensive tutorial, this section is just meant to introduce you to what tools are out there so you can investigate them further if you have a need for them.\n\n14.6.1 Network Models\n\n14.6.1.1 statnet\nstatnet is one of the two largest network packages in R. It allows you to create network objects and generate the network measures we’ve been looking at this far. statnet’s claim to fame however is it’s ability to run network simulations, called exponential random graph models (ERGMs). These models allow you to keep some aspect of a network constant and generate random networks that fit your specifications. This can help you highlight one structural aspect of a network and prove that, all else being random, it is important.\n\n\n\n\n\n\nSee also\n\n\n\nTo learn more about ERGMs, see (Robins, Pattison, et al. 2007; Robins, Snijders, et al. 2007). Learn more on the statnet website.\n\n\n\n\n14.6.1.2 igraph\nigraph is the other big network package in R. It has more network measures than statnet, but less robust simulation capabilities. While the same network concepts you’ve learned with statnet will help you understand all networks, the code syntax for igraph is different, so you can’t use the two tools interchangeably. Notably, some functions are named the same in statnet and igraph, so it is advised not to load both at the same time.\n\n\n\n\n\n\nSee also\n\n\n\nLearn more on the igraph website.\n\n\n\n\n14.6.1.3 intergraph\nintergraph is a utility package in R to convert between statnet and igraph network objects. This means you can prepare your data in your package of choice, then convert your network and use what tools you need from the other package.\n\n\n14.6.1.4 tidygraph\ntidygraph is a relatively new tool in R, built to use Tidyverse syntax. It can do many of the same basic network analyses of the two older packages, but lacks the breadth of igraph and the simulation capabilities of statnet.\n\n\n\n\n\n\nSee also\n\n\n\nLearn more on the tidygraph website.\n\n\n\n\n\n14.6.2 Network Visualization\n\n14.6.2.1 Built-in\nWhile we avoided it today, all network packages have built in visualization capabilities that can look nice if you work on it. The advantage of these is that you can use the network objects themselves to pull attributes from the networks for your plots (for example, pull degree centrality from node size).\n\n\n14.6.2.2 visNetwork\nvisNetwork can make some nice interactive network visualizations with relatively simple code. This is great for learning and for exploring networks interactively. However, it does have significant downsides. For one, you have to keep separate data frames for your edges and attributes as it cannon run directly on network objects. Most importantly it cannot produce static network images! You will most likely need more static plots than interactive ones. If you can only dig deeply into one tool, this one may not be the best to specialize in.\n\n\n14.6.2.3 ggraph\nggraph uses ggplot syntax to plot networks. There are several packages that do this in various stages of development. To my understanding, ggraph is the most recent incarnation still under active development.\n\n\n\n\n\n\nSee also\n\n\n\nLearn more on the ggraph website.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/14_network-analysis.html#references",
    "href": "chapters/14_network-analysis.html#references",
    "title": "14  Network Analysis",
    "section": "14.7 References",
    "text": "14.7 References\n\n\nAn, Weihua, and Yu-Hsin Liu. 2016. “Keyplayer: An R\nPackage for Locating Key Players in Social\nNetworks.” The R Journal 8 (1): 257. https://doi.org/10.32614/RJ-2016-018.\n\n\nBalaban, Alexandru T. 1985. “Applications of Graph Theory in\nChemistry.” Journal of Chemical Information and Modeling\n25 (3): 334–43. https://doi.org/10.1021/ci00047a033.\n\n\nBassett, Danielle S., and Olaf Sporns. 2017. “Network\nNeuroscience.” Nature Neuroscience 20 (3): 353–64. https://doi.org/10.1038/nn.4502.\n\n\nFan, Chao, and Ali Mostafavi. 2019. “A Graph-Based Method for\nSocial Sensing of Infrastructure Disruptions in Disasters.”\nComputer-Aided Civil and Infrastructure Engineering 34 (12):\n1055–70. https://doi.org/10.1111/mice.12457.\n\n\nKadushin, Charles. 2012. Understanding Social Networks:\nTheories, Concepts, and\nFindings. New York, NY: Oxford\nUniversity Press.\n\n\nKrebs, Valdis E. 2002. “Mapping Networks of Terrorist\nCells.” Connections 24 (3): 43–52.\n\n\nMoreno, Jacob L. 1953. “Who Shall Survive?:\nFoundations of Sociometry, Group\nPsychotherapy and Sociodrama.” In.\nBeacon, N.Y.: Beacon House Inc.\n\n\nPage, Lawrence. 2001. Method for node ranking in a linked database.\nUS6285999B1, issued September 2001. https://patents.google.com/patent/US6285999/en.\n\n\nRobins, Garry, Pip Pattison, Yuval Kalish, and Dean Lusher. 2007.\n“An Introduction to Exponential Random Graph (p*) Models for\nSocial Networks.” Social Networks, Special\nSection: Advances in Exponential Random\nGraph (p*) Models, 29 (2): 173–91. https://doi.org/10.1016/j.socnet.2006.08.002.\n\n\nRobins, Garry, Tom Snijders, Peng Wang, Mark Handcock, and Philippa\nPattison. 2007. “Recent Developments in Exponential Random Graph\n(p*) Models for Social Networks.” Social Networks,\nSpecial Section: Advances in Exponential\nRandom Graph (p*) Models, 29 (2): 192–215. https://doi.org/10.1016/j.socnet.2006.08.003.\n\n\nWasserman, Stanley, and Katherine Faust. 1994. Social Network\nAnalysis: Methods and Applications. Cambridge,\nUK: Cambridge University Press.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Network Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html",
    "href": "chapters/15_natural-language-processing.html",
    "title": "15  Natural Language Processing",
    "section": "",
    "text": "15.1 Using a File Manifest\nIn this lesson, we’ll be preparing a collection of texts for computational analysis. Before we start that work in full, we’re going to load in a file manifest, which will help us a) identify what’s in our collection; and b) keep track of things like the order of texts.\nmanifest &lt;- read.csv(\"data/C19_novels_manifest.csv\", row.names = 1)\nmanifest\n\n   last_name  first_name                         title year genre\n1   Beckford     William                        Vathek 1786     G\n2  Radcliffe         Ann              ASicilianRomance 1790     G\n3  Radcliffe         Ann         TheMysteriesofUdolpho 1794     G\n4      Lewis     Matthew                       TheMonk 1795     G\n5     Austen        Jane           SenseandSensibility 1811     N\n6    Shelley        Mary                  Frankenstein 1818     G\n7      Scott      Walter                       Ivanhoe 1820     N\n8        Poe  EdgarAllen TheNarrativeofArthurGordonPym 1838     N\n9     Bronte       Emily              WutheringHeights 1847     G\n10 Hawthorne   Nathaniel      TheHouseoftheSevenGables 1851     N\n11   Gaskell   Elizabeth                 NorthandSouth 1854     N\n12   Collins      Wilkie               TheWomaninWhite 1860     N\n13   Dickens     Charles             GreatExpectations 1861     N\n14     James       Henry               PortraitofaLady 1881     N\n15 Stevenson RobertLouis                TreasureIsland 1882     N\n16 Stevenson RobertLouis                 JekyllandHyde 1886     G\n17     Wilde       Oscar        ThePictureofDorianGray 1890     G\n18    Stoker        Bram                       Dracula 1897     G\nAs you can see, in addition to the author and title listings, we also have a genre tag. G is for “Gothic” literature, while N is “not Gothic.” Let’s convert the datatype for the genre column into a factor, which will make life easier later on.\nmanifest$genre &lt;- as.factor(manifest$genre)",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#loading-a-corpus",
    "href": "chapters/15_natural-language-processing.html#loading-a-corpus",
    "title": "15  Natural Language Processing",
    "section": "15.2 Loading a Corpus",
    "text": "15.2 Loading a Corpus\nWith our metadata loaded, it’s time to bring in our files. We’ll be using files stored in an RDS format, though you could also load straight from a directory with a combination of lapply and readLines.\n\nfiles &lt;- readRDS(\"data/C19_novels_raw.rds\")\n\nLoading our files like this will create a giant list of vectors, where each vector is a full text file. Those vectors are chunked by paragraph right now, but for our purposes it would be easier if each vector was a single stream of text (like the output of ocr, if you’ll remember). We can collapse them together with paste.\n\nfiles &lt;- lapply(files, paste, collapse = \" \")\n\nFrom here, we can wrap these files in a special “corpus” object, which the tm package enables (a corpus is a large collection of texts). A tm corpus works somewhat like a database. It has a section for “content”, which contains text data, as well as various metadata sections, which we can populate with additional information about our texts, if we wished. Taken together, these features make it easy to streamline workflows with text data.\nTo make a corpus with tm, we call the Corpus function, specifying with VectorSource (because our texts are vectors):\n\nlibrary(\"tm\")\ncorpus &lt;- Corpus(VectorSource(files))\n\nHere’s a high-level glimpse at what’s in this object:\n\ncorpus\n\n&lt;&lt;SimpleCorpus&gt;&gt;\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 18\n\n\nZooming in to metadata about a text in the corpus:\n\ncorpus[[6]]\n\n&lt;&lt;PlainTextDocument&gt;&gt;\nMetadata:  7\nContent:  chars: 424017\n\n\nNot much here so far, but we’ll add more later.\nFinally, we can get content from a text:\n\nlibrary(\"stringr\")\n\nstr_sub(corpus[[6]]$content, start = 1, end = 500)\n\n[1] \"FRANKENSTEIN:  OR,  THE MODERN PROMETHEUS.  BY MARY W. SHELLEY.  PREFACE.  The event on which this fiction is founded, has been supposed, by Dr. Darwin, and some of the physiological writers of Germany, as not of impossible occurrence. I shall not be supposed as according the remotest degree of serious faith to such an imagination; yet, in assuming it as the basis of a work of fancy, I have not considered myself as merely weaving a series of supernatural terrors. The event on which the interest \"\n\n\nIn this last view, you can see that the text file is still formatted (at least we didn’t have to OCR it!). This formatting is unwieldy and worse, it makes it so we can’t really access the elements that comprise each novel. We’ll need to do more work to preprocess our texts before we can analyze them.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#preprocessing",
    "href": "chapters/15_natural-language-processing.html#preprocessing",
    "title": "15  Natural Language Processing",
    "section": "15.3 Preprocessing",
    "text": "15.3 Preprocessing\nPart of preprocessing entails making decisions about the kinds of information we want to know about our data. Knowing what information we want often guides the way we structure data. Put another way: research questions drive preprocessing.\n\n15.3.1 Tokenizing and Bags of Words\nFor example, it’d be helpful to know how many words are in each novel, which might enable us to study patterns and differences between authors’ styles. To get word counts, we need to split the text vectors into individual words. One way to do this would be to first strip out everything in each novel that isn’t an alphabetic character or a space. Let’s grab one text to experiment with.\n\nfrankenstein &lt;- corpus[[6]]$content\nfrankenstein &lt;- str_replace_all(\n  frankenstein, pattern = \"[^A-Za-z]\", replacement = \" \"\n)\n\nFrom here, it would be easy enough to count the words in a novel by splitting its vector on spaces, removing empty elements in the vector, and calling length on the vector. The end result is what we call a bag of words.\n\nfrankenstein &lt;- str_split(frankenstein, \" \")\nfrankenstein &lt;- lapply(frankenstein, function(x) x[x != \"\"])\nlength(frankenstein[[1]])\n\n[1] 76015\n\n\nAnd here are the first nine words (or “tokens”):\n\nfrankenstein[[1]][1:9]\n\n[1] \"FRANKENSTEIN\" \"OR\"           \"THE\"          \"MODERN\"       \"PROMETHEUS\"  \n[6] \"BY\"           \"MARY\"         \"W\"            \"SHELLEY\"     \n\n\n\n\n15.3.2 Text Normalization\nWhile easy, producing our bag of words this way is a bit clunky. And further, this process can’t handle contractions (“I’m”, “don’t”, “that’s”) or differences in capitalization.\n\nfrankenstein[[1]][188:191]\n\n[1] \"Midsummer\" \"Night\"     \"s\"         \"Dream\"    \n\n\nShould be:\nMidsummer Night's Dream\nAnd\n\"FRANKENSTEIN\", \"Frankenstein\"\nShould be:\n\"Frankenstein\"\nOr, even better:\nfrankenstein\nTypically, when we work with text data we want all of our words to be in the same case because this makes it easier to do things like counting operations. Remember that, to a computer, “Word” and “word” are two separate words, and if we want to count them together, we need to pick one version or the other. Making all words lowercase (even proper nouns) is the standard. Doing this is part of what’s called text normalization. (Other forms of normalization might entail handling orthographic differences between British and American English, like “color” and “colour”.)\nAs for contractions, we have some decisions to make. On the one hand, it’s important to retain as much information as we can about the original text, so keeping “don’t” or “what’s” (which would be “don t” and “what s” in our current method) is important. One way corpus linguists handle these words is to lemmatize them. Lemmatizing involves removing inflectional endings to return words to their base form:\n\ncar, cars, car’s, cars’ =&gt; car\ndon’t =&gt; do\n\nThis is a helpful step if what we’re primarily interested in is doing a high- level analysis of semantics. On the other hand, though, many words that feature contractions are high-frequency function words, which don’t have much meaning beyond the immediate context of a sentence or two. Words like “that’s” or “won’t” appear in huge numbers in text data, but they don’t carry much information in and of themselves—it may in fact be the case that we could get rid of them entirely…\n\n\n15.3.3 Stop Words\n…and indeed this is the case! When structuring text data to study it at scale, it’s common to remove, or stop out, words that don’t have much meaning. This makes it much easier to identify significant (i.e. unique) features in a text, without having to swim through all the noise of “the” or “that,” which would almost always show up as the highest-occurring words in an analysis. But what words should we remove? Ultimately, this depends on your text data. We can usually assume that function words will be on our list of stop words, but it may be that you’ll have to add or subtract others depending on your data and, of course, your research question.\nThe tm package has a good starting list. Let’s look at the first 100 words.\n\nhead(stopwords(\"SMART\"), 100)\n\n  [1] \"a\"            \"a's\"          \"able\"         \"about\"        \"above\"       \n  [6] \"according\"    \"accordingly\"  \"across\"       \"actually\"     \"after\"       \n [11] \"afterwards\"   \"again\"        \"against\"      \"ain't\"        \"all\"         \n [16] \"allow\"        \"allows\"       \"almost\"       \"alone\"        \"along\"       \n [21] \"already\"      \"also\"         \"although\"     \"always\"       \"am\"          \n [26] \"among\"        \"amongst\"      \"an\"           \"and\"          \"another\"     \n [31] \"any\"          \"anybody\"      \"anyhow\"       \"anyone\"       \"anything\"    \n [36] \"anyway\"       \"anyways\"      \"anywhere\"     \"apart\"        \"appear\"      \n [41] \"appreciate\"   \"appropriate\"  \"are\"          \"aren't\"       \"around\"      \n [46] \"as\"           \"aside\"        \"ask\"          \"asking\"       \"associated\"  \n [51] \"at\"           \"available\"    \"away\"         \"awfully\"      \"b\"           \n [56] \"be\"           \"became\"       \"because\"      \"become\"       \"becomes\"     \n [61] \"becoming\"     \"been\"         \"before\"       \"beforehand\"   \"behind\"      \n [66] \"being\"        \"believe\"      \"below\"        \"beside\"       \"besides\"     \n [71] \"best\"         \"better\"       \"between\"      \"beyond\"       \"both\"        \n [76] \"brief\"        \"but\"          \"by\"           \"c\"            \"c'mon\"       \n [81] \"c's\"          \"came\"         \"can\"          \"can't\"        \"cannot\"      \n [86] \"cant\"         \"cause\"        \"causes\"       \"certain\"      \"certainly\"   \n [91] \"changes\"      \"clearly\"      \"co\"           \"com\"          \"come\"        \n [96] \"comes\"        \"concerning\"   \"consequently\" \"consider\"     \"considering\" \n\n\nThat looks pretty comprehensive so far, though the only way we’ll know whether it’s a good match for our corpus is to process our corpus with it. At first glance, the extra random letters in this list seem like they could be a big help, on the off chance there’s some noise from OCR. If you look at the first novel in the corpus, for example, there are a bunch of stray p’s, which is likely from a pattern for marking pages (“p. 7”):\n\nmessage(str_sub(corpus[[1]]$content, start = 1, end = 1000))\n\nVATHEK;  AN ARABIAN TALE,    BY  WILLIAM BECKFORD, ESQ.    p. 7VATHEK.  Vathek, ninth Caliph [7a] of the race of the Abassides, was the son of Motassem, and the grandson of Haroun Al Raschid.  From an early accession to the throne, and the talents he possessed to adorn it, his subjects were induced to expect that his reign would be long and happy.  His figure was pleasing and majestic; but when he was angry, one of his eyes became so terrible [7b] that no person could bear to behold it; and the wretch upon whom it was fixed instantly fell backward, and sometimes expired.  For fear, however, of depopulating his dominions, and making his palace desolate, he but rarely gave way to his anger.  Being much addicted to women, and the pleasures of the table, he sought by his affability to procure agreeable companions; and he succeeded the better, p. 8as his generosity was unbounded and his indulgences unrestrained; for he was by no means scrupulous: nor did he think, with the Caliph Omar Ben A\n\n\nOur stop word list would take care of this. With it, we could return to our original collection of novels, split them on spaces as before, and filter out everything that’s stored in our stop_list variable. Before we did the filtering, though, we’d need to transform the novels into lowercase (which can be done with stringr’s str_to_lower function).\n\n\n15.3.4 Tokenizers\nThis whole process is ultimately straightforward so far, but it would be nice to collapse all its steps. Luckily, there are packages we can use to streamline our process. The tokenizers package has functions that split a text vector, turn words into lowercase forms, and remove stop words, all in a few lines of code. Further, we can combine these functions with a special tm_map function in the tm package, which will globally apply our changes.\n\nlibrary(\"tokenizers\")\n\ncleaned_corpus &lt;- tm_map(\n  corpus,\n  tokenize_words,\n  stopwords = stopwords('SMART'),\n  lowercase = TRUE,\n  strip_punct = TRUE,\n  strip_numeric = TRUE\n)\n\nYou may see a “transformation drops documents” warning after this. You can disregard it. It has to do with the way tm references text changes against a corpus’s metadata, which we’ve left blank.\nWe can compare our tokenized output with the text data we had been working with earlier:\n\nlist(\n  untokenized = frankenstein[[1]][1:9],\n  tokenized = cleaned_corpus[[6]]$content[1:5]\n)\n\n$untokenized\n[1] \"FRANKENSTEIN\" \"OR\"           \"THE\"          \"MODERN\"       \"PROMETHEUS\"  \n[6] \"BY\"           \"MARY\"         \"W\"            \"SHELLEY\"     \n\n$tokenized\n[1] \"frankenstein\" \"modern\"       \"prometheus\"   \"mary\"         \"shelley\"     \n\n\nFrom the title alone we can see how much of a difference tokenizing with stop words makes. And while we lose a bit of information by doing this, what we can is a much clearer picture of key words we’d want to further analyze.\n\n\n15.3.5 Document Chunking and N-grams\nFinally, it’s possible to change the way we separate out our text data. Instead of tokenizing on words, we could use the tokenizers package to break apart our texts on paragraphs (tokenize_paragraphs), sentences (tokenize_sentences), and more. There might be valuable information to be learned about the average sentence length of a novel, for example, so we might chunk it accordingly.\nWe might also want to see whether a text contains repeated phrases, or if two or three words often occur in the same sequence. We could investigate this by adjusting the window around which we tokenize individual words. So far we’ve used the “unigram,” or a single word, as our basic unit of counting, but we could break our texts into “bigrams” (two word phrases), “trigrams” (three word phrases), or, well any sequence of \\(n\\) units. Generally, you’ll see these sequences referred to as n-grams:\n\nfrankenstein_bigrams &lt;- tokenize_ngrams(\n  corpus[[6]]$content,\n  n = 2,\n  stopwords = stopwords(\"SMART\")\n)\n\nHere, n = 2 sets the n-gram window at two:\n\nfrankenstein_bigrams[[1]][1:20]\n\n [1] \"frankenstein modern\"   \"modern prometheus\"     \"prometheus mary\"      \n [4] \"mary shelley\"          \"shelley preface\"       \"preface event\"        \n [7] \"event fiction\"         \"fiction founded\"       \"founded supposed\"     \n[10] \"supposed dr\"           \"dr darwin\"             \"darwin physiological\" \n[13] \"physiological writers\" \"writers germany\"       \"germany impossible\"   \n[16] \"impossible occurrence\" \"occurrence supposed\"   \"supposed remotest\"    \n[19] \"remotest degree\"       \"degree faith\"         \n\n\nNote though that, for this function, we’d need to do some preprocessing on our own to remove numeric characters and punctuation; tokenize_ngrams won’t do it for us.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#counting-terms",
    "href": "chapters/15_natural-language-processing.html#counting-terms",
    "title": "15  Natural Language Processing",
    "section": "15.4 Counting Terms",
    "text": "15.4 Counting Terms\nLet’s return to our single word counts. Now that we’ve transformed our novels into bags of single words, we can start with some analysis. Simply counting the number of times a word appears in some data can tell us a lot about a text. The following steps should feel familiar: we did them with OCR.\nLet’s look at Wuthering Heights, which is our ninth text:\n\nlibrary(\"tidyverse\")\n\nwuthering_heights &lt;- table(cleaned_corpus[[9]]$content)\nwuthering_heights &lt;- data.frame(\n  word = names(wuthering_heights),\n  count = as.numeric(wuthering_heights)\n)\nwuthering_heights &lt;- arrange(wuthering_heights, desc(count))\n\nhead(wuthering_heights, 30)\n\n         word count\n1  heathcliff   422\n2      linton   348\n3   catherine   339\n4          mr   312\n5      master   185\n6     hareton   169\n7    answered   156\n8        till   151\n9       house   144\n10       door   133\n11        mrs   133\n12     joseph   130\n13       miss   129\n14       time   127\n15       back   121\n16    thought   118\n17      cathy   117\n18       good   117\n19    replied   117\n20   earnshaw   116\n21       eyes   116\n22      cried   114\n23      young   107\n24        day   106\n25     father   106\n26      asked   105\n27       make   105\n28      edgar   104\n29      night   104\n30       made   102\n\n\nLooks good! The two main characters in this novel are named Heathcliff and Catherine, so it makes sense that these words would appear a lot. You can see, however, that we might want to fine tune our stop word list so that it removes “mr” and “mrs” from the text. Though again, it depends on our research question. If we’re exploring gender roles in nineteenth-century literature, we’d probably keep those words in.\nIn addition to fine tuning stop words, pausing here at these counts would be a good way to check whether some other form of textual noise is present in your data, which you haven’t yet caught. There’s nothing like that here, but you might imagine how consistent OCR noise could make itself known in this view.\n\n15.4.1 Term Frequency\nAfter you’ve done your fine tuning, it would be good to get a term frequency number for each word in this data frame. Raw counts are nice, but expressing those counts in proportion to the total words in a document will tell us more information about a word’s contribution to the document as a whole. We can get term frequencies for our words by dividing a word’s count by document length (which is the sum of all words in the document).\n\nwuthering_heights$term_frequency &lt;- sapply(\n  wuthering_heights$count,\n  function(x) x / sum(wuthering_heights$count)\n)\nhead(wuthering_heights, 30)\n\n         word count term_frequency\n1  heathcliff   422    0.009619549\n2      linton   348    0.007932709\n3   catherine   339    0.007727552\n4          mr   312    0.007112084\n5      master   185    0.004217101\n6     hareton   169    0.003852379\n7    answered   156    0.003556042\n8        till   151    0.003442066\n9       house   144    0.003282500\n10       door   133    0.003031754\n11        mrs   133    0.003031754\n12     joseph   130    0.002963368\n13       miss   129    0.002940573\n14       time   127    0.002894983\n15       back   121    0.002758212\n16    thought   118    0.002689827\n17      cathy   117    0.002667031\n18       good   117    0.002667031\n19    replied   117    0.002667031\n20   earnshaw   116    0.002644236\n21       eyes   116    0.002644236\n22      cried   114    0.002598646\n23      young   107    0.002439080\n24        day   106    0.002416285\n25     father   106    0.002416285\n26      asked   105    0.002393490\n27       make   105    0.002393490\n28      edgar   104    0.002370695\n29      night   104    0.002370695\n30       made   102    0.002325104\n\n\n\n\n15.4.2 Plotting Term Frequency\nLet’s plot the top 50 words in Wuthering Heights. We’ll call fct_reorder in the aes layer of ggplot to sort words in the descending order of their term frequency.\n\nlibrary(\"ggplot2\")\n\nggplot(wuthering_heights[1:50, ]) +\n  aes(x = fct_reorder(word, -term_frequency), y = term_frequency) +\n  geom_bar(stat =\"identity\") +\n  theme(\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)\n  ) +\n  labs(\n    title = \"Top 50 words in Wuthering Heights\",\n    x = \"Word\",\n    y = \"Term Frequency\"\n  )\n\n\n\n\n\n\n\n\nThis is a good start for creating a high-level view of the novel, but further tuning might be in order. We’ve already mentioned “mrs” and “mr” as two words that we could cut out of the text. Another option would be to collapse these two words together into a base form by stemming them. Though this would overweight their base form (which in this case is “mr”) in terms of term frequency, it would also free up space to see other terms in the document. Other examples of stemming words would be transforming “fishing”, “fished”, and “fisher” all into “fish.”\nThat said, like all preprocessing, lemmatizing words is an interpretive decision, which comes with its own consequences. Maybe it’s okay to transform “mr” and “mrs” into “mr” for some analyses, but it’s also the case that we’d be erasing potentially important gender differences in the text—and would do so by overweighting the masculine form of the word. Regardless of what you decide, it’s important to keep track of these decisions as you make them because they will impact the kinds of claims you make about your data later on.\n\n\n15.4.3 Comparing Term Frequencies Across Documents\nTerm frequency is helpful if we want to start comparing words across two texts. We can make some comparisons by transforming the above code into a function:\n\nterm_table &lt;- function(text) {\n  term_tab &lt;- table(text)\n\n  term_tab &lt;- data.frame(word = names(term_tab), count = as.numeric(term_tab))\n  term_tab$term_frequency &lt;- sapply(\n    term_tab$count,\n    function(x) (x/sum(term_tab$count))\n  )\n\n  arrange(term_tab, desc(count))\n}\n\nWe already have a term table for Wuthering Heights. Let’s make one for Dracula:\n\ndracula &lt;- term_table(cleaned_corpus[[18]]$content)\nhead(dracula, 30)\n\n        word count term_frequency\n1       time   387    0.007280458\n2        van   321    0.006038829\n3    helsing   299    0.005624953\n4       back   261    0.004910076\n5       room   231    0.004345699\n6       good   225    0.004232824\n7       lucy   225    0.004232824\n8        man   224    0.004214012\n9       dear   219    0.004119949\n10      mina   217    0.004082324\n11     night   217    0.004082324\n12      hand   209    0.003931823\n13      face   205    0.003856573\n14      door   201    0.003781323\n15      made   193    0.003630822\n16      poor   192    0.003612010\n17     sleep   190    0.003574385\n18      eyes   186    0.003499135\n19    looked   185    0.003480322\n20    friend   183    0.003442697\n21     great   182    0.003423884\n22  jonathan   182    0.003423884\n23        dr   178    0.003348634\n24    things   174    0.003273384\n25      make   163    0.003066446\n26       day   160    0.003010008\n27 professor   155    0.002915946\n28     count   153    0.002878320\n29     found   153    0.002878320\n30   thought   153    0.002878320\n\n\nNow we can compare the relative frequency of a word across two novels:\n\ncomparison_words &lt;- c(\"dark\", \"night\", \"ominous\")\nfor (i in comparison_words) {\n  wh &lt;- list(wh = subset(wuthering_heights, word == i))\n  drac &lt;- list(drac = subset(dracula, word == i))\n  print(wh)\n  print(drac)\n}\n\n$wh\n    word count term_frequency\n183 dark    32   0.0007294445\n\n$drac\n   word count term_frequency\n90 dark    77    0.001448566\n\n$wh\n    word count term_frequency\n29 night   104    0.002370695\n\n$drac\n    word count term_frequency\n11 night   217    0.004082324\n\n$wh\n        word count term_frequency\n7283 ominous     1   2.279514e-05\n\n$drac\n        word count term_frequency\n7217 ominous     1   1.881255e-05\n\n\nNot bad! We might be able to make a few generalizations from this, but to say anything definitively, we’ll need to scale our method. Doing so wouldn’t be easy with this setup as it stands now. While it’s true that we could write some functions to roll through these two data frames and systematically compare the words in each, it would take a lot of work to do so. Luckily, the tm package (which we’ve used to make our stop word list) features generalized functions for just this kind of thing.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#text-mining-pipepline",
    "href": "chapters/15_natural-language-processing.html#text-mining-pipepline",
    "title": "15  Natural Language Processing",
    "section": "15.5 Text Mining Pipepline",
    "text": "15.5 Text Mining Pipepline\nBefore going further, we should note that tm has its own functions for preprocessing texts. To send raw files directly through those functions, you’d call tm_map in conjunction with these functions. You can think of tm_map as a cognate to the apply family.\ncorpus_2 &lt;- Corpus(VectorSource(files))\ncorpus_2 &lt;- tm_map(corpus_2, removeNumbers)\ncorpus_2 &lt;- tm_map(corpus_2, removeWords, stopwords(\"SMART\"))\ncorpus_2 &lt;- tm_map(corpus_2, removePunctuation)\ncorpus_2 &lt;- tm_map(corpus_2, stripWhitespace)\nNote the order of operations here: because our stop words list takes into account punctuated words, like “don’t” or “i’m”, we want to remove stop words before removing punctuation. If we didn’t do this, removeWords wouldn’t catch the un-punctuated “dont” or “im”. This won’t always be the case, since we can use different stop word lists, which may have a different set of terms, but in this instance, the order in which we preprocess matters.\nPreparing your text files like this would be fine, and indeed sometimes it’s preferable to sequentially step through each part of the preprocessing workflow. That said, tokenizers manages the order of operations above on its own and its preprocessing functions are generally a bit faster to run (in particular, removeWords is quite slow in comparison to tokenize_words).\nThere is, however, one caveat to using tokenizers. It splits documents up to do text cleaning, but other functions in tm require non-split documents. If we use tokenizers, then, we need to do a quick workaround with paste.\n\ncleaned_corpus &lt;- lapply(cleaned_corpus, paste, collapse = \" \")\n\nAnd then reformat that output as a corpus object:\n\ncleaned_corpus &lt;- Corpus(VectorSource(cleaned_corpus))\n\nUltimately, it’s up to you to decide what workflow makes sense. Personally, I (Tyler) like to do exploratory preprocessing steps with tokenizers, often with a sample set of all the documents. Then, once I’ve settled on my stop word list and so forth, I reprocess all my files with the tm-specific functions above.\nRegardless of what workflow you choose, preprocessing can take a while, so now would be a good place to save your data. That way, you can retrieve your corpus later on.\n\nsaveRDS(cleaned_corpus, \"data/C19_novels_cleaned.rds\")\n\nLoading it back in is straightforward:\n\ncleaned_corpus &lt;- readRDS(\"data/C19_novels_cleaned.rds\")",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#document-term-matrix",
    "href": "chapters/15_natural-language-processing.html#document-term-matrix",
    "title": "15  Natural Language Processing",
    "section": "15.6 Document Term Matrix",
    "text": "15.6 Document Term Matrix\nThe advantage of using a tm corpus is that it makes comparing data easier. Remember that, in our old workflow, looking at the respective term frequencies in two documents entailed a fair bit of code. And further, we left off before generalizing that code to the corpus as a whole. But what if we wanted to look at a term across multiple documents?\nTo do so, we need to create what’s called a document-term matrix, or DTM. A DTM describes the frequency of terms across an entire corpus (rather than just one document). Rows of the matrix correspond to documents, while columns correspond to the terms. For a given document, we count the number of times that term appears and enter that number in the column in question. We do this even if the count is 0; key to the way a DTM works is that it’s a corpus-wide representation of text data, so it matters if a text does or doesn’t contain a term.\nHere’s a simple example with three documents:\n\nDocument 1: “I like cats”\nDocument 2: “I like dogs”\nDocument 3: “I like both cats and dogs”\n\nTransforming these into a document-term matrix would yield:\n\n\n\nn_doc\nI\nlike\nboth\ncats\nand\ndogs\n\n\n\n\n1\n1\n1\n0\n1\n0\n0\n\n\n2\n1\n1\n0\n0\n0\n1\n\n\n3\n1\n1\n1\n1\n1\n1\n\n\n\nRepresenting texts in this way is incredibly useful because it enables us to easily discern similarities and differences in our corpus. For example, we can see that each of the above documents contain the words “I” and “like.” Given that, if we wanted to know what makes documents unique, we can ignore those two words and focus on the rest of the values.\nNow, imagine doing this for thousands of words! What patterns might emerge?\nLet’s try it on our corpus. We can transform a tm corpus object into a DTM by calling DocumentTermMatrix.\n\n\n\n\n\n\nWarning\n\n\n\nDocumentTermMatrix is one of the functions in the tm package that requires non-split documents, so before you call it make sure you know how you’ve preprocessed your texts!\n\n\n\ndtm &lt;- DocumentTermMatrix(cleaned_corpus)\n\nThis object is quite similar to the one that results from Corpus: it contains a fair bit of metadata, as well as an all-important dimnames field, which records the documents in the matrix and the entire term vocabulary. We access all of this information with the same syntax we use for data frames.\nLet’s look around a bit and get some high-level info.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/15_natural-language-processing.html#corpus-analytics",
    "href": "chapters/15_natural-language-processing.html#corpus-analytics",
    "title": "15  Natural Language Processing",
    "section": "15.7 Corpus Analytics",
    "text": "15.7 Corpus Analytics\nNumber of columns in the DTM (that is, the vocabulary size):\n\ndtm$ncol\n\n[1] 34925\n\n\nNumber of rows in the DTM (that is, the number of documents this matrix represents):\n\ndtm$nrow\n\n[1] 18\n\n\nRight now, the document names are just a numbers in a vector:\n\ndtm$dimnames$Docs\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n\nBut they’re ordered according to the sequence in which the corpus was originally created. This means we can use our metadata from way back when to associate a document with its title:\n\ndtm$dimnames$Docs &lt;- manifest$title\ndtm$dimnames$Docs\n\n [1] \"Vathek\"                        \"ASicilianRomance\"             \n [3] \"TheMysteriesofUdolpho\"         \"TheMonk\"                      \n [5] \"SenseandSensibility\"           \"Frankenstein\"                 \n [7] \"Ivanhoe\"                       \"TheNarrativeofArthurGordonPym\"\n [9] \"WutheringHeights\"              \"TheHouseoftheSevenGables\"     \n[11] \"NorthandSouth\"                 \"TheWomaninWhite\"              \n[13] \"GreatExpectations\"             \"PortraitofaLady\"              \n[15] \"TreasureIsland\"                \"JekyllandHyde\"                \n[17] \"ThePictureofDorianGray\"        \"Dracula\"                      \n\n\nWith this information associated, we can use inspect to get a high-level view of the corpus:\n\ninspect(dtm)\n\n&lt;&lt;DocumentTermMatrix (documents: 18, terms: 34925)&gt;&gt;\nNon-/sparse entries: 145233/483417\nSparsity           : 77%\nMaximal term length: 19\nWeighting          : term frequency (tf)\nSample             :\n                          Terms\nDocs                       back day eyes good great long made man thought time\n  Dracula                   261 160  186  225   182  147  193 224     153  387\n  GreatExpectations         244 216  180  256   198  173  300 307     238  373\n  Ivanhoe                    77 138  100  298   111  154  151 235      46  182\n  NorthandSouth             184 257  197  316   179  211  234 270     332  423\n  PortraitofaLady           210 241  226  520   421  187  381 317     302  339\n  TheHouseoftheSevenGables   79 113   72  100   144  153  144 211      60  113\n  TheMonk                    81 106  184   80    66  108  167  95      72  162\n  TheMysteriesofUdolpho     117 167  225  186   164  359  316 213     341  367\n  TheWomaninWhite           417 351  233  235   112  188  244 443     183  706\n  WutheringHeights          121 106  116  117    63   97  102  88     118  127\n\n\nOf special note here is sparsity. Sparsity measures the amount of 0s in the data. This happens when a document does not contain a term that appears elsewhere in the corpus. In our case, of the 628,650 entries in this matrix, 80% of them are 0. Such is the way of working with DTMs: they’re big, expansive data structures that have a lot of empty space.\nWe can zoom in and filter on term counts with findFreqTerms. Here are terms that appear more than 1,000 times in the corpus:\n\nfindFreqTerms(dtm, 1000)\n\n [1] \"answered\" \"appeared\" \"asked\"    \"back\"     \"day\"      \"dear\"    \n [7] \"death\"    \"door\"     \"eyes\"     \"face\"     \"father\"   \"felt\"    \n[13] \"found\"    \"friend\"   \"gave\"     \"give\"     \"good\"     \"great\"   \n[19] \"half\"     \"hand\"     \"hands\"    \"head\"     \"hear\"     \"heard\"   \n[25] \"heart\"    \"hope\"     \"kind\"     \"knew\"     \"lady\"     \"leave\"   \n[31] \"left\"     \"life\"     \"light\"    \"long\"     \"looked\"   \"love\"    \n[37] \"made\"     \"make\"     \"man\"      \"men\"      \"mind\"     \"moment\"  \n[43] \"morning\"  \"mother\"   \"night\"    \"part\"     \"passed\"   \"people\"  \n[49] \"person\"   \"place\"    \"poor\"     \"present\"  \"put\"      \"replied\" \n[55] \"returned\" \"round\"    \"side\"     \"speak\"    \"stood\"    \"thing\"   \n[61] \"thou\"     \"thought\"  \"till\"     \"time\"     \"told\"     \"turned\"  \n[67] \"voice\"    \"woman\"    \"words\"    \"world\"    \"young\"    \"count\"   \n[73] \"house\"    \"madame\"   \"room\"     \"sir\"      \"emily\"    \"margaret\"\n[79] \"miss\"     \"mrs\"      \"isabel\"  \n\n\nUsing findAssocs, we can also track which words rise and fall in usage alongside a given word. (The number in the third argument position of this function is a cutoff for the strength of a correlation.)\nHere’s “boat”:\n\nfindAssocs(dtm, \"boat\", .85)\n\n$boat\n  thumping scoundrels     midday  direction \n      0.94       0.88       0.87       0.85 \n\n\nHere’s “writing” (there are a lot of terms, so we’ll limit to 15):\n\nwriting &lt;- findAssocs(dtm, \"writing\", .85)\nwriting[[1]][1:15]\n\n     letter        copy    disposal   inquiries    bedrooms   hindrance \n       0.99        0.97        0.97        0.97        0.97        0.97 \n   messages certificate    distrust     plainly    drawings   anonymous \n       0.97        0.97        0.96        0.96        0.96        0.96 \n   ladyship  plantation    lodgings \n       0.96        0.96        0.96 \n\n\n\n15.7.1 Corpus Term Counts\nFrom here, it would be useful to get a full count of all the terms in the corpus. We can transform the DTM into a matrix and then a data frame:\n\nterm_counts &lt;- as.matrix(dtm)\nterm_counts &lt;- data.frame(sort(colSums(term_counts), decreasing = TRUE))\nterm_counts &lt;- cbind(newColName = rownames(term_counts), term_counts)\ncolnames(term_counts) &lt;- c(\"term\", \"count\")\n\nAs before, let’s plot the top 50 terms in these counts, but this time, they will cover the entire corpus:\n\nggplot(term_counts[1:50, ]) +\n  aes(x = fct_reorder(term, -count), y = count) +\n  geom_bar(stat = \"identity\") +\n  theme(\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)\n  ) +\n  labs(\n    title = \"Top 50 words in 18 Nineteenth-Century Novels\",\n    x = \"Word\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThis looks good, though the words here are all pretty common. In fact, many of them are simply the most common words in the English language. “Time” is the 64th-most frequent word in English; “make” is the 50th. As it stands, then, this graph doesn’t tell us very much about the specificity of our particular collection of texts; if we ran the same process on English novels from the twentieth century, we’d probably produce very similar output.\n\n\n15.7.2 TF-IDF Scores\nGiven this, if we want to know what makes our corpus special, we need a measure of uniqueness for the terms it contains. One of the most common ways to do this is to get what’s called a TF-IDF score (short for “term frequency-inverse document frequency”) for each term in our corpus. TF-IDF is a weighting method. It increases proportionally to the number of times a word appears in a document but is importantly offset by the number of documents in the corpus that contain this term. This offset adjusts for common words across a corpus, pushing their scores down while boosting the scores of rarer terms in the corpus.\nInverse document frequency can be expressed as:\n\\[\\begin{align*}\nidf_i = log(\\frac{n}{df_i})\n\\end{align*}\\]\nWhere \\(idf_i\\) is the idf score for term \\(i\\), \\(df_i\\) is the number of documents that contain \\(i\\), and \\(n\\) is the total number of documents.\nA TF-IDF score can be calculated by the following:\n\\[\\begin{align*}\nw_i,_j = tf_i,_j \\times idf_i\n\\end{align*}\\]\nWhere \\(w_i,_j\\) is the TF-IDF score of term \\(i\\) in document \\(j\\), \\(tf_i,_j\\) is the term frequency for \\(i\\) in \\(j\\), and \\(idf_i\\) is the inverse document score.\nWhile it’s good to know the underlying equations here, you won’t be tested on the math specifically. And as it happens, tm has a way to perform the above math for each term in a corpus. We can implement TF-IDF scores when making a document-term matrix:\n\ndtm_tfidf &lt;- DocumentTermMatrix(\n  cleaned_corpus,\n  control = list(weighting = weightTfIdf)\n)\ndtm_tfidf$dimnames$Docs &lt;- manifest$title\n\nTo see what difference it makes, let’s plot the top terms in our corpus using their TF-IDF scores:\n\ntfidf_counts &lt;- as.matrix(dtm_tfidf)\ntfidf_counts &lt;- data.frame(sort(colSums(tfidf_counts), decreasing = TRUE))\ntfidf_counts &lt;- cbind(newColName = rownames(tfidf_counts), tfidf_counts)\ncolnames(tfidf_counts) &lt;- c(\"term\", \"tfidf\")\n\n\nggplot(data = tfidf_counts[1:50, ]) +\n  aes(x = fct_reorder(term, -tfidf), y = tfidf) +\n  geom_bar(stat = \"identity\") +\n  theme(\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)\n  ) +\n  labs(\n    title = \"Words with the 50-highest TF-IDF scores in 18 Nineteenth-Century Novels\",\n    x = \"Word\",\n    y = \"TF-IDF\"\n  )\n\n\n\n\n\n\n\n\nLots of names! That makes sense: heavily weighted terms in these novels are going to be terms that are unique to each text. Main characters’ names are used a lot in novels, and the main character names in these novels are all unique.\nTo see in more concrete way how TF-IDF scores might make a difference in the way we analyze our corpus, we’ll do two last things. First, we’ll look again at term correlations, using the same words from above with findAssocs, but this time we’ll use TF-IDF scores.\nHere’s “boat”:\n\nfindAssocs(dtm_tfidf, terms = \"boat\", corlimit = .85)\n\n$boat\n   thumping       shore      bucket      cables         doo       geese \n       0.95        0.93        0.92        0.92        0.92        0.92 \n    pickled         sea      rudder     gunwale  scoundrels       boats \n       0.92        0.91        0.91        0.91        0.91        0.90 \n       keel      sailed        crew    baffling     biscuit    bowsprit \n       0.90        0.89        0.89        0.89        0.89        0.89 \n    hauling     muskets      ripped      splash      anchor         oar \n       0.89        0.89        0.89        0.89        0.88        0.88 \n   rattling       sandy        cook      patted     shipped       beach \n       0.88        0.88        0.88        0.88        0.88        0.87 \n    pistols      seamen     tobacco         lee    bulwarks      hauled \n       0.87        0.87        0.87        0.87        0.87        0.87 \n    inkling      musket  navigation        rags    steering      island \n       0.87        0.87        0.87        0.87        0.87        0.86 \n     bottle     tumbled       avast       belay       bilge   broadside \n       0.86        0.86        0.86        0.86        0.86        0.86 \n   cruising   cutlasses    diagonal   furtively     headway     jupiter \n       0.86        0.86        0.86        0.86        0.86        0.86 \n   mainland      marlin      midday     monthly   mutineers outnumbered \n       0.86        0.86        0.86        0.86        0.86        0.86 \n    plumped     riggers    schooner   schooners   seaworthy    swamping \n       0.86        0.86        0.86        0.86        0.86        0.86 \n     tide's      tiller     tonnage       towed       yawed        sail \n       0.86        0.86        0.86        0.86        0.86        0.85 \n       ship         tap     loading       sails         aft      berths \n       0.85        0.85        0.85        0.85        0.85        0.85 \n     pinned \n       0.85 \n\n\nHere’s “writing”:\n\nfindAssocs(dtm_tfidf, terms = \"writing\", corlimit = .85)\n\n$writing\n    hindrance      messages      disposal     inquiries      bedrooms \n         0.92          0.91          0.90          0.90          0.89 \n     ladyship          copy      lodgings        london    unforeseen \n         0.88          0.87          0.87          0.87          0.87 \n     drawings    plantation  explanations   certificate         dears \n         0.86          0.86          0.86          0.86          0.86 \nneighbourhood    allowances \n         0.85          0.85 \n\n\nThe semantics of these results have changed. For “boats”, we get much more terms related to seafaring. Most probably this is because only a few novels talk about boats so these terms correlate highly with one another. For “writing”, we’ve interestingly lost a lot of the words associated with writing in a strict sense (“copy”, “message”) but we’ve gained instead a list of terms that seem to situate us in where writing takes place in these novels, or what characters write about. So far though this is speculation; we’d have to look into this further to see whether the hypothesis holds.\nFinally, we can disaggregate our giant term count graph from above to focus more closely on the uniqueness of individual novels in our corpus. First, we’ll make a data frame from our TF-IDF DTM. We’ll transpose the DTM so the documents are our variables (columns) and the corpus vocabulary terms are our observations (or rows). Don’t forget the t!\n\ntfidf_df &lt;- as.matrix(dtm_tfidf)\ntfidf_df &lt;- as.data.frame(t(tfidf_df))\ncolnames(tfidf_df) &lt;- manifest$title\n\n\n\n15.7.3 Unique Terms in a Document\nWith this data frame made, we can order our rows by the highest value for a given column. In other words, we can find out not only the top terms for a novel, but the top most unique terms in that novel.\nHere’s Dracula:\n\nordering &lt;- order(tfidf_df$Dracula, decreasing = TRUE)\nrownames(tfidf_df[ordering[1:50], ])\n\n [1] \"helsing\"      \"mina\"         \"lucy\"         \"jonathan\"     \"van\"         \n [6] \"harker\"       \"godalming\"    \"quincey\"      \"seward\"       \"professor\"   \n[11] \"morris\"       \"lucy's\"       \"harker's\"     \"diary\"        \"seward's\"    \n[16] \"arthur\"       \"renfield\"     \"westenra\"     \"whilst\"       \"undead\"      \n[21] \"tonight\"      \"whitby\"       \"dracula\"      \"varna\"        \"carfax\"      \n[26] \"journal\"      \"helsing's\"    \"count\"        \"count's\"      \"hawkins\"     \n[31] \"madam\"        \"galatz\"       \"jonathan's\"   \"mina's\"       \"pier\"        \n[36] \"wolves\"       \"tomorrow\"     \"czarina\"      \"telegram\"     \"boxes\"       \n[41] \"today\"        \"holmwood\"     \"hypnotic\"     \"garlic\"       \"vampire\"     \n[46] \"phonograph\"   \"transylvania\" \"cliff\"        \"piccadilly\"   \"slovaks\"     \n\n\nNote here that some contractions have slipped through. Lemmatizing would take care of this, though we could also go back to the corpus object and add in another step with tm_map and then make another DTM:\n\ncleaned_corpus &lt;- tm_map(\n  cleaned_corpus, str_remove_all, pattern = \"\\\\'s\", replacement = \" \"\n)\n\nWe won’t bother to do this whole process now, but it’s a good example of how iterative the preprocessing workflow is.\nHere’s Frankenstein:\n\nordering &lt;- order(tfidf_df$Frankenstein, decreasing = TRUE)\nrownames(tfidf_df[ordering[1:50], ])\n\n [1] \"clerval\"      \"justine\"      \"elizabeth\"    \"felix\"        \"geneva\"      \n [6] \"frankenstein\" \"safie\"        \"cottagers\"    \"dæmon\"        \"ingolstadt\"  \n[11] \"kirwin\"       \"agatha\"       \"victor\"       \"ernest\"       \"mont\"        \n[16] \"krempe\"       \"lacey\"        \"waldman\"      \"agrippa\"      \"walton\"      \n[21] \"mountains\"    \"creator\"      \"cottage\"      \"sledge\"       \"hovel\"       \n[26] \"switzerland\"  \"ice\"          \"beaufort\"     \"cornelius\"    \"william\"     \n[31] \"protectors\"   \"moritz\"       \"henry\"        \"labours\"      \"chamounix\"   \n[36] \"glacier\"      \"jura\"         \"blanc\"        \"endeavoured\"  \"lake\"        \n[41] \"leghorn\"      \"monster\"      \"rhine\"        \"magistrate\"   \"belrive\"     \n[46] \"lavenza\"      \"salêve\"       \"saville\"      \"strasburgh\"   \"werter\"      \n\n\nAnd here’s Sense and Sensibility:\n\nordering &lt;- order(tfidf_df$SenseandSensibility, decreasing = TRUE)\nrownames(tfidf_df[ordering[1:50], ])\n\n [1] \"elinor\"       \"marianne\"     \"dashwood\"     \"jennings\"     \"willoughby\"  \n [6] \"lucy\"         \"brandon\"      \"barton\"       \"ferrars\"      \"colonel\"     \n[11] \"mrs\"          \"marianne's\"   \"edward\"       \"middleton\"    \"elinor's\"    \n[16] \"norland\"      \"palmer\"       \"steele\"       \"dashwoods\"    \"jennings's\"  \n[21] \"willoughby's\" \"edward's\"     \"delaford\"     \"steeles\"      \"cleveland\"   \n[26] \"mama\"         \"dashwood's\"   \"lucy's\"       \"brandon's\"    \"fanny\"       \n[31] \"allenham\"     \"middletons\"   \"devonshire\"   \"combe\"        \"ferrars's\"   \n[36] \"sister\"       \"morton\"       \"miss\"         \"margaret\"     \"park\"        \n[41] \"charlotte\"    \"exeter\"       \"magna\"        \"berkeley\"     \"harley\"      \n[46] \"john\"         \"middleton's\"  \"parsonage\"    \"beaux\"        \"behaviour\"   \n\n\nNames still rank high, but we can see in these results other words that indeed seem to be particular to each novel. With this data, we now have a sense of what makes each document unique in its relationship with all other documents in a corpus.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Natural Language Processing</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html",
    "href": "chapters/16_geospatial-data.html",
    "title": "16  Geospatial Data",
    "section": "",
    "text": "16.1 What is Geospatial Data?\nGeospatial data (also known as spatial data, GIS data, and other names) is information that can be attributed to a real-world location or can relate to each other in space.\nTechnically, “geospatial” refers to locations on Earth, while “spatial” can be locations anywhere, including other planets or even ficticious places (like J.R.R. Tolkien’s hand-drawn maps for his novels), but quite often the terms are used interchangably.\nYou use geospatial data every day on your smart phone through spatially-enabled apps like Google Maps, food delivery apps, fitness trackers, weather, or games like Pokemon Go.\n\\[\\begin{align*}\n\\textrm{(geo)Spatial Data} &= \\textrm{Attributes} + \\textrm{Locations} \\\\\n\n\\textrm{Location} &= \\textrm{Coordinate Reference System (CRS)} +\n  \\textrm{Coordinates}\n\\end{align*}\\]\nSo…\n\\[\n\\textrm{(geo)Spatial Data} = \\textrm{Attributes} +\n  \\textrm{Coordinate Reference System (CRS)} +\n  \\textrm{Coordinates}\n\\]",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#what-is-geospatial-data",
    "href": "chapters/16_geospatial-data.html#what-is-geospatial-data",
    "title": "16  Geospatial Data",
    "section": "",
    "text": "16.1.1 Attributes\nAttributes are pieces of information about a location. For example, if I’m mapping gas stations, my attributes might be something like the price of gas, the address of the station, and the company that runs it (Shell, Arco, etc.). This isn’t the same thing as metadata, which is information about the entire data set such as who made the data, when they made it, and how the data was created.\n\n\n16.1.2 Coordinate Reference System\nThe earth is generally round. Maps are generally flat, with a few exceptions. If you were to try to flatten out the earth, you would create some fairly major distortions. Next time you eat an orange or a tangerine, try taking off the peel and then try to create a flat solid sheet of peel from it. You’ll end up needing to cut it or smash it to get a flat surface. The same thing happens to geospatial data when we try to translate it from a round globe to a flat map. But there are ways to minimize distortions.\nA coordinate reference system (sometimes called a projection) is a set of mathematical formulas that translate measurements on a round globe to a flat piece of paper. The coordinate reference system also specifies the linear units of measure (i.e. feet, meters, decimal degrees, or something else) and a set of reference lines.\nFor our purposes, we can think of coordinate reference systems coming in two flavors. One is geographic coordinate systems. For simplicity’s sake, we can think of these as coordinate reference systems that apply to latitude and longitude coordinates. Projected coordinate systems translate latitude and longitude coordinates into linear units from a specified baseline and aim to reduce some aspect of the distortion introduced in the round to flat translation.\n\n\n\n\n\n\nNote\n\n\n\nI am very much simplifying these concepts so we can learn the basics without getting overwhelmed.\n\n\nTo work with more than one digital spatial data set, the coordinate reference systems must match. If they don’t match, you can transform your data into a different coordinate reference system.\n\n\n16.1.3 Coordinates\nCoordinates are given in the distance (in the linear units specified in the CRS) from the baselines (specified in the CRS). Coordinates can be plotted just like coordinates on a graph (Cartesian coordinate system). Sometimes we refer to these as \\(x\\) and \\(y\\), just like a graph, but sometimes you’ll hear people refer to the cardinal directions (north, south, east, and west).\nLet’s take a moment to talk about latitude and longitude. You’re probably at least a little familiar with latitude (\\(y\\)) and longitude (\\(x\\)), but this is a special case that’s more complex than we probably initially realize. Latitude and longitude are angular measurements (with units in degrees) from a set of baselines—usually the Equator and the Greenwich Meridian. We can plot latitude and longitude on a Cartesian coordinate system, but this introduces major distortions increasing as you approach the poles. You never want to use straight latitude/longitude coordinates (commonly in North America, you’ll see data in the geographic coordinate reference system called WGS84) for an analysis. Always translate them into a projected coordinate system first. In addition, because the units are degrees, they are rather hard for us to interpret when we make measurements. How many degrees is it from the UC Davis campus to your apartment? It’s probably a very small fraction of a degree. Area measurements make even less sense. (What is a square degree and what does that look like?) Latitude/longitude coordinates are a great starting place, we just need to handle them correctly.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#geospatial-data-models",
    "href": "chapters/16_geospatial-data.html#geospatial-data-models",
    "title": "16  Geospatial Data",
    "section": "16.2 Geospatial Data Models",
    "text": "16.2 Geospatial Data Models\nNow we have an idea of what makes data spatial, but what does spatial data look like in a computer? There are two common data models for geospatial data: Vector and Raster.\n\n\n\n\n\n\n\n\nData Model\nGeometry\nExample\n\n\n\n\nVector\nPoints\nVery small things, like cities at world scale\n\n\n.\nLines\nLinear things, like roads at city scale\n\n\n.\nPolygons\nLarger things that take up space, like parks at a city scale\n\n\nRaster\nGrid\nDigital Photo\n\n\n\n\n\n\n\n\n\nFigure 16.1: A visual table of raster versus vector data as continuous and discrete data.\n\n\n\n\n16.2.1 Vector Data\nVector data represents discrete objects in the real world with points, lines, and polygons in the data set.\nIf you were to draw a map to your house for a friend, you would typically use vector data—roads would be lines, a shopping center included as an important landmark might be a rectangle of sorts, and your house might be a point (perhaps represented by a star or a house icon).\nFor this lecture, we will focus on point data.\n\n\n16.2.2 Raster Data\nRaster data represents continuous fields or discrete objects on a grid, storing measurements or category codes in each cell of the grid.\nDigital photos are raster data you are already familiar with. If you zoom in far enough on a digital photo, you’ll see that photo is made up of pixels, which appear as colored squares. Pixels are cells in a regular grid and each contains the digital code that corresponds to the color that should be displayed there. Satellite images (like you see in Google Maps) are a very similar situation.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#data-structures-applied-to-geospatial-data",
    "href": "chapters/16_geospatial-data.html#data-structures-applied-to-geospatial-data",
    "title": "16  Geospatial Data",
    "section": "16.3 Data Structures Applied to Geospatial Data",
    "text": "16.3 Data Structures Applied to Geospatial Data\nIn Chapter 6, you learned that data can be structured in a number of ways, such as tabular, tree (XML and JSON), relational, and non-hierarchical structures. All of these structures can include spatial information.\n\n\n\n\n\n\n\n\nData Structure\nExample File Type\nHow It’s Implemented\n\n\n\n\nTabular\nCSV\nOne or more columns hold spatial data (like latitude & longitude)\n\n\nTree\ngeoJSON\nTags in the structure indicate spatial information like geometry type and vertex locations\n\n\nRelational Database\nPostGIS or Spatialite\nOne column holds the “geometry” information (vertexes & CRS)\n\n\nNon-Hierarchical Relational Data\nSpatial Graph Databases\nNodes have locations associated with them, edges represent flow (think: transportation networks or stream networks)\n\n\n\nFor visualization purposes, geospatial software typically show all of these data structures as a map where each entity is linked with a table of the attribute data—one row of data in the table relates to one entity on the map. So regardless of the underlying data structure, you can think of these as interactive maps like you find on Google Maps.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#cleaning-geospatial-data",
    "href": "chapters/16_geospatial-data.html#cleaning-geospatial-data",
    "title": "16  Geospatial Data",
    "section": "16.4 Cleaning Geospatial Data",
    "text": "16.4 Cleaning Geospatial Data\nWhat can go wrong?\n\nLocation data isn’t usable\nLocation data is incorrect\nAttribute data is incorrect\nCoordinate Reference System (CRS) is improperly defined\n\n\n16.4.1 Example Data\nThe data set we’ll be working with as an example contains locations and attributes about lake monsters. Lake monsters are fictional creatures like sea monsters, but they live in lakes and not the ocean. The most famous lake monster is probably Nessie, who lives in Loch Ness. The data set we’re working with today is the early stages of a now much cleaner data set. This data came from a Wikipedia page and the locations were geocoded (a process that matches text locations with real-world locations). We’ll walk through some common processes and challenges with point data stored in a CSV file.\n\n\n16.4.2 Making Location Data Usable\nSomeone sends you a CSV file. At first glance, nothing looks amiss. There is a column for latitude and another for longitude, but how is it formatted? It’s degrees-minutes-seconds (DMS)! DMS looks like this:\n34° 36' 31.774\"\n(That’s 34 degrees, 36 minutes, 31.447 seconds). Sometimes people put in the symbols for degrees (°), minutes ('), and seconds (\"), and sometimes not. The computer can’t read this format, especially the symbols. It has to be converted to decimal degrees (DD), which looks like this:\n34.60882611\nTo convert it, we need to know that there are 60 minutes in a degree and 60 seconds in a minute.\n\\[\n\\textrm{Decimal Degrees} = \\textrm{Degrees} +\n  (\\textrm{Minutes} / 60) + (\\textrm{Seconds} / 3600)\n\\]\n\\[\n34.60882611 = 34 + (36 / 60) + (31.447 / 3600)\n\\]\nFirst, we need to load the libraries we’ll need and then load the data:\n\n# Load libraries\nlibrary(\"sf\")\n\nLinking to GEOS 3.13.0, GDAL 3.10.0, PROJ 9.5.0; sf_use_s2() is TRUE\n\nlibrary(\"mapview\")\nlibrary(\"gdtools\")  # Makes the display (dependency of mapview)\nlibrary(\"leafem\")  # Makes the labels work (dependency of mapview)\nlibrary(\"leaflet\")\n\n# Read data\nmonsters.raw &lt;- read.csv(\n  \"data/lake_monsters.csv\", stringsAsFactors = FALSE, encoding = \"utf-8\"\n)\n\n# Explore the data\nhead(monsters.raw)\n\n  fid field_1               Lake        Area        Country     Continent\n1   1       1      Arenal Lagoon    Alajuela     Costa Rica North America\n2   2       2    Bangweulu Swamp                     Zambia        Africa\n3   3       3 Bassenthwaite Lake     England United Kingdom        Europe\n4   4       4          Bear Lake Idaho, Utah            USA North America\n5   5       5        Brosno Lake Tver Oblast         Russia        Europe\n6   6       6   Bueng Khong Long   Bueng Kan       Thailand          Asia\n                         Name       lat         lon        lat_dms\n1                     unnamed  10.49143  -84.851696 10°29?29.1304?\n2                      Nsanga -11.14741   29.784582 -11°8?50.6760?\n3                       Eachy  54.65279   -3.213612 54°39?10.0359?\n4 Bear Lake Monster, Isabella  42.21721 -111.319881  42°13?1.9643?\n5               Brosno Dragon  56.82407   31.914652 56°49?26.6520?\n6                  Phaya Naga  18.02363  104.014360  18°1?25.0676?\n           lon_dms                                 coords_3395    lon_3395\n1   -84°51?6.1069?  Point (-9445647.63285386 1166706.48735204)  -9445647.6\n2    29°47?4.4935?  Point (3315604.44829715 -1240572.14607131)   3315604.4\n3   -3°12?49.0016?   Point (-357737.60213262 7259890.14217639)   -357737.6\n4 -111°19?11.5709? Point (-12392072.44582391 5164853.16566773) -12392072.4\n5   31°54?52.7472?   Point (3552722.80948453 7688451.06249625)   3552722.8\n6   104°0?51.6974?  Point (11578825.63491604 2027100.69217741)  11578825.6\n  lat_3395\n1  1166706\n2 -1240572\n3  7259890\n4  5164853\n5  7688451\n6  2027101\n\n\nNext, we need to write some functions to deal with our specific DMS data and how its formatted:\n\n# This function splits up the DMS column into three columns - D, M, & S\nsplit.dms &lt;- function(dms.column) {\n  # Separate the pieces of the DMS column\n\n  # Make a matrix of characters\n  variable &lt;- do.call(rbind, args = c(strsplit(dms.column, '[°?]+')))\n\n  # Set the data type to numeric instead of character\n  mode(variable) &lt;- \"numeric\"\n\n  dms.split &lt;- as.data.frame(variable)\n\n  split.string &lt;- strsplit(dms.column, '[°?]+')\n\n  # Name the columns\n  names(dms.split) &lt;- c(\"D\", \"M\", \"S\")\n\n  dms.split\n}\n\n\n# This function coverts a 3 column data frame of DMS to DD, like the data\n# created by split.dms\ndecimaldegrees &lt;- function(dms.df) {\n  dd &lt;- data.frame()\n\n  for (i in 1:dim(dms.df)[1]) {\n    if (dms.df[i, 1] &gt; 0){\n      # Decimal Degrees = Degrees + (Minutes / 60) + (Seconds / 3600)\n      dd.row &lt;- dms.df[i, 1] + (dms.df[i, 2] / 60) + (dms.df[i, 3] / 3600)\n      dd &lt;- rbind(dd, dd.row)\n\n    } else {\n      # -Decimal Degrees = Degrees - (Minutes / 60) - (Seconds / 3600)\n      dd.row &lt;- dms.df[i, 1] - (dms.df[i,2] / 60) - (dms.df[i,3] / 3600)\n      dd &lt;- rbind(dd, dd.row)\n    }\n  }\n  dd\n}\n\nFinally, we can process our DMS data to convert it to Decimal Degreess (DD):\n\n# Process latitude\ndms.split &lt;- split.dms(monsters.raw$lat_dms)\ndd &lt;- decimaldegrees(dms.split)\nmonsters.df &lt;- cbind(monsters.raw, dd)\nnames(monsters.df)[15] &lt;- \"lat_dd\"\n\n# Process longitude\ndms.split &lt;- split.dms(monsters.raw$lon_dms)\ndd &lt;- decimaldegrees(dms.split)\nmonsters.df &lt;- cbind(monsters.df, dd)\nnames(monsters.df)[16] &lt;- \"lon_dd\"\n\n# Look at the data\nhead(monsters.df)\n\n  fid field_1               Lake        Area        Country     Continent\n1   1       1      Arenal Lagoon    Alajuela     Costa Rica North America\n2   2       2    Bangweulu Swamp                     Zambia        Africa\n3   3       3 Bassenthwaite Lake     England United Kingdom        Europe\n4   4       4          Bear Lake Idaho, Utah            USA North America\n5   5       5        Brosno Lake Tver Oblast         Russia        Europe\n6   6       6   Bueng Khong Long   Bueng Kan       Thailand          Asia\n                         Name       lat         lon        lat_dms\n1                     unnamed  10.49143  -84.851696 10°29?29.1304?\n2                      Nsanga -11.14741   29.784582 -11°8?50.6760?\n3                       Eachy  54.65279   -3.213612 54°39?10.0359?\n4 Bear Lake Monster, Isabella  42.21721 -111.319881  42°13?1.9643?\n5               Brosno Dragon  56.82407   31.914652 56°49?26.6520?\n6                  Phaya Naga  18.02363  104.014360  18°1?25.0676?\n           lon_dms                                 coords_3395    lon_3395\n1   -84°51?6.1069?  Point (-9445647.63285386 1166706.48735204)  -9445647.6\n2    29°47?4.4935?  Point (3315604.44829715 -1240572.14607131)   3315604.4\n3   -3°12?49.0016?   Point (-357737.60213262 7259890.14217639)   -357737.6\n4 -111°19?11.5709? Point (-12392072.44582391 5164853.16566773) -12392072.4\n5   31°54?52.7472?   Point (3552722.80948453 7688451.06249625)   3552722.8\n6   104°0?51.6974?  Point (11578825.63491604 2027100.69217741)  11578825.6\n  lat_3395    lat_dd      lon_dd\n1  1166706  10.49143  -84.851696\n2 -1240572 -11.14741   29.784582\n3  7259890  54.65279   -3.213612\n4  5164853  42.21721 -111.319881\n5  7688451  56.82407   31.914652\n6  2027101  18.02363  104.014360\n\n\nAnother common issue with point data is that the latitude and longitude are not in any form of degrees, but instead are in a projected coordinate system with linear units (usually feet or meters). If the data doesn’t come with metadata, you may be left guessing which coordinate system it is in. With experience, you’ll get better at guessing, but sometimes the data is not usable. Our monsters data set has latitude and longitude in the World Mercator (EPSG: 3395) projection as well. Let’s briefly look at that here, but we’ll play with that more later in this document.\n\nmonsters.df[1:10, 13:16]\n\n      lon_3395 lat_3395    lat_dd      lon_dd\n1   -9445647.6  1166706  10.49143  -84.851696\n2    3315604.4 -1240572 -11.14741   29.784582\n3    -357737.6  7259890  54.65279   -3.213612\n4  -12392072.4  5164853  42.21721 -111.319881\n5    3552722.8  7688451  56.82407   31.914652\n6   11578825.6  2027101  18.02363  104.014360\n7   -7845463.9  5433619  43.98618  -70.477001\n8  -12704546.6  6054836  47.87777 -114.126884\n9   -9467608.2  5128572  41.97447  -85.048971\n10 -12525669.2  5011829  41.18707 -112.520000\n\n\nNote that data preparation and cleaning is the vast majority of the work for all data, not just spatial data. All of the code we just looked at was just to get the data in a usable format. We’ll convert it to a spatial data type and map it in the next section.\n\n\n16.4.3 Cleaning Location Data\nSometimes, the locations in your data set are incorrect. This can happen for a number of reasons.\nFor example, it’s fairly common for data to get truncated or rounded if you open a CSV in Excel. Removing decimal places from coordinate data loses precision.\nPeople often swap their latitude and longitude columns as well, which make data show up in the wrong Cartesian coordinate, for example, \\((-119, 34)\\) is a verrry different location than \\((34, -119)\\). \\(-119\\) is actually out of the range of latitude data and will often break your code.\nAnother common source of error is in the way the data was made. If data is produced by geocoding, turning an address or place name into a coordinate, the location may have been matched badly. If the data was made by an analysis process, an unexpected aspect of the data could cause problems, like a one-to-many join when you thought you had a one-to-one join in a database.\nRegardless of how the errors came about, how do we find incorrect locations? Start by mapping the data and see where it lands. Is it where you expect the data to be? Sometimes you can’t tell it’s wrong because the data looks normal.\n\n# Convert the monsters data frame into an sf (spatial) object\n#   Note: x is the data frame, not longitude.\n#   Coordinate Reference System (CRS): we're using lat/long here so we need\n#     WGS84 which is EPSG code 4326 - we just need to tell R what the CRS is,\n#     we don't change it this way. If we want to change it, we need to use\n#     `st_transform`.\n\nmonsters.sf &lt;- st_as_sf(\n  x = monsters.df, coords = c(\"lon_dd\", \"lat_dd\"), crs = 4326\n)\n\n# Notice we added a geometry column!\nnames(monsters.sf)\n\n [1] \"fid\"         \"field_1\"     \"Lake\"        \"Area\"        \"Country\"    \n [6] \"Continent\"   \"Name\"        \"lat\"         \"lon\"         \"lat_dms\"    \n[11] \"lon_dms\"     \"coords_3395\" \"lon_3395\"    \"lat_3395\"    \"geometry\"   \n\n\n\n# Plot a map\nmapview(monsters.sf)\n\n\n\n\n\n\n\nFigure 16.2: This is a screen capture of the output for the mapview function. Running this code in a regular R session (that is, not in Quarto like we do to create this reader) will make an interactive map.\n\n\n\nIn the interactive version of this map, you can pan and zoom to different areas to see more detail. Clicking on a point will open a pop-up with attribute information.\nFirst impressions: This map looks good! The points are all on land masses, none in the ocean. Let’s see if they are on the correct continent…\n\nmapview(monsters.sf, zcol = \"Continent\", legend = TRUE)\n\n\n\n\n\n\n\nFigure 16.3: Map of monster locations by continent.\n\n\n\nIt’s hard to see, but there’s a point in Michigan that’s the wrong color for North America!\n\n\n\n\n\n\nFigure 16.4: Map of monster locations by continent zoomed in to the Great Lakes.\n\n\n\nWhoops! Lakes of Killarney isn’t in Michigan! That point should be in Ireland! If we zoom in, we can see why the geocoder got confused. The lake names are very similar.\n\n\n16.4.4 Cleaning Attribute Data\nAttribute data can be proofed in much the same way tabular data can be proofed. You can look at the statistical properties of numeric data or the unique entities in a list of categorical variables to see if any values are odd or out of place.\nWith spatial data, we can also map the data and visualize it by attribute values to see if anything is out of place spatially. Labels are another helpful tool. Sometimes cleaning attributes uncovers issues with the locations.\nLet’s make sure the lake names match the lakes the points are in. We’ll make a map and if you zoom in enough, the lake names will appear in the background map data.\n\n# Makes a pop-up with attribute information\nmy.label.options &lt;- labelOptions(clickable = TRUE)\n\nmap.lakename &lt;- mapview(monsters.sf, zcol = \"Lake\", legend = FALSE)\nlabels.lakename &lt;- addStaticLabels(\n  map.lakename, label = monsters.sf$Lake, labelOption = my.label.options\n)\n\nlabels.lakename\n\n\n\n\n\n\n\nFigure 16.5: Map of monster locations by lake name zoomed in to the Great Lakes.\n\n\n\n\n\n\n\n\n\nFigure 16.6: Map of monster locations by lake name zoomed in to the Great Lakes.\n\n\n\nAnd for fun, let’s look at the monster names:\n\nmap.monstername &lt;- mapview(monsters.sf, zcol = \"Name\", legend = FALSE)\nlabels.monstername &lt;- addStaticLabels(\n  map.monstername, label = monsters.sf$Name, labelOption = my.label.options\n)\n\nlabels.monstername\n\n\n\n\n\n\n\nFigure 16.7: Map of monster locations by monster name zoomed in to the Great Lakes.\n\n\n\n\n\n\n\n\n\nFigure 16.8: Map of monster locations by monster name zoomed in to the Great Lakes.\n\n\n\nYikes! That needs some clean-up too! The name column is missing some names and some records have extra information in them.\n\n\n16.4.5 Checking Coordinate Reference Systems\n\nWhy is my California data showing up in Arizona?\n\nThis is a common question UC Davis researchers ask on the Geospatial email list. Why does this happen? It’s usually because the CRS for their data is improperly defined. Someone changed the definition but didn’t reproject the data (the mathematical process of switching CRSs). Using the wrong CRS will often shift data just enough to look really funny on a map, but sometimes it won’t show up at all.\n\nWhy don’t my data sets line up in my map?\n\nAgain, it’s your CRS. In this case, they could be correct for all of the data sets you’re using, but each data set has a different CRS. You can think of CRSs as different dimensions in your favorite sci-fi story. Sometimes you can see the other person in the other dimension (CRS), but usually they are too different and you’re nowhere near each other. Data sets have to have the same CRS to make a map or do any analysis.\nOur data came with lat/long data in another coordinate reference system—EPSG 3395 “World Mercator”, a world projection centered on Europe. Notice how the coordinates look very different from the lat/long coordinates in EPSG 4326 “WGS 84”:\n\nmonsters.df[1:10,13:16]\n\n      lon_3395 lat_3395    lat_dd      lon_dd\n1   -9445647.6  1166706  10.49143  -84.851696\n2    3315604.4 -1240572 -11.14741   29.784582\n3    -357737.6  7259890  54.65279   -3.213612\n4  -12392072.4  5164853  42.21721 -111.319881\n5    3552722.8  7688451  56.82407   31.914652\n6   11578825.6  2027101  18.02363  104.014360\n7   -7845463.9  5433619  43.98618  -70.477001\n8  -12704546.6  6054836  47.87777 -114.126884\n9   -9467608.2  5128572  41.97447  -85.048971\n10 -12525669.2  5011829  41.18707 -112.520000\n\n# Let's make our World Mercator data spatial so we can explore its CRS\nmonsters.sf.3395 &lt;- st_as_sf(\n  x = monsters.df, coords = c(\"lon_3395\", \"lat_3395\"), crs = 3395\n)\n\n# `st_crs` tells us what the CRS is in well known text (WKT) and EPSG (if it's\n# available)\nst_crs(monsters.sf)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nst_crs(monsters.sf.3395)\n\nCoordinate Reference System:\n  User input: EPSG:3395 \n  wkt:\nPROJCRS[\"WGS 84 / World Mercator\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"World Mercator\",\n        METHOD[\"Mercator (variant A)\",\n            ID[\"EPSG\",9804]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Very small scale conformal mapping.\"],\n        AREA[\"World between 80°S and 84°N.\"],\n        BBOX[-80,-180,84,180]],\n    ID[\"EPSG\",3395]]\n\n# Check to see if they are identical, returning a logical vector\nidentical(st_crs(monsters.sf), st_crs(monsters.sf.3395))\n\n[1] FALSE",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#conclusions",
    "href": "chapters/16_geospatial-data.html#conclusions",
    "title": "16  Geospatial Data",
    "section": "16.5 Conclusions",
    "text": "16.5 Conclusions\nWe’ve learned some of the basics of geospatial data. We learned that the main components of geospatial data are locations, attributes, and a coordinate reference system. We saw how geospatial data can be represented with different data models, but we focused on point vector data. We learned that the data structures we were already familiar with can be modified to contain spatial data. And finally, we looked at some common processes for cleaning our geospatial data.\nThis was a lot to cover, but we just scratched the surface of all your can do with geospatial data science! If you want to learn more, UC Davis has some fantastic introductory classes for GIS (Geographic Information Systems/Science) and Remote Sensing (working satelite data and air photos).",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  },
  {
    "objectID": "chapters/16_geospatial-data.html#optional-further-reading",
    "href": "chapters/16_geospatial-data.html#optional-further-reading",
    "title": "16  Geospatial Data",
    "section": "16.6 Optional Further Reading",
    "text": "16.6 Optional Further Reading\n\nBolstad, P. 2019. GIS Fundamentals: A first text on geographic information systems. Sixth Edition. XanEdu. Ann Arbor, MI. 764 pp.\nSutton, T., O. Dassau, & M. Sutton. 2021. A Gentle Introduction to GIS. https://docs.qgis.org/3.16/en/docs/gentle_gis_introduction/preamble.html (accessed on 2021-02-11)",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Geospatial Data</span>"
    ]
  }
]