{
  "hash": "31daac8cb98c825ae41a8f3ce5e875b4",
  "result": {
    "engine": "knitr",
    "markdown": "# Geospatial Data {#sec-geospatial-data}\n\nThis lecture is designed to introduce you to the basics of geospatial data.\n\n::: {.callout-note title=\"Learning Goals\" collapse=\"false\"}\nAfter this lesson, you should be able to:\n\n * Understand the main components of geospatial data are locations, attributes,\n   and a coordinate reference system\n * Understand how geospatial data can be represented with different data models\n * Understand that the data structures we were already familiar with can be\n   modified to contain spatial data\n * Learn some common processes for cleaning our geospatial data\n:::\n\n\n## What is Geospatial Data?\n\n**Geospatial data** (also known as spatial data, GIS data, and other names) is\ninformation that can be attributed to a real-world location or can relate to\neach other in space.\n\nTechnically, \"geospatial\" refers to locations on Earth, while \"spatial\" can be\nlocations anywhere, including other planets or even ficticious places (like\nJ.R.R. Tolkien's hand-drawn maps for his novels), but quite often the terms are\nused interchangably.\n\nYou use geospatial data every day on your smart phone through spatially-enabled\napps like Google Maps, food delivery apps, fitness trackers, weather, or games\nlike Pokemon Go.\n\n\\begin{align*}\n\\textrm{(geo)Spatial Data} &= \\textrm{Attributes} + \\textrm{Locations} \\\\\n\n\\textrm{Location} &= \\textrm{Coordinate Reference System (CRS)} +\n  \\textrm{Coordinates}\n\\end{align*}\n\nSo...\n\n$$\n\\textrm{(geo)Spatial Data} = \\textrm{Attributes} +\n  \\textrm{Coordinate Reference System (CRS)} +\n  \\textrm{Coordinates}\n$$\n\n\n### Attributes\n\n**Attributes** are pieces of information about a location. For example, if I'm\nmapping gas stations, my attributes might be something like the price of gas,\nthe address of the station, and the company that runs it (Shell, Arco, etc.).\nThis isn't the same thing as metadata, which is information about the entire\ndata set such as who made the data, when they made it, and how the data was\ncreated.\n\n\n### Coordinate Reference System\n\nThe earth is generally round. Maps are generally flat, with a few exceptions.\nIf you were to try to flatten out the earth, you would create some fairly major\ndistortions. Next time you eat an orange or a tangerine, try taking off the\npeel and then try to create a flat solid sheet of peel from it. You'll end up\nneeding to cut it or smash it to get a flat surface. The same thing happens to\ngeospatial data when we try to translate it from a round globe to a flat map.\nBut there are ways to minimize distortions.\n\nA **coordinate reference system** (sometimes called a **projection**) is a set\nof mathematical formulas that translate measurements on a round globe to a flat\npiece of paper. The coordinate reference system also specifies the linear units\nof measure (i.e. feet, meters, decimal degrees, or something else) and a set of\nreference lines.\n\nFor our purposes, we can think of coordinate reference systems coming in two\nflavors. One is **geographic coordinate systems**. For simplicity's sake, we\ncan think of these as coordinate reference systems that apply to latitude and\nlongitude coordinates. **Projected coordinate systems** translate latitude and\nlongitude coordinates into linear units from a specified baseline and aim to\nreduce some aspect of the distortion introduced in the round to flat\ntranslation.\n\n::: {.callout-note}\nI am very much simplifying these concepts so we can learn the basics without\ngetting overwhelmed.\n:::\n\nTo work with more than one digital spatial data set, the coordinate reference\nsystems must match. If they don't match, you can transform your data into a\ndifferent coordinate reference system.\n\n\n### Coordinates\n\nCoordinates are given in the distance (in the linear units specified in the\nCRS) from the baselines (specified in the CRS). Coordinates can be plotted just\nlike coordinates on a graph (Cartesian coordinate system). Sometimes we refer\nto these as $x$ and $y$, just like a graph, but sometimes you'll hear people\nrefer to the cardinal directions (north, south, east, and west).\n\nLet's take a moment to talk about latitude and longitude. You're probably at\nleast a little familiar with latitude ($y$) and longitude ($x$), but this is a\nspecial case that's more complex than we probably initially realize. Latitude\nand longitude are angular measurements (with units in degrees) from a set of\nbaselines---usually the Equator and the Greenwich Meridian. We can plot\nlatitude and longitude on a Cartesian coordinate system, but this introduces\nmajor distortions increasing as you approach the poles. You never want to use\nstraight latitude/longitude coordinates (commonly in North America, you'll see\ndata in the geographic coordinate reference system called WGS84) for an\nanalysis. Always translate them into a projected coordinate system first. In\naddition, because the units are degrees, they are rather hard for us to\ninterpret when we make measurements. How many degrees is it from the UC Davis\ncampus to your apartment? It's probably a very small fraction of a degree. Area\nmeasurements make even less sense. (What is a square degree and what does that\nlook like?) Latitude/longitude coordinates are a great starting place, we just\nneed to handle them correctly.\n\n\n## Geospatial Data Models\n\nNow we have an idea of what makes data spatial, but what does spatial data look\nlike in a computer? There are two common data models for geospatial data:\nVector and Raster.\n\n\nData Model | Geometry | Example\n-----------|----------|---------\nVector     | Points   | Very small things, like cities at world scale\n.          | Lines    | Linear things, like roads at city scale\n.          | Polygons | Larger things that take up space, like parks at a city scale\nRaster     | Grid     | Digital Photo\n\n: {tbl-colwidths=\"[15, 15, 70]\" .striped .hover}\n\n::: {#fig-geo-data-types}\n![](/images/ch16/geometries_data_types.png)\n\nA visual table of raster versus vector data as continuous and discrete data.\n:::\n\n### Vector Data\n\nVector data represents discrete objects in the real world with points, lines,\nand polygons in the data set.\n\nIf you were to draw a map to your house for a friend, you would typically use\nvector data---roads would be lines, a shopping center included as an important\nlandmark might be a rectangle of sorts, and your house might be a point\n(perhaps represented by a star or a house icon).\n\nFor this lecture, **we will focus on point data**.\n\n### Raster Data\n\nRaster data represents continuous fields or discrete objects on a grid, storing\nmeasurements or category codes in each cell of the grid.\n\nDigital photos are raster data you are already familiar with. If you zoom in\nfar enough on a digital photo, you'll see that photo is made up of pixels,\nwhich appear as colored squares. Pixels are cells in a regular grid and each\ncontains the digital code that corresponds to the color that should be\ndisplayed there. Satellite images (like you see in Google Maps) are a very\nsimilar situation.\n\n\n## Data Structures Applied to Geospatial Data\n\nIn @sec-data-structures, you learned that data can be structured in a number of\nways, such as tabular, tree (XML and JSON), relational, and non-hierarchical\nstructures. All of these structures can include spatial information.\n\nData Structure                   | Example File Type       | How It's Implemented\n-------------------------------- | ----------------------- | --------------------\nTabular                          | CSV                     | One or more columns hold spatial data (like latitude & longitude)\nTree                             | geoJSON                 | Tags in the structure indicate spatial information like geometry type and vertex locations\nRelational Database              | PostGIS or Spatialite   | One column holds the \"geometry\" information (vertexes & CRS)\nNon-Hierarchical Relational Data | Spatial Graph Databases | Nodes have locations associated with them, edges represent flow (think: transportation networks or stream networks)\n\n: {tbl-colwidths=\"[25, 25, 50]\" .striped .hover}\n\nFor visualization purposes, geospatial software typically show all of these\ndata structures as a map where each entity is linked with a table of the\nattribute data---one row of data in the table relates to one entity on the map.\nSo regardless of the underlying data structure, you can think of these as\ninteractive maps like you find on Google Maps.\n\n\n## Cleaning Geospatial Data\n\nWhat can go wrong?\n\n1. Location data isn't usable\n2. Location data is incorrect\n3. Attribute data is incorrect\n4. Coordinate Reference System (CRS) is improperly defined\n\n### Example Data\n\nThe data set we'll be working with as an example contains locations and\nattributes about lake monsters. Lake monsters are fictional creatures like sea\nmonsters, but they live in lakes and not the ocean. The most famous lake\nmonster is probably Nessie, who lives in Loch Ness. The data set we're working\nwith today is the early stages of a now much cleaner data set. This data came\nfrom a Wikipedia page and the locations were **geocoded** (a process that\nmatches text locations with real-world locations). We'll walk through some\ncommon processes and challenges with point data stored in a CSV file.\n\n### Making Location Data Usable\n\nSomeone sends you a CSV file. At first glance, nothing looks amiss. There is a\ncolumn for latitude and another for longitude, but how is it formatted? It's\ndegrees-minutes-seconds (DMS)! DMS looks like this:\n\n```\n34° 36' 31.774\"\n```\n\n(That's 34 degrees, 36 minutes, 31.447 seconds). Sometimes people put in the\nsymbols for degrees (`°`), minutes (`'`), and seconds (`\"`), and sometimes not.\nThe computer can't read this format, especially the symbols. It has to be\nconverted to decimal degrees (DD), which looks like this:\n\n```\n34.60882611\n```\n\nTo convert it, we need to know that there are 60 minutes in a degree and 60\nseconds in a minute.\n\n$$\n\\textrm{Decimal Degrees} = \\textrm{Degrees} +\n  (\\textrm{Minutes} / 60) + (\\textrm{Seconds} / 3600)\n$$\n\n$$\n34.60882611 = 34 + (36 / 60) + (31.447 / 3600)\n$$\n\nFirst, we need to load the libraries we'll need and then load the data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(\"sf\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.0, GDAL 3.10.0, PROJ 9.5.0; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(\"mapview\")\nlibrary(\"gdtools\")  # Makes the display (dependency of mapview)\nlibrary(\"leafem\")  # Makes the labels work (dependency of mapview)\nlibrary(\"leaflet\")\n\n# Read data\nmonsters.raw <- read.csv(\n  \"data/lake_monsters.csv\", stringsAsFactors = FALSE, encoding = \"utf-8\"\n)\n\n# Explore the data\nhead(monsters.raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  fid field_1               Lake        Area        Country     Continent\n1   1       1      Arenal Lagoon    Alajuela     Costa Rica North America\n2   2       2    Bangweulu Swamp                     Zambia        Africa\n3   3       3 Bassenthwaite Lake     England United Kingdom        Europe\n4   4       4          Bear Lake Idaho, Utah            USA North America\n5   5       5        Brosno Lake Tver Oblast         Russia        Europe\n6   6       6   Bueng Khong Long   Bueng Kan       Thailand          Asia\n                         Name       lat         lon        lat_dms\n1                     unnamed  10.49143  -84.851696 10°29?29.1304?\n2                      Nsanga -11.14741   29.784582 -11°8?50.6760?\n3                       Eachy  54.65279   -3.213612 54°39?10.0359?\n4 Bear Lake Monster, Isabella  42.21721 -111.319881  42°13?1.9643?\n5               Brosno Dragon  56.82407   31.914652 56°49?26.6520?\n6                  Phaya Naga  18.02363  104.014360  18°1?25.0676?\n           lon_dms                                 coords_3395    lon_3395\n1   -84°51?6.1069?  Point (-9445647.63285386 1166706.48735204)  -9445647.6\n2    29°47?4.4935?  Point (3315604.44829715 -1240572.14607131)   3315604.4\n3   -3°12?49.0016?   Point (-357737.60213262 7259890.14217639)   -357737.6\n4 -111°19?11.5709? Point (-12392072.44582391 5164853.16566773) -12392072.4\n5   31°54?52.7472?   Point (3552722.80948453 7688451.06249625)   3552722.8\n6   104°0?51.6974?  Point (11578825.63491604 2027100.69217741)  11578825.6\n  lat_3395\n1  1166706\n2 -1240572\n3  7259890\n4  5164853\n5  7688451\n6  2027101\n```\n\n\n:::\n:::\n\n\n\n\nNext, we need to write some functions to deal with our specific DMS data and\nhow its formatted:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This function splits up the DMS column into three columns - D, M, & S\nsplit.dms <- function(dms.column) {\n  # Separate the pieces of the DMS column\n\n  # Make a matrix of characters\n  variable <- do.call(rbind, args = c(strsplit(dms.column, '[°?]+')))\n\n  # Set the data type to numeric instead of character\n  mode(variable) <- \"numeric\"\n\n  dms.split <- as.data.frame(variable)\n\n  split.string <- strsplit(dms.column, '[°?]+')\n\n  # Name the columns\n  names(dms.split) <- c(\"D\", \"M\", \"S\")\n\n  dms.split\n}\n\n\n# This function coverts a 3 column data frame of DMS to DD, like the data\n# created by split.dms\ndecimaldegrees <- function(dms.df) {\n  dd <- data.frame()\n\n  for (i in 1:dim(dms.df)[1]) {\n    if (dms.df[i, 1] > 0){\n      # Decimal Degrees = Degrees + (Minutes / 60) + (Seconds / 3600)\n      dd.row <- dms.df[i, 1] + (dms.df[i, 2] / 60) + (dms.df[i, 3] / 3600)\n      dd <- rbind(dd, dd.row)\n\n    } else {\n      # -Decimal Degrees = Degrees - (Minutes / 60) - (Seconds / 3600)\n      dd.row <- dms.df[i, 1] - (dms.df[i,2] / 60) - (dms.df[i,3] / 3600)\n      dd <- rbind(dd, dd.row)\n    }\n  }\n  dd\n}\n```\n:::\n\n\n\n\nFinally, we can process our DMS data to convert it to Decimal Degreess (DD):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Process latitude\ndms.split <- split.dms(monsters.raw$lat_dms)\ndd <- decimaldegrees(dms.split)\nmonsters.df <- cbind(monsters.raw, dd)\nnames(monsters.df)[15] <- \"lat_dd\"\n\n# Process longitude\ndms.split <- split.dms(monsters.raw$lon_dms)\ndd <- decimaldegrees(dms.split)\nmonsters.df <- cbind(monsters.df, dd)\nnames(monsters.df)[16] <- \"lon_dd\"\n\n# Look at the data\nhead(monsters.df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  fid field_1               Lake        Area        Country     Continent\n1   1       1      Arenal Lagoon    Alajuela     Costa Rica North America\n2   2       2    Bangweulu Swamp                     Zambia        Africa\n3   3       3 Bassenthwaite Lake     England United Kingdom        Europe\n4   4       4          Bear Lake Idaho, Utah            USA North America\n5   5       5        Brosno Lake Tver Oblast         Russia        Europe\n6   6       6   Bueng Khong Long   Bueng Kan       Thailand          Asia\n                         Name       lat         lon        lat_dms\n1                     unnamed  10.49143  -84.851696 10°29?29.1304?\n2                      Nsanga -11.14741   29.784582 -11°8?50.6760?\n3                       Eachy  54.65279   -3.213612 54°39?10.0359?\n4 Bear Lake Monster, Isabella  42.21721 -111.319881  42°13?1.9643?\n5               Brosno Dragon  56.82407   31.914652 56°49?26.6520?\n6                  Phaya Naga  18.02363  104.014360  18°1?25.0676?\n           lon_dms                                 coords_3395    lon_3395\n1   -84°51?6.1069?  Point (-9445647.63285386 1166706.48735204)  -9445647.6\n2    29°47?4.4935?  Point (3315604.44829715 -1240572.14607131)   3315604.4\n3   -3°12?49.0016?   Point (-357737.60213262 7259890.14217639)   -357737.6\n4 -111°19?11.5709? Point (-12392072.44582391 5164853.16566773) -12392072.4\n5   31°54?52.7472?   Point (3552722.80948453 7688451.06249625)   3552722.8\n6   104°0?51.6974?  Point (11578825.63491604 2027100.69217741)  11578825.6\n  lat_3395    lat_dd      lon_dd\n1  1166706  10.49143  -84.851696\n2 -1240572 -11.14741   29.784582\n3  7259890  54.65279   -3.213612\n4  5164853  42.21721 -111.319881\n5  7688451  56.82407   31.914652\n6  2027101  18.02363  104.014360\n```\n\n\n:::\n:::\n\n\n\n\nAnother common issue with point data is that the latitude and longitude are not\nin any form of degrees, but instead are in a projected coordinate system with\nlinear units (usually feet or meters). If the data doesn't come with metadata,\nyou may be left guessing which coordinate system it is in. With experience,\nyou'll get better at guessing, but sometimes the data is not usable. Our\nmonsters data set has latitude and longitude in the World Mercator (EPSG: 3395)\nprojection as well. Let's briefly look at that here, but we'll play with that\nmore later in this document.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonsters.df[1:10, 13:16]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      lon_3395 lat_3395    lat_dd      lon_dd\n1   -9445647.6  1166706  10.49143  -84.851696\n2    3315604.4 -1240572 -11.14741   29.784582\n3    -357737.6  7259890  54.65279   -3.213612\n4  -12392072.4  5164853  42.21721 -111.319881\n5    3552722.8  7688451  56.82407   31.914652\n6   11578825.6  2027101  18.02363  104.014360\n7   -7845463.9  5433619  43.98618  -70.477001\n8  -12704546.6  6054836  47.87777 -114.126884\n9   -9467608.2  5128572  41.97447  -85.048971\n10 -12525669.2  5011829  41.18707 -112.520000\n```\n\n\n:::\n:::\n\n\n\n\nNote that data preparation and cleaning is the vast majority of the work for\nall data, not just spatial data. All of the code we just looked at was just to\nget the data in a usable format. We'll convert it to a spatial data type and\nmap it in the next section.\n\n### Cleaning Location Data\n\nSometimes, the locations in your data set are incorrect. This can happen for a\nnumber of reasons.\n\nFor example, it's fairly common for data to get truncated or rounded if you\nopen a CSV in Excel. Removing decimal places from coordinate data loses\nprecision.\n\nPeople often swap their latitude and longitude columns as well, which make data\nshow up in the wrong Cartesian coordinate, for example, $(-119, 34)$ is a\n*verrry* different location than $(34, -119)$. $-119$ is actually out of the\nrange of latitude data and will often break your code.\n\nAnother common source of error is in the way the data was made. If data is\nproduced by geocoding, turning an address or place name into a coordinate, the\nlocation may have been matched badly. If the data was made by an analysis\nprocess, an unexpected aspect of the data could cause problems, like a\none-to-many join when you thought you had a one-to-one join in a database.\n\nRegardless of how the errors came about, how do we find incorrect locations?\nStart by mapping the data and see where it lands. Is it where you expect the\ndata to be? Sometimes you can't tell it's wrong because the data looks normal.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert the monsters data frame into an sf (spatial) object\n#   Note: x is the data frame, not longitude.\n#   Coordinate Reference System (CRS): we're using lat/long here so we need\n#     WGS84 which is EPSG code 4326 - we just need to tell R what the CRS is,\n#     we don't change it this way. If we want to change it, we need to use\n#     `st_transform`.\n\nmonsters.sf <- st_as_sf(\n  x = monsters.df, coords = c(\"lon_dd\", \"lat_dd\"), crs = 4326\n)\n\n# Notice we added a geometry column!\nnames(monsters.sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"fid\"         \"field_1\"     \"Lake\"        \"Area\"        \"Country\"    \n [6] \"Continent\"   \"Name\"        \"lat\"         \"lon\"         \"lat_dms\"    \n[11] \"lon_dms\"     \"coords_3395\" \"lon_3395\"    \"lat_3395\"    \"geometry\"   \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot a map\nmapview(monsters.sf)\n```\n:::\n\n\n\n\n::: {#fig-mapview-monsters}\n![](/images/ch16/mapview_monsters.png)\n\nThis is a screen capture of the output for the `mapview` function. Running this\ncode in a regular R session (that is, not in Quarto like we do to create this\nreader) will make an interactive map.\n:::\n\nIn the interactive version of this map, you can pan and zoom to different areas\nto see more detail. Clicking on a point will open a pop-up with attribute\ninformation.\n\nFirst impressions: This map looks good! The points are all on land masses, none\nin the ocean. Let's see if they are on the correct continent...\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapview(monsters.sf, zcol = \"Continent\", legend = TRUE)\n```\n:::\n\n\n\n\n::: {#fig-mapview-monsters-continent}\n![](/images/ch16/mapview_monsters_byContinent.png)\n\nMap of monster locations by continent.\n:::\n\nIt's hard to see, but there's a point in Michigan that's the wrong color for\nNorth America!\n\n::: {#fig-mapview-monsters-continent-zoom}\n![](/images/ch16/mapview_monsters_byContinent_zoom.png)\n\nMap of monster locations by continent zoomed in to the Great Lakes.\n:::\n\nWhoops! Lakes of Killarney isn't in Michigan! That point should be in Ireland!\nIf we zoom in, we can see why the geocoder got confused. The lake names are\nvery similar.\n\n\n### Cleaning Attribute Data\n\nAttribute data can be proofed in much the same way tabular data can be proofed.\nYou can look at the statistical properties of numeric data or the unique\nentities in a list of categorical variables to see if any values are odd or out\nof place.\n\nWith spatial data, we can also map the data and visualize it by attribute\nvalues to see if anything is out of place spatially. Labels are another helpful\ntool. Sometimes cleaning attributes uncovers issues with the locations.\n\nLet's make sure the lake names match the lakes the points are in. We'll make a\nmap and if you zoom in enough, the lake names will appear in the background\nmap data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Makes a pop-up with attribute information\nmy.label.options <- labelOptions(clickable = TRUE)\n\nmap.lakename <- mapview(monsters.sf, zcol = \"Lake\", legend = FALSE)\nlabels.lakename <- addStaticLabels(\n  map.lakename, label = monsters.sf$Lake, labelOption = my.label.options\n)\n\nlabels.lakename\n```\n:::\n\n\n\n\n::: {#fig-mapview-monsters-lake}\n![](/images/ch16/mapview_monsters_byLake.png)\n\nMap of monster locations by lake name zoomed in to the Great Lakes.\n:::\n\n::: {#fig-mapview-monsters-lake-zoom}\n![](/images/ch16/mapview_monsters_byLake_zoom.png)\n\nMap of monster locations by lake name zoomed in to the Great Lakes.\n:::\n\nAnd for fun, let's look at the monster names:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap.monstername <- mapview(monsters.sf, zcol = \"Name\", legend = FALSE)\nlabels.monstername <- addStaticLabels(\n  map.monstername, label = monsters.sf$Name, labelOption = my.label.options\n)\n\nlabels.monstername\n```\n:::\n\n\n\n\n::: {#fig-mapview-monsters-name}\n![](/images/ch16/mapview_monsters_byName.png)\n\nMap of monster locations by monster name zoomed in to the Great Lakes.\n:::\n\n::: {#fig-mapview-monsters-name-zoom}\n![](/images/ch16/mapview_monsters_byName_zoom.png)\n\nMap of monster locations by monster name zoomed in to the Great Lakes.\n:::\n\nYikes! That needs some clean-up too!  The name column is missing some names and\nsome records have extra information in them.\n\n\n### Checking Coordinate Reference Systems\n\n> Why is my California data showing up in Arizona?\n\nThis is a common question UC Davis researchers ask on the Geospatial email\nlist. Why does this happen? It's usually because the CRS for their data is\nimproperly defined. Someone changed the definition but didn't reproject the\ndata (the mathematical process of switching CRSs). Using the wrong CRS will\noften shift data just enough to look really funny on a map, but sometimes it\nwon't show up at all.\n\n> Why don't my data sets line up in my map?\n\nAgain, it's your CRS. In this case, they could be correct for all of the data\nsets you're using, but each data set has a different CRS. You can think of CRSs\nas different dimensions in your favorite sci-fi story. Sometimes you can see\nthe other person in the other dimension (CRS), but usually they are too\ndifferent and you're nowhere near each other. Data sets have to have the same\nCRS to make a map or do any analysis.\n\nOur data came with lat/long data in another coordinate reference system---EPSG\n3395 \"World Mercator\", a world projection centered on Europe. Notice how the\ncoordinates look very different from the lat/long coordinates in EPSG 4326 \"WGS\n84\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonsters.df[1:10,13:16]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      lon_3395 lat_3395    lat_dd      lon_dd\n1   -9445647.6  1166706  10.49143  -84.851696\n2    3315604.4 -1240572 -11.14741   29.784582\n3    -357737.6  7259890  54.65279   -3.213612\n4  -12392072.4  5164853  42.21721 -111.319881\n5    3552722.8  7688451  56.82407   31.914652\n6   11578825.6  2027101  18.02363  104.014360\n7   -7845463.9  5433619  43.98618  -70.477001\n8  -12704546.6  6054836  47.87777 -114.126884\n9   -9467608.2  5128572  41.97447  -85.048971\n10 -12525669.2  5011829  41.18707 -112.520000\n```\n\n\n:::\n\n```{.r .cell-code}\n# Let's make our World Mercator data spatial so we can explore its CRS\nmonsters.sf.3395 <- st_as_sf(\n  x = monsters.df, coords = c(\"lon_3395\", \"lat_3395\"), crs = 3395\n)\n\n# `st_crs` tells us what the CRS is in well known text (WKT) and EPSG (if it's\n# available)\nst_crs(monsters.sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n```\n\n\n:::\n\n```{.r .cell-code}\nst_crs(monsters.sf.3395)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: EPSG:3395 \n  wkt:\nPROJCRS[\"WGS 84 / World Mercator\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"World Mercator\",\n        METHOD[\"Mercator (variant A)\",\n            ID[\"EPSG\",9804]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Very small scale conformal mapping.\"],\n        AREA[\"World between 80°S and 84°N.\"],\n        BBOX[-80,-180,84,180]],\n    ID[\"EPSG\",3395]]\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check to see if they are identical, returning a logical vector\nidentical(st_crs(monsters.sf), st_crs(monsters.sf.3395))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\n## Conclusions\n\nWe've learned some of the basics of geospatial data. We learned that the main\ncomponents of geospatial data are locations, attributes, and a coordinate\nreference system. We saw how geospatial data can be represented with different\ndata models, but we focused on point vector data. We learned that the data\nstructures we were already familiar with can be modified to contain spatial\ndata. And finally, we looked at some common processes for cleaning our\ngeospatial data.\n\nThis was a lot to cover, but we just scratched the surface of all your can do\nwith geospatial data science! If you want to learn more, UC Davis has some\nfantastic introductory classes for GIS (Geographic Information Systems/Science)\nand Remote Sensing (working satelite data and air photos).\n\n\n## Optional Further Reading\n\n1. Bolstad, P. 2019. *GIS Fundamentals: A first text on geographic information\n   systems*. Sixth Edition. XanEdu. Ann Arbor, MI. 764 pp.\n2. Sutton, T., O. Dassau, & M. Sutton. 2021. *A Gentle Introduction to GIS*. <https://docs.qgis.org/3.16/en/docs/gentle_gis_introduction/preamble.html> (accessed on 2021-02-11)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}