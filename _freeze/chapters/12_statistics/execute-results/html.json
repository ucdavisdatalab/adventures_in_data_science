{
  "hash": "b6eb2f1ec59706c0b088ddce812ffc92",
  "result": {
    "engine": "knitr",
    "markdown": "# Statistics\n\n::: {.callout-note title=\"Learning Goals\" collapse=\"false\"}\nAfter this lesson, you should be able to:\n\n* Explain the difference between a population and a sample\n:::\n\n## Introduction\n\nIt is useful to begin with some concrete examples of statistical questions to\nmotivate the material that we'll cover in this lesson. This will also help\nconfirm that your R environment is working.\n\n::: {.callout-note}\nThe examples that follow use several data sets, which we read directly from CSV\nfiles.\n\nThe data sets come from the fosdata package, which you can optionally install\nto your computer in order to get access to all of the associated help files.\nThe fosdata package is hosted on GitHub but not CRAN, so to install it you need\nanother package, remotes, for its `install_github` function. Here's how to\ninstall both:\n\n```r\n# This is optional!\n# install.packages(\"remotes\")\nremotes::install_github(\"speegled/fosdata\")\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"ggformula\")\n# install.packages(\"mosaic\")\n# remotes::install_github(\"ProjectMOSAIC/mosaicModel\")\nlibrary(\"ggformula\")\nlibrary(\"mosaic\")\nlibrary(\"mosaicModel\")\n```\n:::\n\n\n\n\nNow load the data sets:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmice_pot = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/mice_pot.csv\")\nbarnacles = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/barnacles.csv\")\nBirths78 = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/births.csv\")\nsmoking = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/smoking.csv\")\nadipose = read.csv(\"https://raw.githubusercontent.com/ucdavisdatalab/adventures_in_data_science/master/data/adipose.csv\")\n```\n:::\n\n\n\n\n### The `mice_pot` Data Set\n\nThe `mice_pot` data set comes from an experiment where four groups of mice were\ndosed with different levels of THC. There was a low, medium, and high dosage\ngroup, as well as a control group that got no THC. The mice were then observed\nfor a while and their total movement was quantified as a percentage of the\nbaseline group mean. Two statistical questions that might arise here are:\n\n* Were there differences in the typical amount of movement between mice of\n  different groups?\n* What was the average amount of movement by mice in the\n  medium dose group?\n\nBoth of these questions can be approached by summarizing the sample with\ndescriptive statistics. Here's one way to compute the average (mean) movement\nfor each group:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregate(mice_pot[\"percent_of_act\"], mice_pot[\"group\"], mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  group percent_of_act\n1   0.3       97.32250\n2     1       99.05235\n3     3       70.66787\n4   VEH      100.00000\n```\n\n\n:::\n:::\n\n\n\n\nThe means aren't identical! So there are clearly differences between all of the\ngroups, right? Yes, *in terms of this sample*. But if you want to generalize\nyour conclusion to cover what would happen to other mice that weren't in the\nstudy, then you need to think about the **population**. In this case, that's\nthe population of all the mice that could have been dosed with THC.\n\nBecause we can't see data from mice that weren't part of the study, we rely on\n**statistical inference** to reach conclusions about the population. How is\nthat possible? Statistical methods can tell us about the **distribution** of\nthe sample relative to the population.\n\n### The `barnacles` Data Set\n\nThis data set was collected by counting the barnacles in 88 grid squares on the\nFlower Garden Banks coral reef in the Gulf of Mexico. The counts were\nnormalized to barnacles per square meter. Some questions that you might\napproach with statistical methods are:\n\n* What is the average number of barnacles per square meter, and is it greater\n  than 300?\n\nYou can use R to compute the average:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(barnacles$per_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 332.0186\n```\n\n\n:::\n:::\n\n\n\n\nFrom that calculation, we see that the mean is 332 barnacles per square meter,\nwhich is greater than 300. But again, the first calculation has told us only\nabout the mean of the particular locations that were sampled. Wouldn't it be\nbetter to answer the questions in reference to the number of barnacles per\nsquare meter of reef, rather than square meter of measurement? Here, *the\npopulation is the entire area of the Flower Garden Banks reef*. Again, we will\nbe able to answer the questions relative to the entire reef by working out the\nsample mean's distribution relative to the population.\n\n\n### Sample and Population\n\nSamples and populations are fundamental concepts in statistics. A sample is\ndata---the hard numbers that go into your calculations. The population is\ntrickier: it's the units to which you are able to generalize your conclusions.\n\nFor the `barnacles` data, in order to draw conclusions about the population\n(the entire Flower Garden Banks reef), the sample must be carefully selected to\nensure it is representative. For instance, randomly sampling locations so that\nany location on the reef might be selected is one sampling strategy.\n\nFor the `mice_pot` data, the population is all the mice that might have been\nselected for use in the experiment. How big that population is depends on how\nthe mice were selected for the experiment. Randomly selecting the experimental\nunits from a group is a common way of ensuring that the results can generalize\nto that whole group.\n\nA non-random sample tends to mean that the population to which you can\ngeneralize is quite limited. What sort of population do you think we could\ngeneralize about if we recorded the age of everyone in this class?\n\n\n## Uses of Simulation\n\nThe study of statistics started in the 1800s, but slowly. Most statistical\nmethodology and theory was developed during the first half of the 20th\ncentury---a time when data and processing power were in short supply. Today,\nthat's not so much the case. If you did the assigned reading, then you saw that\nstatisticians are very much still grappling with how to teach statistics in\nlight of the advances in computing over the past 40 years.\n\nTraditionally, statisticians are very concerned with assessing the normality of\na sample, because the conclusions you get from traditional statistical methods\ndepend on a sample coming from a normal distribution. Nowadays, there are a lot\nof clever methods that can avoid the need to assume normality. We're going to\nlearn some of those methods, because they usually don't require any complicated\nmath. If you want to know more, one of the assigned readings was the\nintroduction to a book that would be a great reference for self-guided study.\n\nWe will use simulation-based methods extensively today.\n\nThis is the density curve of a standard normal distribution:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/annotated-density-tails-1.png){width=672}\n:::\n:::\n\n\n\n\nAnd this is a histogram of samples taken from that same distribution:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample 20 numbers from a standard normal and draw the histogram\nx = rnorm(20)\nround(sort(x), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] -1.86 -1.83 -1.39 -1.22 -0.84 -0.76 -0.57 -0.29 -0.09  0.06  0.08  0.20\n[13]  0.31  0.36  0.48  0.57  0.75  0.78  0.85  1.45\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(x)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/normal-histogram-1.png){width=672}\n:::\n:::\n\n\n\n\nDo the numbers seem to come from the high-density part of the normal density\ncurve? Are there any that don't? It isn't surprising if some of your `x`\nsamples are not particularly close to zero. One out of twenty (that's five\npercent) samples from a standard normal population are greater than two or less\nthan negative two, on average. That's \"on average\" over the population. Your\nsample may be different.\n\n\nHere is the density of the exponential distribution:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/exponential-density-1.png){width=672}\n:::\n:::\n\n\n\n\nAnd here is a histogram of 20 samples taken from that distribution:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample 20 numbers from a histogram and plot the histogram\nex = rexp(20)\nround(sort(ex), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.04 0.09 0.22 0.23 0.28 0.29 0.45 0.46 0.56 0.56 0.61 0.64 0.76 0.84 0.93\n[16] 0.97 1.04 1.19 1.38 3.21\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(ex)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/exponential-histogram-1.png){width=672}\n:::\n:::\n\n\n\n\nThe histograms are clearly different, but it would be difficult to definitively\nname the distribution of the data by looking at a sample.\n\n\n## Mathematical Statistics\n\nThe mean has some special properties: you've seen how we can calculate the\nfrequency of samples being within an interval based on known distributions. But\nwe need to know the distribution. It turns out that the distribution of the\nsample mean approaches the normal distribution as the sample size increases,\nfor almost any independent data. That allows us to create intervals and reason\nabout the distribution of real data, even though the data's distribution is\nunknown.\n\n### Law of Large Numbers\n\nThe **Law of Large Numbers** says that if the individual measurements are\nindependent, then the mean of a sample tends toward the mean of the population\nas the sample size gets larger. This is what we'd expect, since we showed the\nrate at which the variance of the sample mean gets smaller is $1/n$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnn = c(1, 2, 4, 8, 12, 20, 33, 45, 66, 100)\nmeans = sapply(nn, function(n) mean(rnorm(n)))\n\nplot(nn, means, bty = 'n', ylab = \"sample mean\")\nabline(h = 0, lty = 2)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/lln-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Central Limit Theorem\n\nThe most important mathematical result in statistics, the **Central Limit\nTheorem**, says that if you take (almost) any sample of random numbers and\ncalculate its mean, the distribution of the mean tends toward a normal\ndistribution. We illustrate the \"tending toward\" with an arrow and it indicates\nthat the distribution of a sample mean is only *approximately* normal. But if\nthe original samples were from a normal distribution then the sample mean has\nan *exactly* normal distribution. From here, I'll start writing the mean of a\nrandom variable $X$ as $\\bar{X}$ and the mean of a sample $x$ as $\\bar{x}$.\n\n$$ \\bar{X} \\rightarrow N(\\mu, \\frac{\\sigma^2}{n}) $$\n\nAnd because of the identities we learned before, you can write this as\n\n$$\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow N(0, 1) $$\n\nThis is significant because we can use the standard normal functions on the\nright, and the data on the left, to start answering questions like, \"what is\nthe 95% confidence interval for the population mean?\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate 20 samples from a uniform distribution and plot their histogram\nN = 20\nu = rexp(N)\nhist(u)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/clt-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Generate 100 repeated samples of the same size, calculate the mean of each\n# one, and plot the histogram of the means.\nB = 100\nmeans = numeric(B)\nfor (i in 1:B) {\n  means[[i]] = mean(rexp(N))\n}\n\nhist(means)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/clt-2.png){width=672}\n:::\n:::\n\n\n\n\nWhat happens as `B` and `N` get larger or smaller? Do they play different\nroles?\n\n\n## Statistical Inference\n\n### Confidence Intervals\n\nRecall the `mice_pot` data set, which contains data from an experiment where\nmice were dosed with THC and then measured for motor activity as a percentage\nof their baseline activity. We are going to look at the group that got a medium\ndose of THC.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract just the mice that got the medium dose of THC\nmice_med = mice_pot[ mice_pot$group == 1, ]\n\n# Assess normality with histogram and QQ plot\nhist(mice_med$percent_of_act)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/mice-normality-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(mice_med$percent_of_act)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/mice-normality-2.png){width=672}\n:::\n:::\n\n\n\n\n#### Finding Confidence Intervals\n\nNow we are using our sample to make some determination about the population, so\nthis is statistical inference. Our best guess of the population mean is the\nsample mean, `mean(mice_med$percent_of_act)`, which is 99.1%. But to get a\nconfidence interval, we need to use the formula:\n\n$$ \\bar{x} \\pm t_{n-1, 0.1} * S / \\sqrt{n} $$\n\nFortunately, R can do all the work for us:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 80% confidence interval for location of mice_med mean:\nt.test(mice_med$percent_of_act, conf.level = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  mice_med$percent_of_act\nt = 13.068, df = 11, p-value = 4.822e-08\nalternative hypothesis: true mean is not equal to 0\n80 percent confidence interval:\n  88.71757 109.38712\nsample estimates:\nmean of x \n 99.05235 \n```\n\n\n:::\n:::\n\n\n\n\n### Two-population Test\n\nThe test of $\\mu_0 = 100$ is a one-population test because it seeks to compare\na single population against a specified standard. On the other hand, you may\nwish to assess the null hypothesis that the movement of mice in the high-THC\ngroup is equal to the movement of mice in the medium-THC group. This is called\na two-population test, since there are two populations to compare against each\nother. The null hypothesis is $\\mu_{0, med} = \\mu_{0, high}$. Testing a\ntwo-population hypothesis requires first assessing normality and also checking\nwhether the variances are equal. There are separate procedures when the\nvariances are equal vs. unequal.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract the samples to be compared\ngroup1 = mice_pot$percent_of_act[mice_pot$group == 1]\ngroup3 = mice_pot$percent_of_act[mice_pot$group == 3]\n\n# Check for equal variances---these are close enough\nvar(group1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 689.4729\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(group3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 429.4551\n```\n\n\n:::\n\n```{.r .cell-code}\n# Confirm equal variances with a boxplot\nboxplot(group1, group3)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/two-pop-t.test-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Check whether the high-THC mice movement is normal\n# (we already checked for the medium-dose mice)\nqqnorm(group3)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/two-pop-t.test-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Two-pop test\nt.test(group1, group3, var.equal=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  group1 and group3\nt = 2.7707, df = 20, p-value = 0.0118\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  7.014608 49.754345\nsample estimates:\nmean of x mean of y \n 99.05235  70.66787 \n```\n\n\n:::\n:::\n\n\n\n\n### Hypothesis Tests for Non-normal Data\n\nJust as with the confidence intervals, there is a bootstrap hypothesis test\nthat can be used where the data are not normal. There are other options, too,\nwith clever derivations. The one I'll show you is the Wilcoxon test, which is\nbased on the ranks of the data.\n\nSince we've already seen that the barnacles per square meter data are not\nnormal, I will illustrate testing the null hypothesis that $\\mu_0 = 300$\nbarnacles per square meter. This is a one-population test, and a two-sided\nalternative.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wilcoxon test for 300 barnacles per square meter\nwilcox.test(barnacles$per_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  barnacles$per_m\nV = 3916, p-value = 3.797e-16\nalternative hypothesis: true location is not equal to 0\n```\n\n\n:::\n:::\n\n\n\n\n\n## Regression\n\nRegression is a mathematical tool that allows you to estimate how some response\nvariable is related to some predictor variable(s). There are methods that\nhandle continuous or discrete responses of many different distributions, but we\nare going to focus on linear regression here.\n\nLinear regression means that the relationship between the predictor variable(s)\nand the response is a linear one. To illustrate, we'll create a plot of the\nrelationship between the waist measurement and body mass index (BMI) of 81\nadults:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the relationship between the waist_cm and bmi variables\nwith(adipose, plot(waist_cm, bmi), bty = 'n')\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/regression-example-1.png){width=672}\n:::\n:::\n\n\n\n\nThe relationship between the two is apparently linear (you can imagine drawing\na straight line through the data). The general mathematical form of a linear\nregression line is:\n\n$$ y = a + \\beta x + \\epsilon $$\n\nHere, the response variable (BMI) is called $y$ and the predictor (waist\nmeasurement) is $x$. The coefficient $\\beta$ indicates how much the response\nchanges for a change in the predictors (that is, the expected change in BMI\nwith a 1 cm change in waist measurement). Variable $a$ denotes the intercept,\nwhich is a constant offset that aligns the mean of $y$ with the mean of $x$.\nFinally, $\\epsilon$ is the so-called residual error in the relationship. It\nrepresents the variation in the response that is not due to the predictor(s).\n\n\n### Fitting a Regression Line\n\nThe R function to fit the model is called `lm`. Let's take a look at an\nexample:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the linear regression BMI vs waist_cm\nfit = lm(bmi ~ waist_cm, data = adipose)\n\n# Plot the fitted regression: begin with the raw data\nwith(adipose, plot(waist_cm, bmi, bty = 'n'))\n\n# Now plot the fitted regression line (in red)\nabline(coef(fit)[[1]], coef(fit)[[2]], col = 'red')\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/bmi-vs-waist-regression-1.png){width=672}\n:::\n:::\n\n\n\n\n### Assumptions and Diagnostics\n\n\"Fitting\" a linear regression model involves estimating $a$ and $\\beta$ in the\nregression equation. You can can do this fitting procedure using any data, but\nthe results won't be reliable unless some conditions are met. The conditions\nare:\n\n1. A linear model is appropriate (linearity).\n2. The residual error is normally distributed.\n3. The variance of the residual error is constant for all observations.\n4. Observations are independent.\n\nThe first of these conditions can't be checked---it has to do with the design\nof the experiment. The rest can be checked, though, and I'll take them in\norder.\n\n#### Checking Linearity\n\nIn the case of a simple linear regression model (one predictor variable), you\ncan check this by plotting the predictor against the response and looking for a\nlinear trend. If you have more than one predictor variable, then you need to\nplot the predictions against the response to look for a linear trend. We'll see\nan example by adding height as a predictor for BMI (in addition to waist\nmeasurement).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Linear model for BMI using waist size and height as predictors\nfit2 = lm(bmi ~ waist_cm + stature_cm, data=adipose)\n\n# Plot the fitted versus the predicted values\nplot(fit2$fitted.values, adipose$bmi, bty = 'n')\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/bmi-waist-height-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Checking that the Residuals Are Normally Distributed\n\nWe have already learned about the QQ plot, which shows visually whether some\nvalues are Normally distributed. In order to depend upon the fit from a linear\nregression model, we need to see that the residuals are Normally distributed,\nand we use the QQ plot to check.\n\n\n#### Checking that the Variance Is Constant\n\nIn an earlier part, we saw that the variance is the average of the squared\nerror. But that would just be a single number, when we want to see if there is\na trend. So like the QQ plot, you'll plot the residuals and use your eyeball to\ndiscern whether there is a trend in the residuals or if they are approximately\nconstant - this is called the scale-location plot. The QQ plot and\nscale-location plot are both created by plotting the fitted model object\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up the pattern of the panels\nlayout(matrix(1:4, 2, 2))\n\n# Make the diagnostic plots\nplot(fit)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/diagnostics-1.png){width=672}\n:::\n:::\n\n\n\n\nThe \"Residuals vs. Fitted\" plot is checking whether the linear model is\ncorrect. There should be no obvious pattern if the data are linear (as is the\ncase here). The Scale-Location plot will have no obvious pattern if the\nvariance of the residuals is constant, as is the case here (you might see a\nslight pattern in the smoothed red line but it isn't obvious). And the QQ plot\nwill look like a straight line if the residuals are from a Normal distribution,\nas is the case here. So this model is good. The fourth diagnostic plot is the\nResiduals vs. Leverage plot, which is used to identify influential outliers. We\nwon't get into that here.\n\n### Functions for Inspecting Regression Fits\n\nWhen you fit a linear regression model, you are estimating the parameters of\nthe regression equation. In order to see those estimates, use the `summary()`\nfunction on the fitted model object.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the model summary\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bmi ~ waist_cm + stature_cm, data = adipose)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1290 -1.0484 -0.2603  1.2661  5.2572 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 14.38196    3.82700   3.758 0.000329 ***\nwaist_cm     0.29928    0.01461  20.491  < 2e-16 ***\nstature_cm  -0.08140    0.02300  -3.539 0.000680 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.724 on 78 degrees of freedom\nMultiple R-squared:  0.844,\tAdjusted R-squared:   0.84 \nF-statistic:   211 on 2 and 78 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nHere you can see that the average marginal effect of one additional centimeter\nof waist measurement is to increase BMI by 0.3 and an\nadditional centimeter of height is associated with a change to BMI of `r\nround(coef(fit2)[[3]], 2)`. You can get the coefficients from the fitted model\nobject using the `coef()` function, and there are some other functions that\nallow you to generate the values shown in the summary table.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the coefficients of the fitted regression\nbeta = coef(fit2)\nround(beta, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)    waist_cm  stature_cm \n      14.38        0.30       -0.08 \n```\n\n\n:::\n:::\n\n\n\n\nGet the variance-covariance matrix:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(vcov(fit2), 4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare the square root of the diagonals of the variance-covariance matrix to\n# the standard errors are reported in the summary table:\nse = sqrt(diag(vcov(fit2)))\n\n# Here are the standard errors:\nround(se, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)    waist_cm  stature_cm \n      3.827       0.015       0.023 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the t-statistics for the regression coefficients (compare these to\n# the t-statistics reported in the summary table)\nt_stats = beta / se\n\n# Show the t-statistics:\nround(t_stats, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)    waist_cm  stature_cm \n       3.76       20.49       -3.54 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the p-values:\npval = 2 * pt(abs(t_stats), df=78, lower.tail=FALSE)\nround(pval, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)    waist_cm  stature_cm \n      3e-04       0e+00       7e-04 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is the residual standard error:\nsd(fit2$residuals) * sqrt(80 / 78)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.72357\n```\n\n\n:::\n\n```{.r .cell-code}\n# R-squared is the proportion of variance\n# explained by the regression model\nround(1 - var(fit2$residuals) / var(adipose$bmi), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.844\n```\n\n\n:::\n:::\n\n\n\n\n### A Model that Fails Diagnostics\n\nWe've seen a model that has good diagnostics. Now let's look at one that\ndoesn't. This time, we'll use linear regression to make a model of the\nrelationship between waist measurement and the visceral adipose tissue fat\n(measured in grams). The visceral adipose tissue fat is abbreviated `vat` in\nthe data. First, since the model uses a single predictor variable, let's look\nat the relationship with a pair plot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the relationship between waist_cm and vat\nwith(adipose, plot(waist_cm, vat, bty = 'n'))\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-plot-1.png){width=672}\n:::\n:::\n\n\n\n\nThe plot is obviously not showing a linear relationship, which will violate one\nof the conditions for linear regression. Also, you can see that there is less\nvariance of vat among the observations that have smaller waist measurements. So\nthat will violate the assumption that the residual variance has no relationship\nto the fitted values. To see how these will show up in the diagnostic plots, we\nneed to fit the linear regression model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate the model for vat\nfit_vat = lm(vat ~ waist_cm, data = adipose)\n\n# There is no problem creating the summary table:\nsummary(fit_vat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = vat ~ waist_cm, data = adipose)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-996.25 -265.96  -61.87  191.24 1903.46 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3604.196    334.241  -10.78   <2e-16 ***\nwaist_cm       51.353      3.937   13.04   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 479 on 79 degrees of freedom\nMultiple R-squared:  0.6829,\tAdjusted R-squared:  0.6789 \nF-statistic: 170.2 on 1 and 79 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Show the diagnostic plots\nlayout(matrix(1:4, 2, 2))\nplot(fit_vat)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-regression-diagnostics-1.png){width=672}\n:::\n:::\n\n\n\n\nThere is obviously a curved pattern in the Residuals vs. Fitted plot, and in\nthe Scale vs. Location plot. Residuals vs. Fitted shows a fan-shaped pattern,\ntoo, which reflects the increasing variance among the greater fitted values.\nThe QQ plot is not a straight line, although the difference is not as obvious.\nIn particular, the upper tail of residuals is heavier than expected. Together,\nall of these are indications that we may need to do a log transformation of the\nresponse. A log transformation helps to exaggerate the differences between\nsmaller numbers (make the lower tail heavier) and collapse some difference\namong larger numbers (make the upper tail less heavy).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a regression model where the response is log-transformed\nfit_log = lm(log(vat) ~ waist_cm, data = adipose)\n\n# Plot the diagnostics for the log-transformed model\nplot(fit_log)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/log-vat-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/log-vat-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/log-vat-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/log-vat-4.png){width=672}\n:::\n:::\n\n\n\n\nThe diagnostics do not look good after the log transformation, but now the\nproblem is the opposite: a too-heavy lower tail and residual variance decreases\nas the fitted value increases. Perhaps a better transformation is something in\nbetween the raw data and the log transform. Try a square-root transformation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a model where the vat is square root transformed\nfit_sqrt = lm(sqrt(vat) ~ waist_cm, data = adipose)\n\n# Plot the diagnostics for the log-transformed model\nplot(fit_sqrt)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-sqrt-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-sqrt-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-sqrt-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/vat-sqrt-4.png){width=672}\n:::\n:::\n\n\n\n\nThese look acceptable for real-world data.\n\n### Predictions and Variability\n\nThere are two scales of uncertainty for a regression model: uncertainty in the\nfitted relationship, and the uncertainty of a predicted outcome. The\nuncertainty of a prediction is always greater because it is calculated by\nadding the uncertainty of the fitted line to the uncertainty of a single data\npoint around that fitted line. We can illustrate using the example of the model\nwe just created to relate the waist measurement to the square root of vat.\n\nFor this example, we'll need the mvtnorm library to be loaded:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"mvtnorm\")\nlibrary(\"mvtnorm\")\n\n# Draw the data on the transformed scale\nwith(adipose, plot(waist_cm, sqrt(vat), bty = 'n'))\n\n# Plot the fitted regression line\nabline(coef(fit_sqrt)[[1]], coef(fit_sqrt)[[2]], col = 'red')\n\n# Plot 100 samples from the distribution of the regression line.\nfor (i in 1:100) {\n  cc = rmvnorm(n = 1, mean = coef(fit_sqrt), sigma = vcov(fit_sqrt))\n  abline(cc[[1]], cc[[2]], col = grey(0.8))\n}\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/predictions-1.png){width=672}\n:::\n:::\n\n\n\n\nClearly, the variability of the data points is greater than the variability of\nthe fitted line (that's why they lie outside the envelope of the fitted lines).\nWe can extract a confidence interval for fitted values or predictions with the\n`predict` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Draw the data on the transformed scale\nwith(adipose, plot(waist_cm, sqrt(vat), bty = 'n'))\n\n# Plot the fitted regression line\nabline(coef(fit_sqrt)[[1]], coef(fit_sqrt)[[2]], col = 'red')\n\n# Define some waist measurements where we'll construct confidence intervals\npred_pts = data.frame(waist_cm = c(70, 85, 110))\n\n# Calculate the 90% CI at each of the pred_pts\nff = predict(fit_sqrt, pred_pts, interval = \"confidence\", level = 0.9)\npp = predict(fit_sqrt, pred_pts, interval = \"prediction\", level = 0.9)\n\n# Convert the confidence intervals to data.frames\nff = as.data.frame(ff)\npp = as.data.frame(pp)\n\n# Add the three confidence intervals to the plots\n# (offset them a bit for clarity in the plot)\nfor (i in 1:3) {\n  lines(\n    x = rep(pred_pts$waist_cm[[i]] - 0.5, 2),\n    y = c(ff$lwr[[i]], ff$upr[[i]]),\n    col = 'blue',\n    lwd = 2\n  )\n\n  lines(\n    x = rep(pred_pts$waist_cm[[i]] + 0.5, 2),\n    y = c(pp$lwr[[i]], pp$upr[[i]]),\n    col = 'orange',\n    lwd = 2\n  )\n}\n\n# Add a legend\nlegend(\n  c(\"90% CI (fitted values)\", \"90% CI (predicted values)\"),\n  col = c(\"blue\", \"orange\"),\n  x = \"topleft\", lwd = 2, bty = 'n'\n)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/prediction-intervals-1.png){width=672}\n:::\n:::\n\n\n\n\nOne thing to notice about the confidence intervals is that the interval is\nsmallest (so the precision of the estimation is greatest) at the mean of the\npredictor variable. This is a general rule of fitting regression.\n\n\n## Model Selection\n\nChoosing how to represent your data is a common task in statistics. The most\ncommon target is to choose the representation (or model) that does the best job\nof predicting new data. We set this target because if we have a representation\nthat predicts the future, then we can say it must accurately represent the\nprocess that generates the data.\n\n## Cross-validation\n\nUnfortunately, we rarely have information about the future, so there isn't new\ndata to predict. One way to do prediction with the available data is to break\nit into a training part and a testing part. You make represent the training\npart with a model, and then use it to predict the left-out testing part. If you\nthen swap the to parts and repeat the process, you'll have a prediction for\nevery data point. This would be called two-fold cross validation because the\ndata was broken into two parts.\n\nIt's more common to break the data into more than two parts - typically five or\nten or one per data point. Then one part is taken as the testing part and all\nthe others go into the training part. The result is five-fold or ten-fold, or\nleave-one-out cross validation.\n\nLet's use cross-validation to do model selection. The model this time is a\nrepresentation of the number of births per day in 1978 in the United States.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the data\ngf_point(births ~ day_of_year, color = ~wknd, data = Births78)\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/cv-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Make models with two through ten knots in the spline for day_of_year\nbmod2  = lm(births ~ wknd + ns(day_of_year,  2), data = Births78)\nbmod4  = lm(births ~ wknd + ns(day_of_year,  4), data = Births78)\nbmod6  = lm(births ~ wknd + ns(day_of_year,  6), data = Births78)\nbmod8  = lm(births ~ wknd + ns(day_of_year,  8), data = Births78)\nbmod10 = lm(births ~ wknd + ns(day_of_year, 10), data = Births78)\n\n# Plot the 2 and 10 knot models\nmod_plot(bmod2, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/cv-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmod_plot(bmod10, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/cv-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Cross-validate to choose the best model\nmod_cv(bmod2, bmod4, bmod6, bmod8, bmod10, k = nrow(Births78), ntrials = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       mse  model\n1 190815.9  bmod2\n2 143305.1  bmod4\n3 104875.7  bmod6\n4 106094.2  bmod8\n5 107130.5 bmod10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot the data\nmod_plot(bmod6, births ~ day_of_year + wknd) +\n  geom_point(\n    mapping = aes(x = day_of_year, y = births, color = wknd),\n    data = Births78\n  )\n```\n\n::: {.cell-output-display}\n![](12_statistics_files/figure-html/cv-4.png){width=672}\n:::\n:::\n\n\n\n\nCross-validation suggests that six knots is the ideal number, because it has\nthe smallest mean-squared error (mse). The resulting model looks good, too.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}